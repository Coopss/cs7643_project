{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X02naVKmHQX9",
    "outputId": "3083cdeb-22d3-4151-9ff4-646063640cab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=68616339456, available=58974699520, percent=14.1, used=9641639936, free=58974699520)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psutil\n",
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JH0JtdCeE1n2",
    "outputId": "3392dbcf-8b05-4f76-a160-ec970d1eca3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/Ryan/Dropbox/CS7643/project/src\n"
     ]
    }
   ],
   "source": [
    "# !nvidia-smi\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bH1W6YrdjNSp"
   },
   "source": [
    "# Prepare the dataset and build a ``TextDataset``\n",
    "\n",
    "The next step is to extract the instructions from all recipes and build a `TextDataset`. The `TextDataset` is a custom implementation of the [Pytroch `Dataset` class](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class) implemented by the transformers library. If you want to know more about Dataset in Pytroch you can check out this [youtube video](https://www.youtube.com/watch?v=PXOzkkB5eH0&ab_channel=PythonEngineer).\n",
    "\n",
    "First, we are going to split the `recipes.json` into a `train` and `test` section and extract `Instructions` from the recipes and write them into a `train_dataset.txt` and `test_dataset.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jg78wNnTl305"
   },
   "source": [
    "the next step is to download the tokenizer, which we use. We use the tokenizer from the `german-gpt2` model on [huggingface](https://huggingface.co/anonymous-german-nlp/german-gpt2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "VCaunLMtlPfw"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "train_path = '../data/train_text.txt'\n",
    "test_path = '../data/test_text.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m9lHS0mIMak4",
    "outputId": "92e945d0-802c-4497-f7e1-71f497d827c9"
   },
   "outputs": [],
   "source": [
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "\n",
    "def load_dataset(train_path, test_path, tokenizer):\n",
    "    train_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=train_path,\n",
    "          block_size=128)\n",
    "     \n",
    "    test_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=test_path,\n",
    "          block_size=128)   \n",
    "    \n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=False,\n",
    "    )\n",
    "    return train_dataset, test_dataset, data_collator\n",
    "\n",
    "train_dataset, test_dataset, data_collator = load_dataset(train_path, test_path, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 284991\n",
      "Size of test set: 142000\n"
     ]
    }
   ],
   "source": [
    "print('Size of training set:', len(train_dataset))\n",
    "print('Size of test set:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThG6jwL7qET8"
   },
   "source": [
    "# Initialize `Trainer` with `TrainingArguments` and GPT-2 model\n",
    "\n",
    "The [Trainer](https://huggingface.co/transformers/main_classes/trainer.html#transformers.Trainer) class provides an API for feature-complete training. It is used in most of the [example scripts](https://huggingface.co/transformers/examples.html) from Huggingface. Before we can instantiate our `Trainer` we need to download our GPT-2 model and create a [TrainingArguments](https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments) to access all the points of customization during training. In the `TrainingArguments`, we can define the Hyperparameters we are going to use in the training process like our `learning_rate`, `num_train_epochs`, or  `per_device_train_batch_size`. A complete list can you find [here](https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H7hhmbT2ModI",
    "outputId": "b07d72e4-3d4a-42b5-928d-bf80b072473f"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments,AutoModelWithLMHead\n",
    "\n",
    "model = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-CC\", #The output directory\n",
    "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "    num_train_epochs=5, # number of training epochs\n",
    "    per_device_train_batch_size=4, # batch size for training\n",
    "    per_device_eval_batch_size=4,  # batch size for evaluation\n",
    "    eval_steps = 400, # Number of update steps between two evaluations.\n",
    "    save_steps=800, # after # steps model is saved \n",
    "    warmup_steps=500,# number of warmup steps for learning rate scheduler\n",
    "    prediction_loss_only=True,\n",
    "    )\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyQh0jlTqR6-"
   },
   "source": [
    "# Train and save the model\n",
    "\n",
    "To train the model we can simply run `Trainer.train()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wjIzSWPTKzBf",
    "outputId": "3a7ff26f-fd4b-418c-c986-5d45f31cb8ae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='4' max='356240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [     4/356240 03:56 < 11701:29:51, 0.01 it/s, Epoch 0.00/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHXqTv8kqxpJ"
   },
   "source": [
    "After training is done you can save the model by calling `save_model()`. This will save the trained model to our `output_dir` from our `TrainingArguments`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q5quyGeMNdjE"
   },
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGEiQ1mhOyNv"
   },
   "source": [
    "# Test the model\n",
    "\n",
    "To test the model we are going to use another [highlight of the transformers library](https://huggingface.co/transformers/main_classes/pipelines.html?highlight=pipelines) called `pipeline`. [Pipelines](https://huggingface.co/transformers/main_classes/pipelines.html?highlight=pipelines) are objects that offer a simple API dedicated to several tasks, among others also `text-generation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fh4Q1BR0OtDo"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "chef = pipeline('text-generation',model='./gpt2-CC', tokenizer='gpt2',config={'max_length':1500})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "laDp891gO25V",
    "outputId": "d47868c7-ce8d-40ad-f436-4ba78faea8b1"
   },
   "outputs": [],
   "source": [
    "chef(\"My dog died this past weekend. Any advice for a grieving boy? <BOS> \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77HLWozaJFQF"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "Copy of Fine-tune a non-English GPT-2 Model with Huggingface",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
