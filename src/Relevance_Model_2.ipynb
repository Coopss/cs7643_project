{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Relevance_Model_2.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"609320f625c443d8ac5aee09e2ee1367":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b0bf5111c6104a9daa47054212f498fe","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_da0e709e831f40d1bd83ec7e5c06ac10","IPY_MODEL_c7db0d46ab2b4356a64cf883833bae11"]}},"b0bf5111c6104a9daa47054212f498fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"da0e709e831f40d1bd83ec7e5c06ac10":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9c93264953fa4c618cabff4117309639","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":106646,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":106646,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5a3a209bfa324b3aaadbd7cd51266461"}},"c7db0d46ab2b4356a64cf883833bae11":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_309fd6cc6cef4ab0ab26efa8e1853caf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 106646/106646 [03:43&lt;00:00, 476.99it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_280e5e721e4c49cdbb00e6c1e55413bb"}},"9c93264953fa4c618cabff4117309639":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5a3a209bfa324b3aaadbd7cd51266461":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"309fd6cc6cef4ab0ab26efa8e1853caf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"280e5e721e4c49cdbb00e6c1e55413bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"77c1a9a3eea84aabaa511926b35b88b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6102c3cb76b447a1b800a629376d13d1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7cd489d038834ee38c655c0b9e163a11","IPY_MODEL_b267a8819bfb4a89a3afb5ee971f4dc1"]}},"6102c3cb76b447a1b800a629376d13d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7cd489d038834ee38c655c0b9e163a11":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4006b27b1a09467ea6d5569db26bc0ef","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":10,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fad87e8fb589424e8aacebdc58f7c0d0"}},"b267a8819bfb4a89a3afb5ee971f4dc1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ffd823b3f235469fa8389d2fc771b52c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 10/10 [12:17&lt;00:00, 73.80s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3f6829da3ac14a24a6b07e3c2f3850be"}},"4006b27b1a09467ea6d5569db26bc0ef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fad87e8fb589424e8aacebdc58f7c0d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ffd823b3f235469fa8389d2fc771b52c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3f6829da3ac14a24a6b07e3c2f3850be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qIAvyc_7_1yg","executionInfo":{"status":"ok","timestamp":1620163537808,"user_tz":240,"elapsed":7972,"user":{"displayName":"Ryan Cooper","photoUrl":"","userId":"03930546846624815383"}},"outputId":"2261c1b6-3172-4ee8-c228-b6cf5c999856"},"source":["!pip install -U sentence-transformers"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting sentence-transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/87/49dc49e13ac107ce912c2f3f3fd92252c6d4221e88d1e6c16747044a11d8/sentence-transformers-1.1.0.tar.gz (78kB)\n","\u001b[K     |████████████████████████████████| 81kB 6.9MB/s \n","\u001b[?25hCollecting transformers<5.0.0,>=3.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 22.3MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n","Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.8.1+cu101)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n","Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n","Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n","Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 35.1MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 50.2MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n","Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.10.1)\n","Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 62.8MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.1)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n","Building wheels for collected packages: sentence-transformers\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-1.1.0-cp37-none-any.whl size=119615 sha256=da3fdb1ed4e0b89b4389ac440d9fe1a487f3f17882af911873c12e95c3211b5b\n","  Stored in directory: /root/.cache/pip/wheels/84/cb/21/1066bff3027215c760ca14a198f698bca8fccb92e33e2327eb\n","Successfully built sentence-transformers\n","Installing collected packages: tokenizers, sacremoses, transformers, sentencepiece, sentence-transformers\n","Successfully installed sacremoses-0.0.45 sentence-transformers-1.1.0 sentencepiece-0.1.95 tokenizers-0.10.2 transformers-4.5.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6O8JgoSyX1Th","executionInfo":{"status":"ok","timestamp":1620163608737,"user_tz":240,"elapsed":78895,"user":{"displayName":"Ryan Cooper","photoUrl":"","userId":"03930546846624815383"}},"outputId":"0673332a-e262-4179-ebb3-cc17b8845fcf"},"source":["!wget https://www.dropbox.com/s/xq4vosn9xyn1dy1/grouped_data.pickle?dl=0 -O grouped_data.pickle"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2021-05-04 21:25:37--  https://www.dropbox.com/s/xq4vosn9xyn1dy1/grouped_data.pickle?dl=0\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6027:18::a27d:4812\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/xq4vosn9xyn1dy1/grouped_data.pickle [following]\n","--2021-05-04 21:25:37--  https://www.dropbox.com/s/raw/xq4vosn9xyn1dy1/grouped_data.pickle\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://ucd61e904455835cc44888c4f138.dl.dropboxusercontent.com/cd/0/inline/BN3elKVOJOA-pwsqB_lneVBabHSJhYV6c6GSmvZWlpxGLpC6cYQ0qL-wnRnuXlly98DSLywORn4ZeB2Og2tpozuW3mSHEmHC1QxRksEdJKmsP_M7tibQPV2GYdRjXRlwuHUNAAamVG6kLTCALJQuz2p6/file# [following]\n","--2021-05-04 21:25:38--  https://ucd61e904455835cc44888c4f138.dl.dropboxusercontent.com/cd/0/inline/BN3elKVOJOA-pwsqB_lneVBabHSJhYV6c6GSmvZWlpxGLpC6cYQ0qL-wnRnuXlly98DSLywORn4ZeB2Og2tpozuW3mSHEmHC1QxRksEdJKmsP_M7tibQPV2GYdRjXRlwuHUNAAamVG6kLTCALJQuz2p6/file\n","Resolving ucd61e904455835cc44888c4f138.dl.dropboxusercontent.com (ucd61e904455835cc44888c4f138.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6021:15::a27d:410f\n","Connecting to ucd61e904455835cc44888c4f138.dl.dropboxusercontent.com (ucd61e904455835cc44888c4f138.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1740570798 (1.6G) [text/plain]\n","Saving to: ‘grouped_data.pickle’\n","\n","grouped_data.pickle 100%[===================>]   1.62G  28.2MB/s    in 70s     \n","\n","2021-05-04 21:26:48 (23.8 MB/s) - ‘grouped_data.pickle’ saved [1740570798/1740570798]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eRr0i9ulYK8Q","executionInfo":{"status":"ok","timestamp":1620163608931,"user_tz":240,"elapsed":79084,"user":{"displayName":"Ryan Cooper","photoUrl":"","userId":"03930546846624815383"}},"outputId":"a847bdb9-ff18-49b0-929a-b6370a43883e"},"source":["!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Tue May  4 21:26:48 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iLliCdo-YN_c","executionInfo":{"status":"ok","timestamp":1620163687825,"user_tz":240,"elapsed":157972,"user":{"displayName":"Ryan Cooper","photoUrl":"","userId":"03930546846624815383"}},"outputId":"ddf4e0b7-a905-4574-e806-cc7e0c3ed17a"},"source":["import pickle\n","from sentence_transformers import SentenceTransformer\n","\n","import torch\n","!pip install transformers\n","from transformers import BertForNextSentencePrediction, BertTokenizerFast, Trainer, TrainingArguments\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","from tqdm.notebook import tqdm\n","from scipy import stats\n","import sklearn\n","import collections\n","import random\n","\n","from google.colab import drive\n","\n","random.seed(2021)\n","drive.mount('/content/gdrive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["609320f625c443d8ac5aee09e2ee1367","b0bf5111c6104a9daa47054212f498fe","da0e709e831f40d1bd83ec7e5c06ac10","c7db0d46ab2b4356a64cf883833bae11","9c93264953fa4c618cabff4117309639","5a3a209bfa324b3aaadbd7cd51266461","309fd6cc6cef4ab0ab26efa8e1853caf","280e5e721e4c49cdbb00e6c1e55413bb"]},"id":"uatQN8l9YY6h","executionInfo":{"status":"ok","timestamp":1620165859568,"user_tz":240,"elapsed":16590,"user":{"displayName":"Ryan Cooper","photoUrl":"","userId":"03930546846624815383"}},"outputId":"53446df4-9290-4669-8ed8-61ecf4b4e0b5"},"source":["# load sample data\n","# format { post_id: [post, [comment1, comment2, ... ] }\n","\n","data_file_path = 'grouped_data.pickle'\n","\n","def get_best_comm(comms):\n","  best_comm = None\n","  best_score = -np.inf\n","\n","  for comm in comms:\n","    if comm['score'] > best_score:\n","      best_comm = comm\n","      best_score = comm['score']\n","\n","    return best_comm\n","\n","def load_data(file_path):\n","    posts_comments = []\n","    with open(file_path, 'rb') as f:\n","        data = pickle.load(f)\n","        for post_id, val in tqdm(list(data.items())):\n","            post = val[0]\n","            comms = val[1]\n","            # best_comm = get_best_comm(comms)\n","\n","            # if len(post['title']) < 500 and len(best_comm['body']) < 500 and best_comm['body'] != '[deleted]' and best_comm['body'] != '[removed]':\n","            #   posts_comments.append((post['title'], best_comm['body']))\n","\n","            for com in comms:\n","                try:\n","                    if len(post['title']) < 500 and len(com['body']) < 500 and com['body'] != '[deleted]' and com['body'] != '[removed]':\n","                        posts_comments.append((post['title'], com['body']))\n","                except:\n","                    pass\n","                \n","    return posts_comments\n","    \n","posts_comms = load_data(data_file_path)\n","len(posts_comms)"],"execution_count":90,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"609320f625c443d8ac5aee09e2ee1367","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=106646.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["1403354"]},"metadata":{"tags":[]},"execution_count":90}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sKIyl2MwYr3s","executionInfo":{"status":"ok","timestamp":1620165862431,"user_tz":240,"elapsed":17026,"user":{"displayName":"Ryan Cooper","photoUrl":"","userId":"03930546846624815383"}},"outputId":"024a383b-ac35-4d26-9b67-69a989dede32"},"source":["post_comms_realfake = []\n","labels = []\n","for post, comment in posts_comms:\n","  while True:\n","    rpost, rcomment = random.choice(posts_comms)\n","    if post != rpost:\n","      break\n","  \n","  post_comms_realfake.append((post, comment))\n","  labels.append(0) # comment \\in post\n","  post_comms_realfake.append((post, rcomment))\n","  labels.append(1) # comment \\nin post\n","\n","len(post_comms_realfake)"],"execution_count":91,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2806708"]},"metadata":{"tags":[]},"execution_count":91}]},{"cell_type":"code","metadata":{"id":"lrbmecbIYuMu","executionInfo":{"status":"ok","timestamp":1620165864149,"user_tz":240,"elapsed":16888,"user":{"displayName":"Ryan Cooper","photoUrl":"","userId":"03930546846624815383"}}},"source":["# split text\n","train_texts, test_texts, train_labels, test_labels = train_test_split(post_comms_realfake, labels, test_size=.25, shuffle=True)\n","#train_texts, test_texts, train_labels, test_labels = train_test_split(post_comms_realfake, labels, test_size=.01, train_size=.04, shuffle=True)"],"execution_count":92,"outputs":[]},{"cell_type":"code","metadata":{"id":"d6U-pmUyqj3U","executionInfo":{"status":"ok","timestamp":1620165866096,"user_tz":240,"elapsed":17152,"user":{"displayName":"Ryan Cooper","photoUrl":"","userId":"03930546846624815383"}}},"source":["model = SentenceTransformer('stsb-distilroberta-base-v2')"],"execution_count":93,"outputs":[]},{"cell_type":"code","metadata":{"id":"VVOh0uGnANzh","executionInfo":{"status":"ok","timestamp":1620165868353,"user_tz":240,"elapsed":19098,"user":{"displayName":"Ryan Cooper","photoUrl":"","userId":"03930546846624815383"}}},"source":["train_posts = [item[0] + \" \" + item[1] for item in train_texts]\n","test_posts = [item[0] + \" \" + item[1] for item in test_texts]"],"execution_count":94,"outputs":[]},{"cell_type":"code","metadata":{"id":"d1b_nEDoAWGY","executionInfo":{"status":"ok","timestamp":1620168190036,"user_tz":240,"elapsed":2340004,"user":{"displayName":"Ryan Cooper","photoUrl":"","userId":"03930546846624815383"}}},"source":["embed_train = model.encode(train_posts)"],"execution_count":95,"outputs":[]},{"cell_type":"code","metadata":{"id":"jfp3ZxhIAhSX","executionInfo":{"status":"ok","timestamp":1620168960985,"user_tz":240,"elapsed":3110543,"user":{"displayName":"Ryan Cooper","photoUrl":"","userId":"03930546846624815383"}}},"source":["embed_test = model.encode(test_posts)"],"execution_count":96,"outputs":[]},{"cell_type":"code","metadata":{"id":"N7xE83WuVdy2","executionInfo":{"status":"ok","timestamp":1620168960987,"user_tz":240,"elapsed":3109093,"user":{"displayName":"Ryan Cooper","photoUrl":"","userId":"03930546846624815383"}}},"source":["# create dataset class and load encodings and associated labels to it\n","\n","class upvote_prediction_dataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        return torch.tensor(self.encodings[idx]), torch.tensor(self.labels[idx])\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","train_dataset = upvote_prediction_dataset(embed_train, train_labels)\n","test_dataset = upvote_prediction_dataset(embed_test, test_labels)"],"execution_count":97,"outputs":[]},{"cell_type":"code","metadata":{"id":"NBMB-qa8Sz0z","executionInfo":{"status":"ok","timestamp":1620168960988,"user_tz":240,"elapsed":3108212,"user":{"displayName":"Ryan Cooper","photoUrl":"","userId":"03930546846624815383"}}},"source":["batch_size = 64\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False)"],"execution_count":98,"outputs":[]},{"cell_type":"code","metadata":{"id":"nOs0Ms5ES27n","executionInfo":{"status":"ok","timestamp":1620168960988,"user_tz":240,"elapsed":3107987,"user":{"displayName":"Ryan Cooper","photoUrl":"","userId":"03930546846624815383"}}},"source":["class Net(torch.nn.Module):\n","    def __init__(self, input_size):\n","        super(Net, self).__init__()                    # Inherited from the parent class nn.Module\n","        self.fc1 = torch.nn.Linear(input_size, 250)  \n","        self.relu = torch.nn.ReLU()                        \n","        self.fc2 = torch.nn.Linear(250, 50) \n","        self.relu2 = torch.nn.ReLU()    \n","        self.fc3 = torch.nn.Linear(50, 2) \n","        self.softmax = torch.nn.Softmax(dim=1) \n","    def forward(self, x):                              # Forward pass: stacking each layer together\n","        out = self.fc1(x)\n","        out = self.relu(out)\n","        out = self.fc2(out)\n","        out = self.relu2(out)\n","        out = self.fc3(out)\n","        out = self.softmax(out)\n","        return out"],"execution_count":99,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IK2P1PfDS8pv","executionInfo":{"status":"ok","timestamp":1620168960989,"user_tz":240,"elapsed":3107535,"user":{"displayName":"Ryan Cooper","photoUrl":"","userId":"03930546846624815383"}},"outputId":"796392ed-b9ce-46e8-ef27-041cbf78976d"},"source":["net = Net(embed_train.shape[1])\n","net.cuda()"],"execution_count":100,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Net(\n","  (fc1): Linear(in_features=768, out_features=250, bias=True)\n","  (relu): ReLU()\n","  (fc2): Linear(in_features=250, out_features=50, bias=True)\n","  (relu2): ReLU()\n","  (fc3): Linear(in_features=50, out_features=2, bias=True)\n","  (softmax): Softmax(dim=1)\n",")"]},"metadata":{"tags":[]},"execution_count":100}]},{"cell_type":"code","metadata":{"id":"AVPMQZqzTN-P","executionInfo":{"status":"ok","timestamp":1620168960990,"user_tz":240,"elapsed":3106789,"user":{"displayName":"Ryan Cooper","photoUrl":"","userId":"03930546846624815383"}}},"source":["criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(net.parameters())"],"execution_count":101,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["77c1a9a3eea84aabaa511926b35b88b8","6102c3cb76b447a1b800a629376d13d1","7cd489d038834ee38c655c0b9e163a11","b267a8819bfb4a89a3afb5ee971f4dc1","4006b27b1a09467ea6d5569db26bc0ef","fad87e8fb589424e8aacebdc58f7c0d0","ffd823b3f235469fa8389d2fc771b52c","3f6829da3ac14a24a6b07e3c2f3850be"]},"id":"Wmsc31dZTWlR","executionInfo":{"status":"ok","timestamp":1620170467086,"user_tz":240,"elapsed":738397,"user":{"displayName":"Ryan Cooper","photoUrl":"","userId":"03930546846624815383"}},"outputId":"d4931617-f7f7-45d4-af31-30c9c2eda240"},"source":["num_epochs = 10\n","for epoch in tqdm(range(num_epochs)):\n","    for i, (x, labels) in enumerate(train_loader):   # Load a batch of images with its (index, data, class)\n","        if torch.cuda.is_available():\n","          x = x.cuda()\n","          labels = labels.cuda()\n","        \n","        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n","        outputs = net(x)                             # Forward pass: compute the output class given a image\n","        loss = criterion(outputs, labels)                 # Compute the loss: difference between the output class and the pre-given label\n","        loss.backward()                                   # Backward pass: compute the weight\n","        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n","        \n","        if (i+1) % 100 == 0:                              # Logging\n","            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' % (epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss))"],"execution_count":107,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77c1a9a3eea84aabaa511926b35b88b8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Epoch [1/10], Step [100/32891], Loss: 0.4977\n","Epoch [1/10], Step [200/32891], Loss: 0.4983\n","Epoch [1/10], Step [300/32891], Loss: 0.5454\n","Epoch [1/10], Step [400/32891], Loss: 0.4320\n","Epoch [1/10], Step [500/32891], Loss: 0.5278\n","Epoch [1/10], Step [600/32891], Loss: 0.4960\n","Epoch [1/10], Step [700/32891], Loss: 0.4831\n","Epoch [1/10], Step [800/32891], Loss: 0.4933\n","Epoch [1/10], Step [900/32891], Loss: 0.5123\n","Epoch [1/10], Step [1000/32891], Loss: 0.5601\n","Epoch [1/10], Step [1100/32891], Loss: 0.5040\n","Epoch [1/10], Step [1200/32891], Loss: 0.4343\n","Epoch [1/10], Step [1300/32891], Loss: 0.5581\n","Epoch [1/10], Step [1400/32891], Loss: 0.5041\n","Epoch [1/10], Step [1500/32891], Loss: 0.5909\n","Epoch [1/10], Step [1600/32891], Loss: 0.4496\n","Epoch [1/10], Step [1700/32891], Loss: 0.5450\n","Epoch [1/10], Step [1800/32891], Loss: 0.5686\n","Epoch [1/10], Step [1900/32891], Loss: 0.5652\n","Epoch [1/10], Step [2000/32891], Loss: 0.5171\n","Epoch [1/10], Step [2100/32891], Loss: 0.5005\n","Epoch [1/10], Step [2200/32891], Loss: 0.5424\n","Epoch [1/10], Step [2300/32891], Loss: 0.4731\n","Epoch [1/10], Step [2400/32891], Loss: 0.4441\n","Epoch [1/10], Step [2500/32891], Loss: 0.5356\n","Epoch [1/10], Step [2600/32891], Loss: 0.5604\n","Epoch [1/10], Step [2700/32891], Loss: 0.4732\n","Epoch [1/10], Step [2800/32891], Loss: 0.5042\n","Epoch [1/10], Step [2900/32891], Loss: 0.5204\n","Epoch [1/10], Step [3000/32891], Loss: 0.5453\n","Epoch [1/10], Step [3100/32891], Loss: 0.5243\n","Epoch [1/10], Step [3200/32891], Loss: 0.5382\n","Epoch [1/10], Step [3300/32891], Loss: 0.5083\n","Epoch [1/10], Step [3400/32891], Loss: 0.4997\n","Epoch [1/10], Step [3500/32891], Loss: 0.4404\n","Epoch [1/10], Step [3600/32891], Loss: 0.5713\n","Epoch [1/10], Step [3700/32891], Loss: 0.4568\n","Epoch [1/10], Step [3800/32891], Loss: 0.5905\n","Epoch [1/10], Step [3900/32891], Loss: 0.5859\n","Epoch [1/10], Step [4000/32891], Loss: 0.5158\n","Epoch [1/10], Step [4100/32891], Loss: 0.5599\n","Epoch [1/10], Step [4200/32891], Loss: 0.5102\n","Epoch [1/10], Step [4300/32891], Loss: 0.5246\n","Epoch [1/10], Step [4400/32891], Loss: 0.4827\n","Epoch [1/10], Step [4500/32891], Loss: 0.5447\n","Epoch [1/10], Step [4600/32891], Loss: 0.5213\n","Epoch [1/10], Step [4700/32891], Loss: 0.4902\n","Epoch [1/10], Step [4800/32891], Loss: 0.5808\n","Epoch [1/10], Step [4900/32891], Loss: 0.4912\n","Epoch [1/10], Step [5000/32891], Loss: 0.4952\n","Epoch [1/10], Step [5100/32891], Loss: 0.4424\n","Epoch [1/10], Step [5200/32891], Loss: 0.5712\n","Epoch [1/10], Step [5300/32891], Loss: 0.5665\n","Epoch [1/10], Step [5400/32891], Loss: 0.6066\n","Epoch [1/10], Step [5500/32891], Loss: 0.5251\n","Epoch [1/10], Step [5600/32891], Loss: 0.4790\n","Epoch [1/10], Step [5700/32891], Loss: 0.5281\n","Epoch [1/10], Step [5800/32891], Loss: 0.5497\n","Epoch [1/10], Step [5900/32891], Loss: 0.5218\n","Epoch [1/10], Step [6000/32891], Loss: 0.4924\n","Epoch [1/10], Step [6100/32891], Loss: 0.5207\n","Epoch [1/10], Step [6200/32891], Loss: 0.4543\n","Epoch [1/10], Step [6300/32891], Loss: 0.5416\n","Epoch [1/10], Step [6400/32891], Loss: 0.4652\n","Epoch [1/10], Step [6500/32891], Loss: 0.4886\n","Epoch [1/10], Step [6600/32891], Loss: 0.5088\n","Epoch [1/10], Step [6700/32891], Loss: 0.4875\n","Epoch [1/10], Step [6800/32891], Loss: 0.4768\n","Epoch [1/10], Step [6900/32891], Loss: 0.4868\n","Epoch [1/10], Step [7000/32891], Loss: 0.5793\n","Epoch [1/10], Step [7100/32891], Loss: 0.5189\n","Epoch [1/10], Step [7200/32891], Loss: 0.4726\n","Epoch [1/10], Step [7300/32891], Loss: 0.4944\n","Epoch [1/10], Step [7400/32891], Loss: 0.5512\n","Epoch [1/10], Step [7500/32891], Loss: 0.5639\n","Epoch [1/10], Step [7600/32891], Loss: 0.5174\n","Epoch [1/10], Step [7700/32891], Loss: 0.5023\n","Epoch [1/10], Step [7800/32891], Loss: 0.4990\n","Epoch [1/10], Step [7900/32891], Loss: 0.5771\n","Epoch [1/10], Step [8000/32891], Loss: 0.4981\n","Epoch [1/10], Step [8100/32891], Loss: 0.5498\n","Epoch [1/10], Step [8200/32891], Loss: 0.6019\n","Epoch [1/10], Step [8300/32891], Loss: 0.4774\n","Epoch [1/10], Step [8400/32891], Loss: 0.5183\n","Epoch [1/10], Step [8500/32891], Loss: 0.5184\n","Epoch [1/10], Step [8600/32891], Loss: 0.5325\n","Epoch [1/10], Step [8700/32891], Loss: 0.5537\n","Epoch [1/10], Step [8800/32891], Loss: 0.5531\n","Epoch [1/10], Step [8900/32891], Loss: 0.5394\n","Epoch [1/10], Step [9000/32891], Loss: 0.5277\n","Epoch [1/10], Step [9100/32891], Loss: 0.5781\n","Epoch [1/10], Step [9200/32891], Loss: 0.5259\n","Epoch [1/10], Step [9300/32891], Loss: 0.5209\n","Epoch [1/10], Step [9400/32891], Loss: 0.5640\n","Epoch [1/10], Step [9500/32891], Loss: 0.5336\n","Epoch [1/10], Step [9600/32891], Loss: 0.4338\n","Epoch [1/10], Step [9700/32891], Loss: 0.5001\n","Epoch [1/10], Step [9800/32891], Loss: 0.5307\n","Epoch [1/10], Step [9900/32891], Loss: 0.5371\n","Epoch [1/10], Step [10000/32891], Loss: 0.4991\n","Epoch [1/10], Step [10100/32891], Loss: 0.6011\n","Epoch [1/10], Step [10200/32891], Loss: 0.4572\n","Epoch [1/10], Step [10300/32891], Loss: 0.4965\n","Epoch [1/10], Step [10400/32891], Loss: 0.5053\n","Epoch [1/10], Step [10500/32891], Loss: 0.5171\n","Epoch [1/10], Step [10600/32891], Loss: 0.4649\n","Epoch [1/10], Step [10700/32891], Loss: 0.5078\n","Epoch [1/10], Step [10800/32891], Loss: 0.4774\n","Epoch [1/10], Step [10900/32891], Loss: 0.5339\n","Epoch [1/10], Step [11000/32891], Loss: 0.4943\n","Epoch [1/10], Step [11100/32891], Loss: 0.4497\n","Epoch [1/10], Step [11200/32891], Loss: 0.5717\n","Epoch [1/10], Step [11300/32891], Loss: 0.5014\n","Epoch [1/10], Step [11400/32891], Loss: 0.5349\n","Epoch [1/10], Step [11500/32891], Loss: 0.4983\n","Epoch [1/10], Step [11600/32891], Loss: 0.5851\n","Epoch [1/10], Step [11700/32891], Loss: 0.5701\n","Epoch [1/10], Step [11800/32891], Loss: 0.5396\n","Epoch [1/10], Step [11900/32891], Loss: 0.4861\n","Epoch [1/10], Step [12000/32891], Loss: 0.5752\n","Epoch [1/10], Step [12100/32891], Loss: 0.5356\n","Epoch [1/10], Step [12200/32891], Loss: 0.5258\n","Epoch [1/10], Step [12300/32891], Loss: 0.5207\n","Epoch [1/10], Step [12400/32891], Loss: 0.5359\n","Epoch [1/10], Step [12500/32891], Loss: 0.4971\n","Epoch [1/10], Step [12600/32891], Loss: 0.4748\n","Epoch [1/10], Step [12700/32891], Loss: 0.5769\n","Epoch [1/10], Step [12800/32891], Loss: 0.5114\n","Epoch [1/10], Step [12900/32891], Loss: 0.6503\n","Epoch [1/10], Step [13000/32891], Loss: 0.5358\n","Epoch [1/10], Step [13100/32891], Loss: 0.5172\n","Epoch [1/10], Step [13200/32891], Loss: 0.5533\n","Epoch [1/10], Step [13300/32891], Loss: 0.4315\n","Epoch [1/10], Step [13400/32891], Loss: 0.5852\n","Epoch [1/10], Step [13500/32891], Loss: 0.5210\n","Epoch [1/10], Step [13600/32891], Loss: 0.6037\n","Epoch [1/10], Step [13700/32891], Loss: 0.5610\n","Epoch [1/10], Step [13800/32891], Loss: 0.4317\n","Epoch [1/10], Step [13900/32891], Loss: 0.4984\n","Epoch [1/10], Step [14000/32891], Loss: 0.5446\n","Epoch [1/10], Step [14100/32891], Loss: 0.5859\n","Epoch [1/10], Step [14200/32891], Loss: 0.5702\n","Epoch [1/10], Step [14300/32891], Loss: 0.4936\n","Epoch [1/10], Step [14400/32891], Loss: 0.5359\n","Epoch [1/10], Step [14500/32891], Loss: 0.4765\n","Epoch [1/10], Step [14600/32891], Loss: 0.4936\n","Epoch [1/10], Step [14700/32891], Loss: 0.5162\n","Epoch [1/10], Step [14800/32891], Loss: 0.5254\n","Epoch [1/10], Step [14900/32891], Loss: 0.5806\n","Epoch [1/10], Step [15000/32891], Loss: 0.4861\n","Epoch [1/10], Step [15100/32891], Loss: 0.6014\n","Epoch [1/10], Step [15200/32891], Loss: 0.4756\n","Epoch [1/10], Step [15300/32891], Loss: 0.4658\n","Epoch [1/10], Step [15400/32891], Loss: 0.5117\n","Epoch [1/10], Step [15500/32891], Loss: 0.5081\n","Epoch [1/10], Step [15600/32891], Loss: 0.4674\n","Epoch [1/10], Step [15700/32891], Loss: 0.5544\n","Epoch [1/10], Step [15800/32891], Loss: 0.5111\n","Epoch [1/10], Step [15900/32891], Loss: 0.4968\n","Epoch [1/10], Step [16000/32891], Loss: 0.5075\n","Epoch [1/10], Step [16100/32891], Loss: 0.5261\n","Epoch [1/10], Step [16200/32891], Loss: 0.6169\n","Epoch [1/10], Step [16300/32891], Loss: 0.4919\n","Epoch [1/10], Step [16400/32891], Loss: 0.5315\n","Epoch [1/10], Step [16500/32891], Loss: 0.4874\n","Epoch [1/10], Step [16600/32891], Loss: 0.5535\n","Epoch [1/10], Step [16700/32891], Loss: 0.5440\n","Epoch [1/10], Step [16800/32891], Loss: 0.5183\n","Epoch [1/10], Step [16900/32891], Loss: 0.5122\n","Epoch [1/10], Step [17000/32891], Loss: 0.5126\n","Epoch [1/10], Step [17100/32891], Loss: 0.5657\n","Epoch [1/10], Step [17200/32891], Loss: 0.5477\n","Epoch [1/10], Step [17300/32891], Loss: 0.5093\n","Epoch [1/10], Step [17400/32891], Loss: 0.4843\n","Epoch [1/10], Step [17500/32891], Loss: 0.5286\n","Epoch [1/10], Step [17600/32891], Loss: 0.4768\n","Epoch [1/10], Step [17700/32891], Loss: 0.4926\n","Epoch [1/10], Step [17800/32891], Loss: 0.5486\n","Epoch [1/10], Step [17900/32891], Loss: 0.5262\n","Epoch [1/10], Step [18000/32891], Loss: 0.4641\n","Epoch [1/10], Step [18100/32891], Loss: 0.6167\n","Epoch [1/10], Step [18200/32891], Loss: 0.4765\n","Epoch [1/10], Step [18300/32891], Loss: 0.4831\n","Epoch [1/10], Step [18400/32891], Loss: 0.4943\n","Epoch [1/10], Step [18500/32891], Loss: 0.4641\n","Epoch [1/10], Step [18600/32891], Loss: 0.5241\n","Epoch [1/10], Step [18700/32891], Loss: 0.4857\n","Epoch [1/10], Step [18800/32891], Loss: 0.5719\n","Epoch [1/10], Step [18900/32891], Loss: 0.5575\n","Epoch [1/10], Step [19000/32891], Loss: 0.4532\n","Epoch [1/10], Step [19100/32891], Loss: 0.5112\n","Epoch [1/10], Step [19200/32891], Loss: 0.4893\n","Epoch [1/10], Step [19300/32891], Loss: 0.4883\n","Epoch [1/10], Step [19400/32891], Loss: 0.4974\n","Epoch [1/10], Step [19500/32891], Loss: 0.4669\n","Epoch [1/10], Step [19600/32891], Loss: 0.4904\n","Epoch [1/10], Step [19700/32891], Loss: 0.4711\n","Epoch [1/10], Step [19800/32891], Loss: 0.5068\n","Epoch [1/10], Step [19900/32891], Loss: 0.4943\n","Epoch [1/10], Step [20000/32891], Loss: 0.4093\n","Epoch [1/10], Step [20100/32891], Loss: 0.4230\n","Epoch [1/10], Step [20200/32891], Loss: 0.6038\n","Epoch [1/10], Step [20300/32891], Loss: 0.5575\n","Epoch [1/10], Step [20400/32891], Loss: 0.5974\n","Epoch [1/10], Step [20500/32891], Loss: 0.5915\n","Epoch [1/10], Step [20600/32891], Loss: 0.5240\n","Epoch [1/10], Step [20700/32891], Loss: 0.5460\n","Epoch [1/10], Step [20800/32891], Loss: 0.5246\n","Epoch [1/10], Step [20900/32891], Loss: 0.4942\n","Epoch [1/10], Step [21000/32891], Loss: 0.5347\n","Epoch [1/10], Step [21100/32891], Loss: 0.5702\n","Epoch [1/10], Step [21200/32891], Loss: 0.6271\n","Epoch [1/10], Step [21300/32891], Loss: 0.5524\n","Epoch [1/10], Step [21400/32891], Loss: 0.5485\n","Epoch [1/10], Step [21500/32891], Loss: 0.5556\n","Epoch [1/10], Step [21600/32891], Loss: 0.5038\n","Epoch [1/10], Step [21700/32891], Loss: 0.5872\n","Epoch [1/10], Step [21800/32891], Loss: 0.4848\n","Epoch [1/10], Step [21900/32891], Loss: 0.5287\n","Epoch [1/10], Step [22000/32891], Loss: 0.4532\n","Epoch [1/10], Step [22100/32891], Loss: 0.4759\n","Epoch [1/10], Step [22200/32891], Loss: 0.5721\n","Epoch [1/10], Step [22300/32891], Loss: 0.5696\n","Epoch [1/10], Step [22400/32891], Loss: 0.4901\n","Epoch [1/10], Step [22500/32891], Loss: 0.5276\n","Epoch [1/10], Step [22600/32891], Loss: 0.5245\n","Epoch [1/10], Step [22700/32891], Loss: 0.4701\n","Epoch [1/10], Step [22800/32891], Loss: 0.5361\n","Epoch [1/10], Step [22900/32891], Loss: 0.5375\n","Epoch [1/10], Step [23000/32891], Loss: 0.4656\n","Epoch [1/10], Step [23100/32891], Loss: 0.5513\n","Epoch [1/10], Step [23200/32891], Loss: 0.5230\n","Epoch [1/10], Step [23300/32891], Loss: 0.5452\n","Epoch [1/10], Step [23400/32891], Loss: 0.5719\n","Epoch [1/10], Step [23500/32891], Loss: 0.5204\n","Epoch [1/10], Step [23600/32891], Loss: 0.4557\n","Epoch [1/10], Step [23700/32891], Loss: 0.5302\n","Epoch [1/10], Step [23800/32891], Loss: 0.5233\n","Epoch [1/10], Step [23900/32891], Loss: 0.4605\n","Epoch [1/10], Step [24000/32891], Loss: 0.5304\n","Epoch [1/10], Step [24100/32891], Loss: 0.4865\n","Epoch [1/10], Step [24200/32891], Loss: 0.4947\n","Epoch [1/10], Step [24300/32891], Loss: 0.5156\n","Epoch [1/10], Step [24400/32891], Loss: 0.5096\n","Epoch [1/10], Step [24500/32891], Loss: 0.4851\n","Epoch [1/10], Step [24600/32891], Loss: 0.5595\n","Epoch [1/10], Step [24700/32891], Loss: 0.5184\n","Epoch [1/10], Step [24800/32891], Loss: 0.5108\n","Epoch [1/10], Step [24900/32891], Loss: 0.5171\n","Epoch [1/10], Step [25000/32891], Loss: 0.5204\n","Epoch [1/10], Step [25100/32891], Loss: 0.4779\n","Epoch [1/10], Step [25200/32891], Loss: 0.5244\n","Epoch [1/10], Step [25300/32891], Loss: 0.5910\n","Epoch [1/10], Step [25400/32891], Loss: 0.4634\n","Epoch [1/10], Step [25500/32891], Loss: 0.5414\n","Epoch [1/10], Step [25600/32891], Loss: 0.5978\n","Epoch [1/10], Step [25700/32891], Loss: 0.5291\n","Epoch [1/10], Step [25800/32891], Loss: 0.5838\n","Epoch [1/10], Step [25900/32891], Loss: 0.4908\n","Epoch [1/10], Step [26000/32891], Loss: 0.5387\n","Epoch [1/10], Step [26100/32891], Loss: 0.4752\n","Epoch [1/10], Step [26200/32891], Loss: 0.5102\n","Epoch [1/10], Step [26300/32891], Loss: 0.5977\n","Epoch [1/10], Step [26400/32891], Loss: 0.4812\n","Epoch [1/10], Step [26500/32891], Loss: 0.6153\n","Epoch [1/10], Step [26600/32891], Loss: 0.5966\n","Epoch [1/10], Step [26700/32891], Loss: 0.5150\n","Epoch [1/10], Step [26800/32891], Loss: 0.5744\n","Epoch [1/10], Step [26900/32891], Loss: 0.5267\n","Epoch [1/10], Step [27000/32891], Loss: 0.5150\n","Epoch [1/10], Step [27100/32891], Loss: 0.4915\n","Epoch [1/10], Step [27200/32891], Loss: 0.5653\n","Epoch [1/10], Step [27300/32891], Loss: 0.4709\n","Epoch [1/10], Step [27400/32891], Loss: 0.5593\n","Epoch [1/10], Step [27500/32891], Loss: 0.4798\n","Epoch [1/10], Step [27600/32891], Loss: 0.5359\n","Epoch [1/10], Step [27700/32891], Loss: 0.5060\n","Epoch [1/10], Step [27800/32891], Loss: 0.4589\n","Epoch [1/10], Step [27900/32891], Loss: 0.4730\n","Epoch [1/10], Step [28000/32891], Loss: 0.5508\n","Epoch [1/10], Step [28100/32891], Loss: 0.5374\n","Epoch [1/10], Step [28200/32891], Loss: 0.4014\n","Epoch [1/10], Step [28300/32891], Loss: 0.4599\n","Epoch [1/10], Step [28400/32891], Loss: 0.5968\n","Epoch [1/10], Step [28500/32891], Loss: 0.4937\n","Epoch [1/10], Step [28600/32891], Loss: 0.5685\n","Epoch [1/10], Step [28700/32891], Loss: 0.5133\n","Epoch [1/10], Step [28800/32891], Loss: 0.4038\n","Epoch [1/10], Step [28900/32891], Loss: 0.5050\n","Epoch [1/10], Step [29000/32891], Loss: 0.4985\n","Epoch [1/10], Step [29100/32891], Loss: 0.4865\n","Epoch [1/10], Step [29200/32891], Loss: 0.4730\n","Epoch [1/10], Step [29300/32891], Loss: 0.5815\n","Epoch [1/10], Step [29400/32891], Loss: 0.5308\n","Epoch [1/10], Step [29500/32891], Loss: 0.5673\n","Epoch [1/10], Step [29600/32891], Loss: 0.4256\n","Epoch [1/10], Step [29700/32891], Loss: 0.5489\n","Epoch [1/10], Step [29800/32891], Loss: 0.4626\n","Epoch [1/10], Step [29900/32891], Loss: 0.5484\n","Epoch [1/10], Step [30000/32891], Loss: 0.5041\n","Epoch [1/10], Step [30100/32891], Loss: 0.5261\n","Epoch [1/10], Step [30200/32891], Loss: 0.5428\n","Epoch [1/10], Step [30300/32891], Loss: 0.4898\n","Epoch [1/10], Step [30400/32891], Loss: 0.5157\n","Epoch [1/10], Step [30500/32891], Loss: 0.5012\n","Epoch [1/10], Step [30600/32891], Loss: 0.5657\n","Epoch [1/10], Step [30700/32891], Loss: 0.4759\n","Epoch [1/10], Step [30800/32891], Loss: 0.4905\n","Epoch [1/10], Step [30900/32891], Loss: 0.5280\n","Epoch [1/10], Step [31000/32891], Loss: 0.4969\n","Epoch [1/10], Step [31100/32891], Loss: 0.5341\n","Epoch [1/10], Step [31200/32891], Loss: 0.5366\n","Epoch [1/10], Step [31300/32891], Loss: 0.5829\n","Epoch [1/10], Step [31400/32891], Loss: 0.5400\n","Epoch [1/10], Step [31500/32891], Loss: 0.6185\n","Epoch [1/10], Step [31600/32891], Loss: 0.4673\n","Epoch [1/10], Step [31700/32891], Loss: 0.4800\n","Epoch [1/10], Step [31800/32891], Loss: 0.4431\n","Epoch [1/10], Step [31900/32891], Loss: 0.5239\n","Epoch [1/10], Step [32000/32891], Loss: 0.5700\n","Epoch [1/10], Step [32100/32891], Loss: 0.5140\n","Epoch [1/10], Step [32200/32891], Loss: 0.5283\n","Epoch [1/10], Step [32300/32891], Loss: 0.4630\n","Epoch [1/10], Step [32400/32891], Loss: 0.5952\n","Epoch [1/10], Step [32500/32891], Loss: 0.5214\n","Epoch [1/10], Step [32600/32891], Loss: 0.4673\n","Epoch [1/10], Step [32700/32891], Loss: 0.5732\n","Epoch [1/10], Step [32800/32891], Loss: 0.4803\n","Epoch [2/10], Step [100/32891], Loss: 0.5883\n","Epoch [2/10], Step [200/32891], Loss: 0.4980\n","Epoch [2/10], Step [300/32891], Loss: 0.5618\n","Epoch [2/10], Step [400/32891], Loss: 0.4562\n","Epoch [2/10], Step [500/32891], Loss: 0.5319\n","Epoch [2/10], Step [600/32891], Loss: 0.4611\n","Epoch [2/10], Step [700/32891], Loss: 0.4639\n","Epoch [2/10], Step [800/32891], Loss: 0.4763\n","Epoch [2/10], Step [900/32891], Loss: 0.5623\n","Epoch [2/10], Step [1000/32891], Loss: 0.5522\n","Epoch [2/10], Step [1100/32891], Loss: 0.4899\n","Epoch [2/10], Step [1200/32891], Loss: 0.5542\n","Epoch [2/10], Step [1300/32891], Loss: 0.5220\n","Epoch [2/10], Step [1400/32891], Loss: 0.4449\n","Epoch [2/10], Step [1500/32891], Loss: 0.5050\n","Epoch [2/10], Step [1600/32891], Loss: 0.5063\n","Epoch [2/10], Step [1700/32891], Loss: 0.4751\n","Epoch [2/10], Step [1800/32891], Loss: 0.4405\n","Epoch [2/10], Step [1900/32891], Loss: 0.5701\n","Epoch [2/10], Step [2000/32891], Loss: 0.4487\n","Epoch [2/10], Step [2100/32891], Loss: 0.5330\n","Epoch [2/10], Step [2200/32891], Loss: 0.5172\n","Epoch [2/10], Step [2300/32891], Loss: 0.5184\n","Epoch [2/10], Step [2400/32891], Loss: 0.5048\n","Epoch [2/10], Step [2500/32891], Loss: 0.4957\n","Epoch [2/10], Step [2600/32891], Loss: 0.5756\n","Epoch [2/10], Step [2700/32891], Loss: 0.4712\n","Epoch [2/10], Step [2800/32891], Loss: 0.5130\n","Epoch [2/10], Step [2900/32891], Loss: 0.5229\n","Epoch [2/10], Step [3000/32891], Loss: 0.5305\n","Epoch [2/10], Step [3100/32891], Loss: 0.5254\n","Epoch [2/10], Step [3200/32891], Loss: 0.4593\n","Epoch [2/10], Step [3300/32891], Loss: 0.5023\n","Epoch [2/10], Step [3400/32891], Loss: 0.5249\n","Epoch [2/10], Step [3500/32891], Loss: 0.5337\n","Epoch [2/10], Step [3600/32891], Loss: 0.5483\n","Epoch [2/10], Step [3700/32891], Loss: 0.5136\n","Epoch [2/10], Step [3800/32891], Loss: 0.5701\n","Epoch [2/10], Step [3900/32891], Loss: 0.4932\n","Epoch [2/10], Step [4000/32891], Loss: 0.4423\n","Epoch [2/10], Step [4100/32891], Loss: 0.5090\n","Epoch [2/10], Step [4200/32891], Loss: 0.5432\n","Epoch [2/10], Step [4300/32891], Loss: 0.5653\n","Epoch [2/10], Step [4400/32891], Loss: 0.5497\n","Epoch [2/10], Step [4500/32891], Loss: 0.4785\n","Epoch [2/10], Step [4600/32891], Loss: 0.5512\n","Epoch [2/10], Step [4700/32891], Loss: 0.4881\n","Epoch [2/10], Step [4800/32891], Loss: 0.5479\n","Epoch [2/10], Step [4900/32891], Loss: 0.5240\n","Epoch [2/10], Step [5000/32891], Loss: 0.5820\n","Epoch [2/10], Step [5100/32891], Loss: 0.5438\n","Epoch [2/10], Step [5200/32891], Loss: 0.4880\n","Epoch [2/10], Step [5300/32891], Loss: 0.5582\n","Epoch [2/10], Step [5400/32891], Loss: 0.5664\n","Epoch [2/10], Step [5500/32891], Loss: 0.5862\n","Epoch [2/10], Step [5600/32891], Loss: 0.5281\n","Epoch [2/10], Step [5700/32891], Loss: 0.4592\n","Epoch [2/10], Step [5800/32891], Loss: 0.4858\n","Epoch [2/10], Step [5900/32891], Loss: 0.5446\n","Epoch [2/10], Step [6000/32891], Loss: 0.4760\n","Epoch [2/10], Step [6100/32891], Loss: 0.5729\n","Epoch [2/10], Step [6200/32891], Loss: 0.5387\n","Epoch [2/10], Step [6300/32891], Loss: 0.4459\n","Epoch [2/10], Step [6400/32891], Loss: 0.5188\n","Epoch [2/10], Step [6500/32891], Loss: 0.5019\n","Epoch [2/10], Step [6600/32891], Loss: 0.5059\n","Epoch [2/10], Step [6700/32891], Loss: 0.6494\n","Epoch [2/10], Step [6800/32891], Loss: 0.4408\n","Epoch [2/10], Step [6900/32891], Loss: 0.4837\n","Epoch [2/10], Step [7000/32891], Loss: 0.5351\n","Epoch [2/10], Step [7100/32891], Loss: 0.5992\n","Epoch [2/10], Step [7200/32891], Loss: 0.4629\n","Epoch [2/10], Step [7300/32891], Loss: 0.5158\n","Epoch [2/10], Step [7400/32891], Loss: 0.5656\n","Epoch [2/10], Step [7500/32891], Loss: 0.5271\n","Epoch [2/10], Step [7600/32891], Loss: 0.5019\n","Epoch [2/10], Step [7700/32891], Loss: 0.5057\n","Epoch [2/10], Step [7800/32891], Loss: 0.5070\n","Epoch [2/10], Step [7900/32891], Loss: 0.5415\n","Epoch [2/10], Step [8000/32891], Loss: 0.5206\n","Epoch [2/10], Step [8100/32891], Loss: 0.5132\n","Epoch [2/10], Step [8200/32891], Loss: 0.5202\n","Epoch [2/10], Step [8300/32891], Loss: 0.4962\n","Epoch [2/10], Step [8400/32891], Loss: 0.4580\n","Epoch [2/10], Step [8500/32891], Loss: 0.4912\n","Epoch [2/10], Step [8600/32891], Loss: 0.5577\n","Epoch [2/10], Step [8700/32891], Loss: 0.4236\n","Epoch [2/10], Step [8800/32891], Loss: 0.4694\n","Epoch [2/10], Step [8900/32891], Loss: 0.5238\n","Epoch [2/10], Step [9000/32891], Loss: 0.5289\n","Epoch [2/10], Step [9100/32891], Loss: 0.4800\n","Epoch [2/10], Step [9200/32891], Loss: 0.5304\n","Epoch [2/10], Step [9300/32891], Loss: 0.6192\n","Epoch [2/10], Step [9400/32891], Loss: 0.5309\n","Epoch [2/10], Step [9500/32891], Loss: 0.5581\n","Epoch [2/10], Step [9600/32891], Loss: 0.4916\n","Epoch [2/10], Step [9700/32891], Loss: 0.5435\n","Epoch [2/10], Step [9800/32891], Loss: 0.4646\n","Epoch [2/10], Step [9900/32891], Loss: 0.5599\n","Epoch [2/10], Step [10000/32891], Loss: 0.5750\n","Epoch [2/10], Step [10100/32891], Loss: 0.5476\n","Epoch [2/10], Step [10200/32891], Loss: 0.4564\n","Epoch [2/10], Step [10300/32891], Loss: 0.5988\n","Epoch [2/10], Step [10400/32891], Loss: 0.6065\n","Epoch [2/10], Step [10500/32891], Loss: 0.5205\n","Epoch [2/10], Step [10600/32891], Loss: 0.5087\n","Epoch [2/10], Step [10700/32891], Loss: 0.4817\n","Epoch [2/10], Step [10800/32891], Loss: 0.4681\n","Epoch [2/10], Step [10900/32891], Loss: 0.5370\n","Epoch [2/10], Step [11000/32891], Loss: 0.5371\n","Epoch [2/10], Step [11100/32891], Loss: 0.4454\n","Epoch [2/10], Step [11200/32891], Loss: 0.5360\n","Epoch [2/10], Step [11300/32891], Loss: 0.4537\n","Epoch [2/10], Step [11400/32891], Loss: 0.6533\n","Epoch [2/10], Step [11500/32891], Loss: 0.5037\n","Epoch [2/10], Step [11600/32891], Loss: 0.5146\n","Epoch [2/10], Step [11700/32891], Loss: 0.5042\n","Epoch [2/10], Step [11800/32891], Loss: 0.5049\n","Epoch [2/10], Step [11900/32891], Loss: 0.4810\n","Epoch [2/10], Step [12000/32891], Loss: 0.4527\n","Epoch [2/10], Step [12100/32891], Loss: 0.5598\n","Epoch [2/10], Step [12200/32891], Loss: 0.5943\n","Epoch [2/10], Step [12300/32891], Loss: 0.4189\n","Epoch [2/10], Step [12400/32891], Loss: 0.4753\n","Epoch [2/10], Step [12500/32891], Loss: 0.5517\n","Epoch [2/10], Step [12600/32891], Loss: 0.5119\n","Epoch [2/10], Step [12700/32891], Loss: 0.4643\n","Epoch [2/10], Step [12800/32891], Loss: 0.5230\n","Epoch [2/10], Step [12900/32891], Loss: 0.5458\n","Epoch [2/10], Step [13000/32891], Loss: 0.5560\n","Epoch [2/10], Step [13100/32891], Loss: 0.5552\n","Epoch [2/10], Step [13200/32891], Loss: 0.5411\n","Epoch [2/10], Step [13300/32891], Loss: 0.5953\n","Epoch [2/10], Step [13400/32891], Loss: 0.5982\n","Epoch [2/10], Step [13500/32891], Loss: 0.5124\n","Epoch [2/10], Step [13600/32891], Loss: 0.4869\n","Epoch [2/10], Step [13700/32891], Loss: 0.4848\n","Epoch [2/10], Step [13800/32891], Loss: 0.5652\n","Epoch [2/10], Step [13900/32891], Loss: 0.5078\n","Epoch [2/10], Step [14000/32891], Loss: 0.5084\n","Epoch [2/10], Step [14100/32891], Loss: 0.6277\n","Epoch [2/10], Step [14200/32891], Loss: 0.4578\n","Epoch [2/10], Step [14300/32891], Loss: 0.4547\n","Epoch [2/10], Step [14400/32891], Loss: 0.4706\n","Epoch [2/10], Step [14500/32891], Loss: 0.4995\n","Epoch [2/10], Step [14600/32891], Loss: 0.4147\n","Epoch [2/10], Step [14700/32891], Loss: 0.5200\n","Epoch [2/10], Step [14800/32891], Loss: 0.5296\n","Epoch [2/10], Step [14900/32891], Loss: 0.5891\n","Epoch [2/10], Step [15000/32891], Loss: 0.4583\n","Epoch [2/10], Step [15100/32891], Loss: 0.5978\n","Epoch [2/10], Step [15200/32891], Loss: 0.5176\n","Epoch [2/10], Step [15300/32891], Loss: 0.4522\n","Epoch [2/10], Step [15400/32891], Loss: 0.5157\n","Epoch [2/10], Step [15500/32891], Loss: 0.4868\n","Epoch [2/10], Step [15600/32891], Loss: 0.4654\n","Epoch [2/10], Step [15700/32891], Loss: 0.5137\n","Epoch [2/10], Step [15800/32891], Loss: 0.5011\n","Epoch [2/10], Step [15900/32891], Loss: 0.5109\n","Epoch [2/10], Step [16000/32891], Loss: 0.5432\n","Epoch [2/10], Step [16100/32891], Loss: 0.5752\n","Epoch [2/10], Step [16200/32891], Loss: 0.5633\n","Epoch [2/10], Step [16300/32891], Loss: 0.4773\n","Epoch [2/10], Step [16400/32891], Loss: 0.4962\n","Epoch [2/10], Step [16500/32891], Loss: 0.5012\n","Epoch [2/10], Step [16600/32891], Loss: 0.5436\n","Epoch [2/10], Step [16700/32891], Loss: 0.4839\n","Epoch [2/10], Step [16800/32891], Loss: 0.4916\n","Epoch [2/10], Step [16900/32891], Loss: 0.5408\n","Epoch [2/10], Step [17000/32891], Loss: 0.5603\n","Epoch [2/10], Step [17100/32891], Loss: 0.4999\n","Epoch [2/10], Step [17200/32891], Loss: 0.5674\n","Epoch [2/10], Step [17300/32891], Loss: 0.5616\n","Epoch [2/10], Step [17400/32891], Loss: 0.5446\n","Epoch [2/10], Step [17500/32891], Loss: 0.5606\n","Epoch [2/10], Step [17600/32891], Loss: 0.4895\n","Epoch [2/10], Step [17700/32891], Loss: 0.4682\n","Epoch [2/10], Step [17800/32891], Loss: 0.5315\n","Epoch [2/10], Step [17900/32891], Loss: 0.4904\n","Epoch [2/10], Step [18000/32891], Loss: 0.5239\n","Epoch [2/10], Step [18100/32891], Loss: 0.5210\n","Epoch [2/10], Step [18200/32891], Loss: 0.5301\n","Epoch [2/10], Step [18300/32891], Loss: 0.5836\n","Epoch [2/10], Step [18400/32891], Loss: 0.5783\n","Epoch [2/10], Step [18500/32891], Loss: 0.6088\n","Epoch [2/10], Step [18600/32891], Loss: 0.4814\n","Epoch [2/10], Step [18700/32891], Loss: 0.5419\n","Epoch [2/10], Step [18800/32891], Loss: 0.4810\n","Epoch [2/10], Step [18900/32891], Loss: 0.5517\n","Epoch [2/10], Step [19000/32891], Loss: 0.5200\n","Epoch [2/10], Step [19100/32891], Loss: 0.5053\n","Epoch [2/10], Step [19200/32891], Loss: 0.5147\n","Epoch [2/10], Step [19300/32891], Loss: 0.5593\n","Epoch [2/10], Step [19400/32891], Loss: 0.5085\n","Epoch [2/10], Step [19500/32891], Loss: 0.5534\n","Epoch [2/10], Step [19600/32891], Loss: 0.5137\n","Epoch [2/10], Step [19700/32891], Loss: 0.5514\n","Epoch [2/10], Step [19800/32891], Loss: 0.5443\n","Epoch [2/10], Step [19900/32891], Loss: 0.4928\n","Epoch [2/10], Step [20000/32891], Loss: 0.4968\n","Epoch [2/10], Step [20100/32891], Loss: 0.5034\n","Epoch [2/10], Step [20200/32891], Loss: 0.5072\n","Epoch [2/10], Step [20300/32891], Loss: 0.4943\n","Epoch [2/10], Step [20400/32891], Loss: 0.5041\n","Epoch [2/10], Step [20500/32891], Loss: 0.5333\n","Epoch [2/10], Step [20600/32891], Loss: 0.4428\n","Epoch [2/10], Step [20700/32891], Loss: 0.4969\n","Epoch [2/10], Step [20800/32891], Loss: 0.5253\n","Epoch [2/10], Step [20900/32891], Loss: 0.5491\n","Epoch [2/10], Step [21000/32891], Loss: 0.4796\n","Epoch [2/10], Step [21100/32891], Loss: 0.4801\n","Epoch [2/10], Step [21200/32891], Loss: 0.5616\n","Epoch [2/10], Step [21300/32891], Loss: 0.5334\n","Epoch [2/10], Step [21400/32891], Loss: 0.5586\n","Epoch [2/10], Step [21500/32891], Loss: 0.5950\n","Epoch [2/10], Step [21600/32891], Loss: 0.4321\n","Epoch [2/10], Step [21700/32891], Loss: 0.4858\n","Epoch [2/10], Step [21800/32891], Loss: 0.4553\n","Epoch [2/10], Step [21900/32891], Loss: 0.5335\n","Epoch [2/10], Step [22000/32891], Loss: 0.5654\n","Epoch [2/10], Step [22100/32891], Loss: 0.5141\n","Epoch [2/10], Step [22200/32891], Loss: 0.5420\n","Epoch [2/10], Step [22300/32891], Loss: 0.5417\n","Epoch [2/10], Step [22400/32891], Loss: 0.5357\n","Epoch [2/10], Step [22500/32891], Loss: 0.5410\n","Epoch [2/10], Step [22600/32891], Loss: 0.5418\n","Epoch [2/10], Step [22700/32891], Loss: 0.5184\n","Epoch [2/10], Step [22800/32891], Loss: 0.5332\n","Epoch [2/10], Step [22900/32891], Loss: 0.5421\n","Epoch [2/10], Step [23000/32891], Loss: 0.5304\n","Epoch [2/10], Step [23100/32891], Loss: 0.4894\n","Epoch [2/10], Step [23200/32891], Loss: 0.4602\n","Epoch [2/10], Step [23300/32891], Loss: 0.4526\n","Epoch [2/10], Step [23400/32891], Loss: 0.5257\n","Epoch [2/10], Step [23500/32891], Loss: 0.4884\n","Epoch [2/10], Step [23600/32891], Loss: 0.4843\n","Epoch [2/10], Step [23700/32891], Loss: 0.5667\n","Epoch [2/10], Step [23800/32891], Loss: 0.4863\n","Epoch [2/10], Step [23900/32891], Loss: 0.4700\n","Epoch [2/10], Step [24000/32891], Loss: 0.4170\n","Epoch [2/10], Step [24100/32891], Loss: 0.4595\n","Epoch [2/10], Step [24200/32891], Loss: 0.5411\n","Epoch [2/10], Step [24300/32891], Loss: 0.5006\n","Epoch [2/10], Step [24400/32891], Loss: 0.5126\n","Epoch [2/10], Step [24500/32891], Loss: 0.5727\n","Epoch [2/10], Step [24600/32891], Loss: 0.5193\n","Epoch [2/10], Step [24700/32891], Loss: 0.5683\n","Epoch [2/10], Step [24800/32891], Loss: 0.4452\n","Epoch [2/10], Step [24900/32891], Loss: 0.5034\n","Epoch [2/10], Step [25000/32891], Loss: 0.4956\n","Epoch [2/10], Step [25100/32891], Loss: 0.4532\n","Epoch [2/10], Step [25200/32891], Loss: 0.5668\n","Epoch [2/10], Step [25300/32891], Loss: 0.5092\n","Epoch [2/10], Step [25400/32891], Loss: 0.5352\n","Epoch [2/10], Step [25500/32891], Loss: 0.4426\n","Epoch [2/10], Step [25600/32891], Loss: 0.5960\n","Epoch [2/10], Step [25700/32891], Loss: 0.5325\n","Epoch [2/10], Step [25800/32891], Loss: 0.4251\n","Epoch [2/10], Step [25900/32891], Loss: 0.4414\n","Epoch [2/10], Step [26000/32891], Loss: 0.5696\n","Epoch [2/10], Step [26100/32891], Loss: 0.4727\n","Epoch [2/10], Step [26200/32891], Loss: 0.4958\n","Epoch [2/10], Step [26300/32891], Loss: 0.4747\n","Epoch [2/10], Step [26400/32891], Loss: 0.5303\n","Epoch [2/10], Step [26500/32891], Loss: 0.4954\n","Epoch [2/10], Step [26600/32891], Loss: 0.5395\n","Epoch [2/10], Step [26700/32891], Loss: 0.4888\n","Epoch [2/10], Step [26800/32891], Loss: 0.5027\n","Epoch [2/10], Step [26900/32891], Loss: 0.4736\n","Epoch [2/10], Step [27000/32891], Loss: 0.5335\n","Epoch [2/10], Step [27100/32891], Loss: 0.5139\n","Epoch [2/10], Step [27200/32891], Loss: 0.4500\n","Epoch [2/10], Step [27300/32891], Loss: 0.4835\n","Epoch [2/10], Step [27400/32891], Loss: 0.5371\n","Epoch [2/10], Step [27500/32891], Loss: 0.4727\n","Epoch [2/10], Step [27600/32891], Loss: 0.5103\n","Epoch [2/10], Step [27700/32891], Loss: 0.5753\n","Epoch [2/10], Step [27800/32891], Loss: 0.5210\n","Epoch [2/10], Step [27900/32891], Loss: 0.5588\n","Epoch [2/10], Step [28000/32891], Loss: 0.4616\n","Epoch [2/10], Step [28100/32891], Loss: 0.4890\n","Epoch [2/10], Step [28200/32891], Loss: 0.5174\n","Epoch [2/10], Step [28300/32891], Loss: 0.5261\n","Epoch [2/10], Step [28400/32891], Loss: 0.5656\n","Epoch [2/10], Step [28500/32891], Loss: 0.5388\n","Epoch [2/10], Step [28600/32891], Loss: 0.4603\n","Epoch [2/10], Step [28700/32891], Loss: 0.5077\n","Epoch [2/10], Step [28800/32891], Loss: 0.4426\n","Epoch [2/10], Step [28900/32891], Loss: 0.5564\n","Epoch [2/10], Step [29000/32891], Loss: 0.5063\n","Epoch [2/10], Step [29100/32891], Loss: 0.6352\n","Epoch [2/10], Step [29200/32891], Loss: 0.4828\n","Epoch [2/10], Step [29300/32891], Loss: 0.5433\n","Epoch [2/10], Step [29400/32891], Loss: 0.5623\n","Epoch [2/10], Step [29500/32891], Loss: 0.5298\n","Epoch [2/10], Step [29600/32891], Loss: 0.5066\n","Epoch [2/10], Step [29700/32891], Loss: 0.6285\n","Epoch [2/10], Step [29800/32891], Loss: 0.5649\n","Epoch [2/10], Step [29900/32891], Loss: 0.4689\n","Epoch [2/10], Step [30000/32891], Loss: 0.5294\n","Epoch [2/10], Step [30100/32891], Loss: 0.6024\n","Epoch [2/10], Step [30200/32891], Loss: 0.5362\n","Epoch [2/10], Step [30300/32891], Loss: 0.5115\n","Epoch [2/10], Step [30400/32891], Loss: 0.5364\n","Epoch [2/10], Step [30500/32891], Loss: 0.5023\n","Epoch [2/10], Step [30600/32891], Loss: 0.4953\n","Epoch [2/10], Step [30700/32891], Loss: 0.5533\n","Epoch [2/10], Step [30800/32891], Loss: 0.5159\n","Epoch [2/10], Step [30900/32891], Loss: 0.4974\n","Epoch [2/10], Step [31000/32891], Loss: 0.5163\n","Epoch [2/10], Step [31100/32891], Loss: 0.4744\n","Epoch [2/10], Step [31200/32891], Loss: 0.4699\n","Epoch [2/10], Step [31300/32891], Loss: 0.4683\n","Epoch [2/10], Step [31400/32891], Loss: 0.5244\n","Epoch [2/10], Step [31500/32891], Loss: 0.5142\n","Epoch [2/10], Step [31600/32891], Loss: 0.5177\n","Epoch [2/10], Step [31700/32891], Loss: 0.5225\n","Epoch [2/10], Step [31800/32891], Loss: 0.4660\n","Epoch [2/10], Step [31900/32891], Loss: 0.5306\n","Epoch [2/10], Step [32000/32891], Loss: 0.6289\n","Epoch [2/10], Step [32100/32891], Loss: 0.5712\n","Epoch [2/10], Step [32200/32891], Loss: 0.4951\n","Epoch [2/10], Step [32300/32891], Loss: 0.4775\n","Epoch [2/10], Step [32400/32891], Loss: 0.5196\n","Epoch [2/10], Step [32500/32891], Loss: 0.4713\n","Epoch [2/10], Step [32600/32891], Loss: 0.5028\n","Epoch [2/10], Step [32700/32891], Loss: 0.5215\n","Epoch [2/10], Step [32800/32891], Loss: 0.5373\n","Epoch [3/10], Step [100/32891], Loss: 0.5580\n","Epoch [3/10], Step [200/32891], Loss: 0.5548\n","Epoch [3/10], Step [300/32891], Loss: 0.4274\n","Epoch [3/10], Step [400/32891], Loss: 0.5353\n","Epoch [3/10], Step [500/32891], Loss: 0.4706\n","Epoch [3/10], Step [600/32891], Loss: 0.5145\n","Epoch [3/10], Step [700/32891], Loss: 0.5118\n","Epoch [3/10], Step [800/32891], Loss: 0.5090\n","Epoch [3/10], Step [900/32891], Loss: 0.5219\n","Epoch [3/10], Step [1000/32891], Loss: 0.5305\n","Epoch [3/10], Step [1100/32891], Loss: 0.4498\n","Epoch [3/10], Step [1200/32891], Loss: 0.5787\n","Epoch [3/10], Step [1300/32891], Loss: 0.5161\n","Epoch [3/10], Step [1400/32891], Loss: 0.5454\n","Epoch [3/10], Step [1500/32891], Loss: 0.4716\n","Epoch [3/10], Step [1600/32891], Loss: 0.4826\n","Epoch [3/10], Step [1700/32891], Loss: 0.5446\n","Epoch [3/10], Step [1800/32891], Loss: 0.5430\n","Epoch [3/10], Step [1900/32891], Loss: 0.5072\n","Epoch [3/10], Step [2000/32891], Loss: 0.5371\n","Epoch [3/10], Step [2100/32891], Loss: 0.5529\n","Epoch [3/10], Step [2200/32891], Loss: 0.5509\n","Epoch [3/10], Step [2300/32891], Loss: 0.5737\n","Epoch [3/10], Step [2400/32891], Loss: 0.4882\n","Epoch [3/10], Step [2500/32891], Loss: 0.4616\n","Epoch [3/10], Step [2600/32891], Loss: 0.6276\n","Epoch [3/10], Step [2700/32891], Loss: 0.6466\n","Epoch [3/10], Step [2800/32891], Loss: 0.5122\n","Epoch [3/10], Step [2900/32891], Loss: 0.5756\n","Epoch [3/10], Step [3000/32891], Loss: 0.5173\n","Epoch [3/10], Step [3100/32891], Loss: 0.5382\n","Epoch [3/10], Step [3200/32891], Loss: 0.5266\n","Epoch [3/10], Step [3300/32891], Loss: 0.5215\n","Epoch [3/10], Step [3400/32891], Loss: 0.5162\n","Epoch [3/10], Step [3500/32891], Loss: 0.5515\n","Epoch [3/10], Step [3600/32891], Loss: 0.5000\n","Epoch [3/10], Step [3700/32891], Loss: 0.4776\n","Epoch [3/10], Step [3800/32891], Loss: 0.4899\n","Epoch [3/10], Step [3900/32891], Loss: 0.5250\n","Epoch [3/10], Step [4000/32891], Loss: 0.5220\n","Epoch [3/10], Step [4100/32891], Loss: 0.4477\n","Epoch [3/10], Step [4200/32891], Loss: 0.6019\n","Epoch [3/10], Step [4300/32891], Loss: 0.5584\n","Epoch [3/10], Step [4400/32891], Loss: 0.4923\n","Epoch [3/10], Step [4500/32891], Loss: 0.5460\n","Epoch [3/10], Step [4600/32891], Loss: 0.5594\n","Epoch [3/10], Step [4700/32891], Loss: 0.4242\n","Epoch [3/10], Step [4800/32891], Loss: 0.5218\n","Epoch [3/10], Step [4900/32891], Loss: 0.5457\n","Epoch [3/10], Step [5000/32891], Loss: 0.5744\n","Epoch [3/10], Step [5100/32891], Loss: 0.5058\n","Epoch [3/10], Step [5200/32891], Loss: 0.5168\n","Epoch [3/10], Step [5300/32891], Loss: 0.4780\n","Epoch [3/10], Step [5400/32891], Loss: 0.5909\n","Epoch [3/10], Step [5500/32891], Loss: 0.4868\n","Epoch [3/10], Step [5600/32891], Loss: 0.5023\n","Epoch [3/10], Step [5700/32891], Loss: 0.5461\n","Epoch [3/10], Step [5800/32891], Loss: 0.5014\n","Epoch [3/10], Step [5900/32891], Loss: 0.5326\n","Epoch [3/10], Step [6000/32891], Loss: 0.4373\n","Epoch [3/10], Step [6100/32891], Loss: 0.5496\n","Epoch [3/10], Step [6200/32891], Loss: 0.4206\n","Epoch [3/10], Step [6300/32891], Loss: 0.5879\n","Epoch [3/10], Step [6400/32891], Loss: 0.5518\n","Epoch [3/10], Step [6500/32891], Loss: 0.5261\n","Epoch [3/10], Step [6600/32891], Loss: 0.5619\n","Epoch [3/10], Step [6700/32891], Loss: 0.5322\n","Epoch [3/10], Step [6800/32891], Loss: 0.4894\n","Epoch [3/10], Step [6900/32891], Loss: 0.4519\n","Epoch [3/10], Step [7000/32891], Loss: 0.5655\n","Epoch [3/10], Step [7100/32891], Loss: 0.4740\n","Epoch [3/10], Step [7200/32891], Loss: 0.4757\n","Epoch [3/10], Step [7300/32891], Loss: 0.4762\n","Epoch [3/10], Step [7400/32891], Loss: 0.5148\n","Epoch [3/10], Step [7500/32891], Loss: 0.5037\n","Epoch [3/10], Step [7600/32891], Loss: 0.5325\n","Epoch [3/10], Step [7700/32891], Loss: 0.5316\n","Epoch [3/10], Step [7800/32891], Loss: 0.4940\n","Epoch [3/10], Step [7900/32891], Loss: 0.4558\n","Epoch [3/10], Step [8000/32891], Loss: 0.5752\n","Epoch [3/10], Step [8100/32891], Loss: 0.4583\n","Epoch [3/10], Step [8200/32891], Loss: 0.5236\n","Epoch [3/10], Step [8300/32891], Loss: 0.5606\n","Epoch [3/10], Step [8400/32891], Loss: 0.5156\n","Epoch [3/10], Step [8500/32891], Loss: 0.5104\n","Epoch [3/10], Step [8600/32891], Loss: 0.4814\n","Epoch [3/10], Step [8700/32891], Loss: 0.4186\n","Epoch [3/10], Step [8800/32891], Loss: 0.4978\n","Epoch [3/10], Step [8900/32891], Loss: 0.4605\n","Epoch [3/10], Step [9000/32891], Loss: 0.5574\n","Epoch [3/10], Step [9100/32891], Loss: 0.6000\n","Epoch [3/10], Step [9200/32891], Loss: 0.4798\n","Epoch [3/10], Step [9300/32891], Loss: 0.4824\n","Epoch [3/10], Step [9400/32891], Loss: 0.5290\n","Epoch [3/10], Step [9500/32891], Loss: 0.5335\n","Epoch [3/10], Step [9600/32891], Loss: 0.5472\n","Epoch [3/10], Step [9700/32891], Loss: 0.4671\n","Epoch [3/10], Step [9800/32891], Loss: 0.5667\n","Epoch [3/10], Step [9900/32891], Loss: 0.4950\n","Epoch [3/10], Step [10000/32891], Loss: 0.5080\n","Epoch [3/10], Step [10100/32891], Loss: 0.5271\n","Epoch [3/10], Step [10200/32891], Loss: 0.5370\n","Epoch [3/10], Step [10300/32891], Loss: 0.5647\n","Epoch [3/10], Step [10400/32891], Loss: 0.5073\n","Epoch [3/10], Step [10500/32891], Loss: 0.5449\n","Epoch [3/10], Step [10600/32891], Loss: 0.4955\n","Epoch [3/10], Step [10700/32891], Loss: 0.4647\n","Epoch [3/10], Step [10800/32891], Loss: 0.4783\n","Epoch [3/10], Step [10900/32891], Loss: 0.4347\n","Epoch [3/10], Step [11000/32891], Loss: 0.4840\n","Epoch [3/10], Step [11100/32891], Loss: 0.5519\n","Epoch [3/10], Step [11200/32891], Loss: 0.4167\n","Epoch [3/10], Step [11300/32891], Loss: 0.5088\n","Epoch [3/10], Step [11400/32891], Loss: 0.5136\n","Epoch [3/10], Step [11500/32891], Loss: 0.5549\n","Epoch [3/10], Step [11600/32891], Loss: 0.4768\n","Epoch [3/10], Step [11700/32891], Loss: 0.4392\n","Epoch [3/10], Step [11800/32891], Loss: 0.5869\n","Epoch [3/10], Step [11900/32891], Loss: 0.4667\n","Epoch [3/10], Step [12000/32891], Loss: 0.4720\n","Epoch [3/10], Step [12100/32891], Loss: 0.4859\n","Epoch [3/10], Step [12200/32891], Loss: 0.5881\n","Epoch [3/10], Step [12300/32891], Loss: 0.5467\n","Epoch [3/10], Step [12400/32891], Loss: 0.4776\n","Epoch [3/10], Step [12500/32891], Loss: 0.4760\n","Epoch [3/10], Step [12600/32891], Loss: 0.4058\n","Epoch [3/10], Step [12700/32891], Loss: 0.5330\n","Epoch [3/10], Step [12800/32891], Loss: 0.5786\n","Epoch [3/10], Step [12900/32891], Loss: 0.4599\n","Epoch [3/10], Step [13000/32891], Loss: 0.4934\n","Epoch [3/10], Step [13100/32891], Loss: 0.5485\n","Epoch [3/10], Step [13200/32891], Loss: 0.5058\n","Epoch [3/10], Step [13300/32891], Loss: 0.5114\n","Epoch [3/10], Step [13400/32891], Loss: 0.4324\n","Epoch [3/10], Step [13500/32891], Loss: 0.5362\n","Epoch [3/10], Step [13600/32891], Loss: 0.5147\n","Epoch [3/10], Step [13700/32891], Loss: 0.4898\n","Epoch [3/10], Step [13800/32891], Loss: 0.4515\n","Epoch [3/10], Step [13900/32891], Loss: 0.4922\n","Epoch [3/10], Step [14000/32891], Loss: 0.6216\n","Epoch [3/10], Step [14100/32891], Loss: 0.6099\n","Epoch [3/10], Step [14200/32891], Loss: 0.5410\n","Epoch [3/10], Step [14300/32891], Loss: 0.4898\n","Epoch [3/10], Step [14400/32891], Loss: 0.5561\n","Epoch [3/10], Step [14500/32891], Loss: 0.4684\n","Epoch [3/10], Step [14600/32891], Loss: 0.5497\n","Epoch [3/10], Step [14700/32891], Loss: 0.5360\n","Epoch [3/10], Step [14800/32891], Loss: 0.4799\n","Epoch [3/10], Step [14900/32891], Loss: 0.4878\n","Epoch [3/10], Step [15000/32891], Loss: 0.4674\n","Epoch [3/10], Step [15100/32891], Loss: 0.5350\n","Epoch [3/10], Step [15200/32891], Loss: 0.4634\n","Epoch [3/10], Step [15300/32891], Loss: 0.4930\n","Epoch [3/10], Step [15400/32891], Loss: 0.5501\n","Epoch [3/10], Step [15500/32891], Loss: 0.4867\n","Epoch [3/10], Step [15600/32891], Loss: 0.5063\n","Epoch [3/10], Step [15700/32891], Loss: 0.4288\n","Epoch [3/10], Step [15800/32891], Loss: 0.5536\n","Epoch [3/10], Step [15900/32891], Loss: 0.5975\n","Epoch [3/10], Step [16000/32891], Loss: 0.4332\n","Epoch [3/10], Step [16100/32891], Loss: 0.5458\n","Epoch [3/10], Step [16200/32891], Loss: 0.5492\n","Epoch [3/10], Step [16300/32891], Loss: 0.4801\n","Epoch [3/10], Step [16400/32891], Loss: 0.5594\n","Epoch [3/10], Step [16500/32891], Loss: 0.5065\n","Epoch [3/10], Step [16600/32891], Loss: 0.4592\n","Epoch [3/10], Step [16700/32891], Loss: 0.5414\n","Epoch [3/10], Step [16800/32891], Loss: 0.5714\n","Epoch [3/10], Step [16900/32891], Loss: 0.5075\n","Epoch [3/10], Step [17000/32891], Loss: 0.4477\n","Epoch [3/10], Step [17100/32891], Loss: 0.4698\n","Epoch [3/10], Step [17200/32891], Loss: 0.4472\n","Epoch [3/10], Step [17300/32891], Loss: 0.5599\n","Epoch [3/10], Step [17400/32891], Loss: 0.4967\n","Epoch [3/10], Step [17500/32891], Loss: 0.5042\n","Epoch [3/10], Step [17600/32891], Loss: 0.5038\n","Epoch [3/10], Step [17700/32891], Loss: 0.4792\n","Epoch [3/10], Step [17800/32891], Loss: 0.6417\n","Epoch [3/10], Step [17900/32891], Loss: 0.5743\n","Epoch [3/10], Step [18000/32891], Loss: 0.4669\n","Epoch [3/10], Step [18100/32891], Loss: 0.5124\n","Epoch [3/10], Step [18200/32891], Loss: 0.4852\n","Epoch [3/10], Step [18300/32891], Loss: 0.5158\n","Epoch [3/10], Step [18400/32891], Loss: 0.5342\n","Epoch [3/10], Step [18500/32891], Loss: 0.5199\n","Epoch [3/10], Step [18600/32891], Loss: 0.4427\n","Epoch [3/10], Step [18700/32891], Loss: 0.5477\n","Epoch [3/10], Step [18800/32891], Loss: 0.5536\n","Epoch [3/10], Step [18900/32891], Loss: 0.4672\n","Epoch [3/10], Step [19000/32891], Loss: 0.5116\n","Epoch [3/10], Step [19100/32891], Loss: 0.5111\n","Epoch [3/10], Step [19200/32891], Loss: 0.4787\n","Epoch [3/10], Step [19300/32891], Loss: 0.5472\n","Epoch [3/10], Step [19400/32891], Loss: 0.5492\n","Epoch [3/10], Step [19500/32891], Loss: 0.5016\n","Epoch [3/10], Step [19600/32891], Loss: 0.4673\n","Epoch [3/10], Step [19700/32891], Loss: 0.5004\n","Epoch [3/10], Step [19800/32891], Loss: 0.5064\n","Epoch [3/10], Step [19900/32891], Loss: 0.5686\n","Epoch [3/10], Step [20000/32891], Loss: 0.5619\n","Epoch [3/10], Step [20100/32891], Loss: 0.4938\n","Epoch [3/10], Step [20200/32891], Loss: 0.5781\n","Epoch [3/10], Step [20300/32891], Loss: 0.4642\n","Epoch [3/10], Step [20400/32891], Loss: 0.5107\n","Epoch [3/10], Step [20500/32891], Loss: 0.5054\n","Epoch [3/10], Step [20600/32891], Loss: 0.4044\n","Epoch [3/10], Step [20700/32891], Loss: 0.6124\n","Epoch [3/10], Step [20800/32891], Loss: 0.5006\n","Epoch [3/10], Step [20900/32891], Loss: 0.5348\n","Epoch [3/10], Step [21000/32891], Loss: 0.5593\n","Epoch [3/10], Step [21100/32891], Loss: 0.5342\n","Epoch [3/10], Step [21200/32891], Loss: 0.4665\n","Epoch [3/10], Step [21300/32891], Loss: 0.5299\n","Epoch [3/10], Step [21400/32891], Loss: 0.5099\n","Epoch [3/10], Step [21500/32891], Loss: 0.4929\n","Epoch [3/10], Step [21600/32891], Loss: 0.6070\n","Epoch [3/10], Step [21700/32891], Loss: 0.5130\n","Epoch [3/10], Step [21800/32891], Loss: 0.5540\n","Epoch [3/10], Step [21900/32891], Loss: 0.5801\n","Epoch [3/10], Step [22000/32891], Loss: 0.5599\n","Epoch [3/10], Step [22100/32891], Loss: 0.4231\n","Epoch [3/10], Step [22200/32891], Loss: 0.4473\n","Epoch [3/10], Step [22300/32891], Loss: 0.5218\n","Epoch [3/10], Step [22400/32891], Loss: 0.5290\n","Epoch [3/10], Step [22500/32891], Loss: 0.5529\n","Epoch [3/10], Step [22600/32891], Loss: 0.4751\n","Epoch [3/10], Step [22700/32891], Loss: 0.5140\n","Epoch [3/10], Step [22800/32891], Loss: 0.5500\n","Epoch [3/10], Step [22900/32891], Loss: 0.5718\n","Epoch [3/10], Step [23000/32891], Loss: 0.5648\n","Epoch [3/10], Step [23100/32891], Loss: 0.4642\n","Epoch [3/10], Step [23200/32891], Loss: 0.5638\n","Epoch [3/10], Step [23300/32891], Loss: 0.4784\n","Epoch [3/10], Step [23400/32891], Loss: 0.5460\n","Epoch [3/10], Step [23500/32891], Loss: 0.5711\n","Epoch [3/10], Step [23600/32891], Loss: 0.5709\n","Epoch [3/10], Step [23700/32891], Loss: 0.4487\n","Epoch [3/10], Step [23800/32891], Loss: 0.6016\n","Epoch [3/10], Step [23900/32891], Loss: 0.4847\n","Epoch [3/10], Step [24000/32891], Loss: 0.5121\n","Epoch [3/10], Step [24100/32891], Loss: 0.5310\n","Epoch [3/10], Step [24200/32891], Loss: 0.4823\n","Epoch [3/10], Step [24300/32891], Loss: 0.5414\n","Epoch [3/10], Step [24400/32891], Loss: 0.5573\n","Epoch [3/10], Step [24500/32891], Loss: 0.4810\n","Epoch [3/10], Step [24600/32891], Loss: 0.4402\n","Epoch [3/10], Step [24700/32891], Loss: 0.5241\n","Epoch [3/10], Step [24800/32891], Loss: 0.4783\n","Epoch [3/10], Step [24900/32891], Loss: 0.6130\n","Epoch [3/10], Step [25000/32891], Loss: 0.4831\n","Epoch [3/10], Step [25100/32891], Loss: 0.5327\n","Epoch [3/10], Step [25200/32891], Loss: 0.4733\n","Epoch [3/10], Step [25300/32891], Loss: 0.5524\n","Epoch [3/10], Step [25400/32891], Loss: 0.4723\n","Epoch [3/10], Step [25500/32891], Loss: 0.4770\n","Epoch [3/10], Step [25600/32891], Loss: 0.5478\n","Epoch [3/10], Step [25700/32891], Loss: 0.4917\n","Epoch [3/10], Step [25800/32891], Loss: 0.4772\n","Epoch [3/10], Step [25900/32891], Loss: 0.5416\n","Epoch [3/10], Step [26000/32891], Loss: 0.5026\n","Epoch [3/10], Step [26100/32891], Loss: 0.5623\n","Epoch [3/10], Step [26200/32891], Loss: 0.5250\n","Epoch [3/10], Step [26300/32891], Loss: 0.4532\n","Epoch [3/10], Step [26400/32891], Loss: 0.5699\n","Epoch [3/10], Step [26500/32891], Loss: 0.5061\n","Epoch [3/10], Step [26600/32891], Loss: 0.5560\n","Epoch [3/10], Step [26700/32891], Loss: 0.5626\n","Epoch [3/10], Step [26800/32891], Loss: 0.5625\n","Epoch [3/10], Step [26900/32891], Loss: 0.5332\n","Epoch [3/10], Step [27000/32891], Loss: 0.5295\n","Epoch [3/10], Step [27100/32891], Loss: 0.6447\n","Epoch [3/10], Step [27200/32891], Loss: 0.5010\n","Epoch [3/10], Step [27300/32891], Loss: 0.4814\n","Epoch [3/10], Step [27400/32891], Loss: 0.4897\n","Epoch [3/10], Step [27500/32891], Loss: 0.5018\n","Epoch [3/10], Step [27600/32891], Loss: 0.4655\n","Epoch [3/10], Step [27700/32891], Loss: 0.6016\n","Epoch [3/10], Step [27800/32891], Loss: 0.5428\n","Epoch [3/10], Step [27900/32891], Loss: 0.5179\n","Epoch [3/10], Step [28000/32891], Loss: 0.5027\n","Epoch [3/10], Step [28100/32891], Loss: 0.6347\n","Epoch [3/10], Step [28200/32891], Loss: 0.4352\n","Epoch [3/10], Step [28300/32891], Loss: 0.5613\n","Epoch [3/10], Step [28400/32891], Loss: 0.4536\n","Epoch [3/10], Step [28500/32891], Loss: 0.4818\n","Epoch [3/10], Step [28600/32891], Loss: 0.5630\n","Epoch [3/10], Step [28700/32891], Loss: 0.5389\n","Epoch [3/10], Step [28800/32891], Loss: 0.4687\n","Epoch [3/10], Step [28900/32891], Loss: 0.4891\n","Epoch [3/10], Step [29000/32891], Loss: 0.5435\n","Epoch [3/10], Step [29100/32891], Loss: 0.6338\n","Epoch [3/10], Step [29200/32891], Loss: 0.5402\n","Epoch [3/10], Step [29300/32891], Loss: 0.5703\n","Epoch [3/10], Step [29400/32891], Loss: 0.4333\n","Epoch [3/10], Step [29500/32891], Loss: 0.5174\n","Epoch [3/10], Step [29600/32891], Loss: 0.5941\n","Epoch [3/10], Step [29700/32891], Loss: 0.4927\n","Epoch [3/10], Step [29800/32891], Loss: 0.4705\n","Epoch [3/10], Step [29900/32891], Loss: 0.4814\n","Epoch [3/10], Step [30000/32891], Loss: 0.5878\n","Epoch [3/10], Step [30100/32891], Loss: 0.5205\n","Epoch [3/10], Step [30200/32891], Loss: 0.4881\n","Epoch [3/10], Step [30300/32891], Loss: 0.5250\n","Epoch [3/10], Step [30400/32891], Loss: 0.5830\n","Epoch [3/10], Step [30500/32891], Loss: 0.5504\n","Epoch [3/10], Step [30600/32891], Loss: 0.5322\n","Epoch [3/10], Step [30700/32891], Loss: 0.4649\n","Epoch [3/10], Step [30800/32891], Loss: 0.5203\n","Epoch [3/10], Step [30900/32891], Loss: 0.5021\n","Epoch [3/10], Step [31000/32891], Loss: 0.5542\n","Epoch [3/10], Step [31100/32891], Loss: 0.5298\n","Epoch [3/10], Step [31200/32891], Loss: 0.5689\n","Epoch [3/10], Step [31300/32891], Loss: 0.6397\n","Epoch [3/10], Step [31400/32891], Loss: 0.5759\n","Epoch [3/10], Step [31500/32891], Loss: 0.5599\n","Epoch [3/10], Step [31600/32891], Loss: 0.5063\n","Epoch [3/10], Step [31700/32891], Loss: 0.5207\n","Epoch [3/10], Step [31800/32891], Loss: 0.5755\n","Epoch [3/10], Step [31900/32891], Loss: 0.4996\n","Epoch [3/10], Step [32000/32891], Loss: 0.4499\n","Epoch [3/10], Step [32100/32891], Loss: 0.5644\n","Epoch [3/10], Step [32200/32891], Loss: 0.5315\n","Epoch [3/10], Step [32300/32891], Loss: 0.5102\n","Epoch [3/10], Step [32400/32891], Loss: 0.4787\n","Epoch [3/10], Step [32500/32891], Loss: 0.5889\n","Epoch [3/10], Step [32600/32891], Loss: 0.5194\n","Epoch [3/10], Step [32700/32891], Loss: 0.6101\n","Epoch [3/10], Step [32800/32891], Loss: 0.5073\n","Epoch [4/10], Step [100/32891], Loss: 0.5268\n","Epoch [4/10], Step [200/32891], Loss: 0.5513\n","Epoch [4/10], Step [300/32891], Loss: 0.5187\n","Epoch [4/10], Step [400/32891], Loss: 0.4582\n","Epoch [4/10], Step [500/32891], Loss: 0.5337\n","Epoch [4/10], Step [600/32891], Loss: 0.5231\n","Epoch [4/10], Step [700/32891], Loss: 0.4705\n","Epoch [4/10], Step [800/32891], Loss: 0.4624\n","Epoch [4/10], Step [900/32891], Loss: 0.5339\n","Epoch [4/10], Step [1000/32891], Loss: 0.4571\n","Epoch [4/10], Step [1100/32891], Loss: 0.5415\n","Epoch [4/10], Step [1200/32891], Loss: 0.5240\n","Epoch [4/10], Step [1300/32891], Loss: 0.5196\n","Epoch [4/10], Step [1400/32891], Loss: 0.4975\n","Epoch [4/10], Step [1500/32891], Loss: 0.5056\n","Epoch [4/10], Step [1600/32891], Loss: 0.5329\n","Epoch [4/10], Step [1700/32891], Loss: 0.5258\n","Epoch [4/10], Step [1800/32891], Loss: 0.5034\n","Epoch [4/10], Step [1900/32891], Loss: 0.4846\n","Epoch [4/10], Step [2000/32891], Loss: 0.5128\n","Epoch [4/10], Step [2100/32891], Loss: 0.5086\n","Epoch [4/10], Step [2200/32891], Loss: 0.4795\n","Epoch [4/10], Step [2300/32891], Loss: 0.5620\n","Epoch [4/10], Step [2400/32891], Loss: 0.4299\n","Epoch [4/10], Step [2500/32891], Loss: 0.4619\n","Epoch [4/10], Step [2600/32891], Loss: 0.4615\n","Epoch [4/10], Step [2700/32891], Loss: 0.5140\n","Epoch [4/10], Step [2800/32891], Loss: 0.4722\n","Epoch [4/10], Step [2900/32891], Loss: 0.4793\n","Epoch [4/10], Step [3000/32891], Loss: 0.5168\n","Epoch [4/10], Step [3100/32891], Loss: 0.5585\n","Epoch [4/10], Step [3200/32891], Loss: 0.5182\n","Epoch [4/10], Step [3300/32891], Loss: 0.5029\n","Epoch [4/10], Step [3400/32891], Loss: 0.5117\n","Epoch [4/10], Step [3500/32891], Loss: 0.4224\n","Epoch [4/10], Step [3600/32891], Loss: 0.4508\n","Epoch [4/10], Step [3700/32891], Loss: 0.5581\n","Epoch [4/10], Step [3800/32891], Loss: 0.5082\n","Epoch [4/10], Step [3900/32891], Loss: 0.5419\n","Epoch [4/10], Step [4000/32891], Loss: 0.5256\n","Epoch [4/10], Step [4100/32891], Loss: 0.5825\n","Epoch [4/10], Step [4200/32891], Loss: 0.5612\n","Epoch [4/10], Step [4300/32891], Loss: 0.5184\n","Epoch [4/10], Step [4400/32891], Loss: 0.5211\n","Epoch [4/10], Step [4500/32891], Loss: 0.4696\n","Epoch [4/10], Step [4600/32891], Loss: 0.5042\n","Epoch [4/10], Step [4700/32891], Loss: 0.5522\n","Epoch [4/10], Step [4800/32891], Loss: 0.4927\n","Epoch [4/10], Step [4900/32891], Loss: 0.6242\n","Epoch [4/10], Step [5000/32891], Loss: 0.4922\n","Epoch [4/10], Step [5100/32891], Loss: 0.5510\n","Epoch [4/10], Step [5200/32891], Loss: 0.5070\n","Epoch [4/10], Step [5300/32891], Loss: 0.5558\n","Epoch [4/10], Step [5400/32891], Loss: 0.4977\n","Epoch [4/10], Step [5500/32891], Loss: 0.4577\n","Epoch [4/10], Step [5600/32891], Loss: 0.5006\n","Epoch [4/10], Step [5700/32891], Loss: 0.5105\n","Epoch [4/10], Step [5800/32891], Loss: 0.5812\n","Epoch [4/10], Step [5900/32891], Loss: 0.4201\n","Epoch [4/10], Step [6000/32891], Loss: 0.5219\n","Epoch [4/10], Step [6100/32891], Loss: 0.4573\n","Epoch [4/10], Step [6200/32891], Loss: 0.4833\n","Epoch [4/10], Step [6300/32891], Loss: 0.4967\n","Epoch [4/10], Step [6400/32891], Loss: 0.5550\n","Epoch [4/10], Step [6500/32891], Loss: 0.4989\n","Epoch [4/10], Step [6600/32891], Loss: 0.5926\n","Epoch [4/10], Step [6700/32891], Loss: 0.5537\n","Epoch [4/10], Step [6800/32891], Loss: 0.6068\n","Epoch [4/10], Step [6900/32891], Loss: 0.4927\n","Epoch [4/10], Step [7000/32891], Loss: 0.5252\n","Epoch [4/10], Step [7100/32891], Loss: 0.5240\n","Epoch [4/10], Step [7200/32891], Loss: 0.4358\n","Epoch [4/10], Step [7300/32891], Loss: 0.5196\n","Epoch [4/10], Step [7400/32891], Loss: 0.4485\n","Epoch [4/10], Step [7500/32891], Loss: 0.5868\n","Epoch [4/10], Step [7600/32891], Loss: 0.5887\n","Epoch [4/10], Step [7700/32891], Loss: 0.4527\n","Epoch [4/10], Step [7800/32891], Loss: 0.5509\n","Epoch [4/10], Step [7900/32891], Loss: 0.4550\n","Epoch [4/10], Step [8000/32891], Loss: 0.5619\n","Epoch [4/10], Step [8100/32891], Loss: 0.5672\n","Epoch [4/10], Step [8200/32891], Loss: 0.5455\n","Epoch [4/10], Step [8300/32891], Loss: 0.4282\n","Epoch [4/10], Step [8400/32891], Loss: 0.5545\n","Epoch [4/10], Step [8500/32891], Loss: 0.4915\n","Epoch [4/10], Step [8600/32891], Loss: 0.5592\n","Epoch [4/10], Step [8700/32891], Loss: 0.5488\n","Epoch [4/10], Step [8800/32891], Loss: 0.4400\n","Epoch [4/10], Step [8900/32891], Loss: 0.4742\n","Epoch [4/10], Step [9000/32891], Loss: 0.5027\n","Epoch [4/10], Step [9100/32891], Loss: 0.4571\n","Epoch [4/10], Step [9200/32891], Loss: 0.4573\n","Epoch [4/10], Step [9300/32891], Loss: 0.5036\n","Epoch [4/10], Step [9400/32891], Loss: 0.5518\n","Epoch [4/10], Step [9500/32891], Loss: 0.5507\n","Epoch [4/10], Step [9600/32891], Loss: 0.4882\n","Epoch [4/10], Step [9700/32891], Loss: 0.4751\n","Epoch [4/10], Step [9800/32891], Loss: 0.5506\n","Epoch [4/10], Step [9900/32891], Loss: 0.5174\n","Epoch [4/10], Step [10000/32891], Loss: 0.5599\n","Epoch [4/10], Step [10100/32891], Loss: 0.4839\n","Epoch [4/10], Step [10200/32891], Loss: 0.5365\n","Epoch [4/10], Step [10300/32891], Loss: 0.5821\n","Epoch [4/10], Step [10400/32891], Loss: 0.5118\n","Epoch [4/10], Step [10500/32891], Loss: 0.5368\n","Epoch [4/10], Step [10600/32891], Loss: 0.5737\n","Epoch [4/10], Step [10700/32891], Loss: 0.5032\n","Epoch [4/10], Step [10800/32891], Loss: 0.4898\n","Epoch [4/10], Step [10900/32891], Loss: 0.4831\n","Epoch [4/10], Step [11000/32891], Loss: 0.4917\n","Epoch [4/10], Step [11100/32891], Loss: 0.5609\n","Epoch [4/10], Step [11200/32891], Loss: 0.4857\n","Epoch [4/10], Step [11300/32891], Loss: 0.5373\n","Epoch [4/10], Step [11400/32891], Loss: 0.6090\n","Epoch [4/10], Step [11500/32891], Loss: 0.5007\n","Epoch [4/10], Step [11600/32891], Loss: 0.5768\n","Epoch [4/10], Step [11700/32891], Loss: 0.5884\n","Epoch [4/10], Step [11800/32891], Loss: 0.5173\n","Epoch [4/10], Step [11900/32891], Loss: 0.5276\n","Epoch [4/10], Step [12000/32891], Loss: 0.5909\n","Epoch [4/10], Step [12100/32891], Loss: 0.5590\n","Epoch [4/10], Step [12200/32891], Loss: 0.5309\n","Epoch [4/10], Step [12300/32891], Loss: 0.5002\n","Epoch [4/10], Step [12400/32891], Loss: 0.4498\n","Epoch [4/10], Step [12500/32891], Loss: 0.5162\n","Epoch [4/10], Step [12600/32891], Loss: 0.4355\n","Epoch [4/10], Step [12700/32891], Loss: 0.4619\n","Epoch [4/10], Step [12800/32891], Loss: 0.5254\n","Epoch [4/10], Step [12900/32891], Loss: 0.4496\n","Epoch [4/10], Step [13000/32891], Loss: 0.4035\n","Epoch [4/10], Step [13100/32891], Loss: 0.4953\n","Epoch [4/10], Step [13200/32891], Loss: 0.5197\n","Epoch [4/10], Step [13300/32891], Loss: 0.4968\n","Epoch [4/10], Step [13400/32891], Loss: 0.5254\n","Epoch [4/10], Step [13500/32891], Loss: 0.4980\n","Epoch [4/10], Step [13600/32891], Loss: 0.6177\n","Epoch [4/10], Step [13700/32891], Loss: 0.5428\n","Epoch [4/10], Step [13800/32891], Loss: 0.5505\n","Epoch [4/10], Step [13900/32891], Loss: 0.5569\n","Epoch [4/10], Step [14000/32891], Loss: 0.4992\n","Epoch [4/10], Step [14100/32891], Loss: 0.4978\n","Epoch [4/10], Step [14200/32891], Loss: 0.5003\n","Epoch [4/10], Step [14300/32891], Loss: 0.4107\n","Epoch [4/10], Step [14400/32891], Loss: 0.5212\n","Epoch [4/10], Step [14500/32891], Loss: 0.5354\n","Epoch [4/10], Step [14600/32891], Loss: 0.4245\n","Epoch [4/10], Step [14700/32891], Loss: 0.5221\n","Epoch [4/10], Step [14800/32891], Loss: 0.5181\n","Epoch [4/10], Step [14900/32891], Loss: 0.5436\n","Epoch [4/10], Step [15000/32891], Loss: 0.5762\n","Epoch [4/10], Step [15100/32891], Loss: 0.5476\n","Epoch [4/10], Step [15200/32891], Loss: 0.5463\n","Epoch [4/10], Step [15300/32891], Loss: 0.5555\n","Epoch [4/10], Step [15400/32891], Loss: 0.4377\n","Epoch [4/10], Step [15500/32891], Loss: 0.5290\n","Epoch [4/10], Step [15600/32891], Loss: 0.4772\n","Epoch [4/10], Step [15700/32891], Loss: 0.5281\n","Epoch [4/10], Step [15800/32891], Loss: 0.4690\n","Epoch [4/10], Step [15900/32891], Loss: 0.6263\n","Epoch [4/10], Step [16000/32891], Loss: 0.5132\n","Epoch [4/10], Step [16100/32891], Loss: 0.5415\n","Epoch [4/10], Step [16200/32891], Loss: 0.5032\n","Epoch [4/10], Step [16300/32891], Loss: 0.5583\n","Epoch [4/10], Step [16400/32891], Loss: 0.5536\n","Epoch [4/10], Step [16500/32891], Loss: 0.4922\n","Epoch [4/10], Step [16600/32891], Loss: 0.4666\n","Epoch [4/10], Step [16700/32891], Loss: 0.5145\n","Epoch [4/10], Step [16800/32891], Loss: 0.4568\n","Epoch [4/10], Step [16900/32891], Loss: 0.5200\n","Epoch [4/10], Step [17000/32891], Loss: 0.4819\n","Epoch [4/10], Step [17100/32891], Loss: 0.4994\n","Epoch [4/10], Step [17200/32891], Loss: 0.4885\n","Epoch [4/10], Step [17300/32891], Loss: 0.5090\n","Epoch [4/10], Step [17400/32891], Loss: 0.6231\n","Epoch [4/10], Step [17500/32891], Loss: 0.4061\n","Epoch [4/10], Step [17600/32891], Loss: 0.5624\n","Epoch [4/10], Step [17700/32891], Loss: 0.5214\n","Epoch [4/10], Step [17800/32891], Loss: 0.6059\n","Epoch [4/10], Step [17900/32891], Loss: 0.4828\n","Epoch [4/10], Step [18000/32891], Loss: 0.4786\n","Epoch [4/10], Step [18100/32891], Loss: 0.4890\n","Epoch [4/10], Step [18200/32891], Loss: 0.5130\n","Epoch [4/10], Step [18300/32891], Loss: 0.5024\n","Epoch [4/10], Step [18400/32891], Loss: 0.5256\n","Epoch [4/10], Step [18500/32891], Loss: 0.4610\n","Epoch [4/10], Step [18600/32891], Loss: 0.5438\n","Epoch [4/10], Step [18700/32891], Loss: 0.5189\n","Epoch [4/10], Step [18800/32891], Loss: 0.4278\n","Epoch [4/10], Step [18900/32891], Loss: 0.5020\n","Epoch [4/10], Step [19000/32891], Loss: 0.5411\n","Epoch [4/10], Step [19100/32891], Loss: 0.5095\n","Epoch [4/10], Step [19200/32891], Loss: 0.5811\n","Epoch [4/10], Step [19300/32891], Loss: 0.5561\n","Epoch [4/10], Step [19400/32891], Loss: 0.5630\n","Epoch [4/10], Step [19500/32891], Loss: 0.5833\n","Epoch [4/10], Step [19600/32891], Loss: 0.6401\n","Epoch [4/10], Step [19700/32891], Loss: 0.5560\n","Epoch [4/10], Step [19800/32891], Loss: 0.6045\n","Epoch [4/10], Step [19900/32891], Loss: 0.5089\n","Epoch [4/10], Step [20000/32891], Loss: 0.4888\n","Epoch [4/10], Step [20100/32891], Loss: 0.5379\n","Epoch [4/10], Step [20200/32891], Loss: 0.4496\n","Epoch [4/10], Step [20300/32891], Loss: 0.4385\n","Epoch [4/10], Step [20400/32891], Loss: 0.4578\n","Epoch [4/10], Step [20500/32891], Loss: 0.5720\n","Epoch [4/10], Step [20600/32891], Loss: 0.5989\n","Epoch [4/10], Step [20700/32891], Loss: 0.5319\n","Epoch [4/10], Step [20800/32891], Loss: 0.4330\n","Epoch [4/10], Step [20900/32891], Loss: 0.4861\n","Epoch [4/10], Step [21000/32891], Loss: 0.5403\n","Epoch [4/10], Step [21100/32891], Loss: 0.5276\n","Epoch [4/10], Step [21200/32891], Loss: 0.5725\n","Epoch [4/10], Step [21300/32891], Loss: 0.6335\n","Epoch [4/10], Step [21400/32891], Loss: 0.4112\n","Epoch [4/10], Step [21500/32891], Loss: 0.5888\n","Epoch [4/10], Step [21600/32891], Loss: 0.5906\n","Epoch [4/10], Step [21700/32891], Loss: 0.4646\n","Epoch [4/10], Step [21800/32891], Loss: 0.4841\n","Epoch [4/10], Step [21900/32891], Loss: 0.5819\n","Epoch [4/10], Step [22000/32891], Loss: 0.4946\n","Epoch [4/10], Step [22100/32891], Loss: 0.4961\n","Epoch [4/10], Step [22200/32891], Loss: 0.5793\n","Epoch [4/10], Step [22300/32891], Loss: 0.4339\n","Epoch [4/10], Step [22400/32891], Loss: 0.5284\n","Epoch [4/10], Step [22500/32891], Loss: 0.4505\n","Epoch [4/10], Step [22600/32891], Loss: 0.5357\n","Epoch [4/10], Step [22700/32891], Loss: 0.5391\n","Epoch [4/10], Step [22800/32891], Loss: 0.6762\n","Epoch [4/10], Step [22900/32891], Loss: 0.4686\n","Epoch [4/10], Step [23000/32891], Loss: 0.5781\n","Epoch [4/10], Step [23100/32891], Loss: 0.5310\n","Epoch [4/10], Step [23200/32891], Loss: 0.5377\n","Epoch [4/10], Step [23300/32891], Loss: 0.4266\n","Epoch [4/10], Step [23400/32891], Loss: 0.4973\n","Epoch [4/10], Step [23500/32891], Loss: 0.5875\n","Epoch [4/10], Step [23600/32891], Loss: 0.4994\n","Epoch [4/10], Step [23700/32891], Loss: 0.5001\n","Epoch [4/10], Step [23800/32891], Loss: 0.5325\n","Epoch [4/10], Step [23900/32891], Loss: 0.4589\n","Epoch [4/10], Step [24000/32891], Loss: 0.5753\n","Epoch [4/10], Step [24100/32891], Loss: 0.5173\n","Epoch [4/10], Step [24200/32891], Loss: 0.5017\n","Epoch [4/10], Step [24300/32891], Loss: 0.5121\n","Epoch [4/10], Step [24400/32891], Loss: 0.5062\n","Epoch [4/10], Step [24500/32891], Loss: 0.5883\n","Epoch [4/10], Step [24600/32891], Loss: 0.5284\n","Epoch [4/10], Step [24700/32891], Loss: 0.4435\n","Epoch [4/10], Step [24800/32891], Loss: 0.4631\n","Epoch [4/10], Step [24900/32891], Loss: 0.5370\n","Epoch [4/10], Step [25000/32891], Loss: 0.5913\n","Epoch [4/10], Step [25100/32891], Loss: 0.4995\n","Epoch [4/10], Step [25200/32891], Loss: 0.5304\n","Epoch [4/10], Step [25300/32891], Loss: 0.5006\n","Epoch [4/10], Step [25400/32891], Loss: 0.5430\n","Epoch [4/10], Step [25500/32891], Loss: 0.4897\n","Epoch [4/10], Step [25600/32891], Loss: 0.4611\n","Epoch [4/10], Step [25700/32891], Loss: 0.5321\n","Epoch [4/10], Step [25800/32891], Loss: 0.5648\n","Epoch [4/10], Step [25900/32891], Loss: 0.5188\n","Epoch [4/10], Step [26000/32891], Loss: 0.5262\n","Epoch [4/10], Step [26100/32891], Loss: 0.5201\n","Epoch [4/10], Step [26200/32891], Loss: 0.5052\n","Epoch [4/10], Step [26300/32891], Loss: 0.4796\n","Epoch [4/10], Step [26400/32891], Loss: 0.4483\n","Epoch [4/10], Step [26500/32891], Loss: 0.4885\n","Epoch [4/10], Step [26600/32891], Loss: 0.4559\n","Epoch [4/10], Step [26700/32891], Loss: 0.4842\n","Epoch [4/10], Step [26800/32891], Loss: 0.5162\n","Epoch [4/10], Step [26900/32891], Loss: 0.4981\n","Epoch [4/10], Step [27000/32891], Loss: 0.5124\n","Epoch [4/10], Step [27100/32891], Loss: 0.5814\n","Epoch [4/10], Step [27200/32891], Loss: 0.4990\n","Epoch [4/10], Step [27300/32891], Loss: 0.5043\n","Epoch [4/10], Step [27400/32891], Loss: 0.5162\n","Epoch [4/10], Step [27500/32891], Loss: 0.5094\n","Epoch [4/10], Step [27600/32891], Loss: 0.5539\n","Epoch [4/10], Step [27700/32891], Loss: 0.5236\n","Epoch [4/10], Step [27800/32891], Loss: 0.5316\n","Epoch [4/10], Step [27900/32891], Loss: 0.5155\n","Epoch [4/10], Step [28000/32891], Loss: 0.4775\n","Epoch [4/10], Step [28100/32891], Loss: 0.5072\n","Epoch [4/10], Step [28200/32891], Loss: 0.5406\n","Epoch [4/10], Step [28300/32891], Loss: 0.5046\n","Epoch [4/10], Step [28400/32891], Loss: 0.4815\n","Epoch [4/10], Step [28500/32891], Loss: 0.5704\n","Epoch [4/10], Step [28600/32891], Loss: 0.5723\n","Epoch [4/10], Step [28700/32891], Loss: 0.5260\n","Epoch [4/10], Step [28800/32891], Loss: 0.4521\n","Epoch [4/10], Step [28900/32891], Loss: 0.4544\n","Epoch [4/10], Step [29000/32891], Loss: 0.4949\n","Epoch [4/10], Step [29100/32891], Loss: 0.5852\n","Epoch [4/10], Step [29200/32891], Loss: 0.5157\n","Epoch [4/10], Step [29300/32891], Loss: 0.5818\n","Epoch [4/10], Step [29400/32891], Loss: 0.4879\n","Epoch [4/10], Step [29500/32891], Loss: 0.5466\n","Epoch [4/10], Step [29600/32891], Loss: 0.4640\n","Epoch [4/10], Step [29700/32891], Loss: 0.5353\n","Epoch [4/10], Step [29800/32891], Loss: 0.5428\n","Epoch [4/10], Step [29900/32891], Loss: 0.4784\n","Epoch [4/10], Step [30000/32891], Loss: 0.5251\n","Epoch [4/10], Step [30100/32891], Loss: 0.5174\n","Epoch [4/10], Step [30200/32891], Loss: 0.4543\n","Epoch [4/10], Step [30300/32891], Loss: 0.5536\n","Epoch [4/10], Step [30400/32891], Loss: 0.5457\n","Epoch [4/10], Step [30500/32891], Loss: 0.4748\n","Epoch [4/10], Step [30600/32891], Loss: 0.5186\n","Epoch [4/10], Step [30700/32891], Loss: 0.5297\n","Epoch [4/10], Step [30800/32891], Loss: 0.4705\n","Epoch [4/10], Step [30900/32891], Loss: 0.4859\n","Epoch [4/10], Step [31000/32891], Loss: 0.5202\n","Epoch [4/10], Step [31100/32891], Loss: 0.5140\n","Epoch [4/10], Step [31200/32891], Loss: 0.4990\n","Epoch [4/10], Step [31300/32891], Loss: 0.5236\n","Epoch [4/10], Step [31400/32891], Loss: 0.4591\n","Epoch [4/10], Step [31500/32891], Loss: 0.5075\n","Epoch [4/10], Step [31600/32891], Loss: 0.5566\n","Epoch [4/10], Step [31700/32891], Loss: 0.5011\n","Epoch [4/10], Step [31800/32891], Loss: 0.5637\n","Epoch [4/10], Step [31900/32891], Loss: 0.5934\n","Epoch [4/10], Step [32000/32891], Loss: 0.5601\n","Epoch [4/10], Step [32100/32891], Loss: 0.5621\n","Epoch [4/10], Step [32200/32891], Loss: 0.5170\n","Epoch [4/10], Step [32300/32891], Loss: 0.5033\n","Epoch [4/10], Step [32400/32891], Loss: 0.5370\n","Epoch [4/10], Step [32500/32891], Loss: 0.4621\n","Epoch [4/10], Step [32600/32891], Loss: 0.5470\n","Epoch [4/10], Step [32700/32891], Loss: 0.5178\n","Epoch [4/10], Step [32800/32891], Loss: 0.5357\n","Epoch [5/10], Step [100/32891], Loss: 0.5397\n","Epoch [5/10], Step [200/32891], Loss: 0.5487\n","Epoch [5/10], Step [300/32891], Loss: 0.4928\n","Epoch [5/10], Step [400/32891], Loss: 0.5109\n","Epoch [5/10], Step [500/32891], Loss: 0.6219\n","Epoch [5/10], Step [600/32891], Loss: 0.4992\n","Epoch [5/10], Step [700/32891], Loss: 0.5109\n","Epoch [5/10], Step [800/32891], Loss: 0.5108\n","Epoch [5/10], Step [900/32891], Loss: 0.4916\n","Epoch [5/10], Step [1000/32891], Loss: 0.5030\n","Epoch [5/10], Step [1100/32891], Loss: 0.5454\n","Epoch [5/10], Step [1200/32891], Loss: 0.5027\n","Epoch [5/10], Step [1300/32891], Loss: 0.5043\n","Epoch [5/10], Step [1400/32891], Loss: 0.4950\n","Epoch [5/10], Step [1500/32891], Loss: 0.5065\n","Epoch [5/10], Step [1600/32891], Loss: 0.4891\n","Epoch [5/10], Step [1700/32891], Loss: 0.5384\n","Epoch [5/10], Step [1800/32891], Loss: 0.6168\n","Epoch [5/10], Step [1900/32891], Loss: 0.4760\n","Epoch [5/10], Step [2000/32891], Loss: 0.4962\n","Epoch [5/10], Step [2100/32891], Loss: 0.4869\n","Epoch [5/10], Step [2200/32891], Loss: 0.4995\n","Epoch [5/10], Step [2300/32891], Loss: 0.5646\n","Epoch [5/10], Step [2400/32891], Loss: 0.5491\n","Epoch [5/10], Step [2500/32891], Loss: 0.5481\n","Epoch [5/10], Step [2600/32891], Loss: 0.4932\n","Epoch [5/10], Step [2700/32891], Loss: 0.4975\n","Epoch [5/10], Step [2800/32891], Loss: 0.5207\n","Epoch [5/10], Step [2900/32891], Loss: 0.5695\n","Epoch [5/10], Step [3000/32891], Loss: 0.5144\n","Epoch [5/10], Step [3100/32891], Loss: 0.5607\n","Epoch [5/10], Step [3200/32891], Loss: 0.4407\n","Epoch [5/10], Step [3300/32891], Loss: 0.5701\n","Epoch [5/10], Step [3400/32891], Loss: 0.5063\n","Epoch [5/10], Step [3500/32891], Loss: 0.4891\n","Epoch [5/10], Step [3600/32891], Loss: 0.5030\n","Epoch [5/10], Step [3700/32891], Loss: 0.5148\n","Epoch [5/10], Step [3800/32891], Loss: 0.5568\n","Epoch [5/10], Step [3900/32891], Loss: 0.4637\n","Epoch [5/10], Step [4000/32891], Loss: 0.4724\n","Epoch [5/10], Step [4100/32891], Loss: 0.4831\n","Epoch [5/10], Step [4200/32891], Loss: 0.4782\n","Epoch [5/10], Step [4300/32891], Loss: 0.5135\n","Epoch [5/10], Step [4400/32891], Loss: 0.5523\n","Epoch [5/10], Step [4500/32891], Loss: 0.5192\n","Epoch [5/10], Step [4600/32891], Loss: 0.4789\n","Epoch [5/10], Step [4700/32891], Loss: 0.5563\n","Epoch [5/10], Step [4800/32891], Loss: 0.4735\n","Epoch [5/10], Step [4900/32891], Loss: 0.6290\n","Epoch [5/10], Step [5000/32891], Loss: 0.5017\n","Epoch [5/10], Step [5100/32891], Loss: 0.5229\n","Epoch [5/10], Step [5200/32891], Loss: 0.4615\n","Epoch [5/10], Step [5300/32891], Loss: 0.5348\n","Epoch [5/10], Step [5400/32891], Loss: 0.4352\n","Epoch [5/10], Step [5500/32891], Loss: 0.5561\n","Epoch [5/10], Step [5600/32891], Loss: 0.5326\n","Epoch [5/10], Step [5700/32891], Loss: 0.4927\n","Epoch [5/10], Step [5800/32891], Loss: 0.4798\n","Epoch [5/10], Step [5900/32891], Loss: 0.5500\n","Epoch [5/10], Step [6000/32891], Loss: 0.4800\n","Epoch [5/10], Step [6100/32891], Loss: 0.5554\n","Epoch [5/10], Step [6200/32891], Loss: 0.4854\n","Epoch [5/10], Step [6300/32891], Loss: 0.5473\n","Epoch [5/10], Step [6400/32891], Loss: 0.5019\n","Epoch [5/10], Step [6500/32891], Loss: 0.4932\n","Epoch [5/10], Step [6600/32891], Loss: 0.5115\n","Epoch [5/10], Step [6700/32891], Loss: 0.4153\n","Epoch [5/10], Step [6800/32891], Loss: 0.4977\n","Epoch [5/10], Step [6900/32891], Loss: 0.4620\n","Epoch [5/10], Step [7000/32891], Loss: 0.5411\n","Epoch [5/10], Step [7100/32891], Loss: 0.4453\n","Epoch [5/10], Step [7200/32891], Loss: 0.5571\n","Epoch [5/10], Step [7300/32891], Loss: 0.5466\n","Epoch [5/10], Step [7400/32891], Loss: 0.5386\n","Epoch [5/10], Step [7500/32891], Loss: 0.5521\n","Epoch [5/10], Step [7600/32891], Loss: 0.4797\n","Epoch [5/10], Step [7700/32891], Loss: 0.4424\n","Epoch [5/10], Step [7800/32891], Loss: 0.5152\n","Epoch [5/10], Step [7900/32891], Loss: 0.5251\n","Epoch [5/10], Step [8000/32891], Loss: 0.5527\n","Epoch [5/10], Step [8100/32891], Loss: 0.5736\n","Epoch [5/10], Step [8200/32891], Loss: 0.4748\n","Epoch [5/10], Step [8300/32891], Loss: 0.5020\n","Epoch [5/10], Step [8400/32891], Loss: 0.5487\n","Epoch [5/10], Step [8500/32891], Loss: 0.5983\n","Epoch [5/10], Step [8600/32891], Loss: 0.4371\n","Epoch [5/10], Step [8700/32891], Loss: 0.5536\n","Epoch [5/10], Step [8800/32891], Loss: 0.5298\n","Epoch [5/10], Step [8900/32891], Loss: 0.4722\n","Epoch [5/10], Step [9000/32891], Loss: 0.4867\n","Epoch [5/10], Step [9100/32891], Loss: 0.5861\n","Epoch [5/10], Step [9200/32891], Loss: 0.4708\n","Epoch [5/10], Step [9300/32891], Loss: 0.4887\n","Epoch [5/10], Step [9400/32891], Loss: 0.5033\n","Epoch [5/10], Step [9500/32891], Loss: 0.5887\n","Epoch [5/10], Step [9600/32891], Loss: 0.4933\n","Epoch [5/10], Step [9700/32891], Loss: 0.4998\n","Epoch [5/10], Step [9800/32891], Loss: 0.6250\n","Epoch [5/10], Step [9900/32891], Loss: 0.5248\n","Epoch [5/10], Step [10000/32891], Loss: 0.4991\n","Epoch [5/10], Step [10100/32891], Loss: 0.4889\n","Epoch [5/10], Step [10200/32891], Loss: 0.5209\n","Epoch [5/10], Step [10300/32891], Loss: 0.5337\n","Epoch [5/10], Step [10400/32891], Loss: 0.5127\n","Epoch [5/10], Step [10500/32891], Loss: 0.4704\n","Epoch [5/10], Step [10600/32891], Loss: 0.4959\n","Epoch [5/10], Step [10700/32891], Loss: 0.4563\n","Epoch [5/10], Step [10800/32891], Loss: 0.4922\n","Epoch [5/10], Step [10900/32891], Loss: 0.5194\n","Epoch [5/10], Step [11000/32891], Loss: 0.5098\n","Epoch [5/10], Step [11100/32891], Loss: 0.5363\n","Epoch [5/10], Step [11200/32891], Loss: 0.4768\n","Epoch [5/10], Step [11300/32891], Loss: 0.5071\n","Epoch [5/10], Step [11400/32891], Loss: 0.4986\n","Epoch [5/10], Step [11500/32891], Loss: 0.5630\n","Epoch [5/10], Step [11600/32891], Loss: 0.5452\n","Epoch [5/10], Step [11700/32891], Loss: 0.5926\n","Epoch [5/10], Step [11800/32891], Loss: 0.4893\n","Epoch [5/10], Step [11900/32891], Loss: 0.5010\n","Epoch [5/10], Step [12000/32891], Loss: 0.5499\n","Epoch [5/10], Step [12100/32891], Loss: 0.4482\n","Epoch [5/10], Step [12200/32891], Loss: 0.5352\n","Epoch [5/10], Step [12300/32891], Loss: 0.5645\n","Epoch [5/10], Step [12400/32891], Loss: 0.4653\n","Epoch [5/10], Step [12500/32891], Loss: 0.5036\n","Epoch [5/10], Step [12600/32891], Loss: 0.5482\n","Epoch [5/10], Step [12700/32891], Loss: 0.5335\n","Epoch [5/10], Step [12800/32891], Loss: 0.5194\n","Epoch [5/10], Step [12900/32891], Loss: 0.5455\n","Epoch [5/10], Step [13000/32891], Loss: 0.5481\n","Epoch [5/10], Step [13100/32891], Loss: 0.5787\n","Epoch [5/10], Step [13200/32891], Loss: 0.5080\n","Epoch [5/10], Step [13300/32891], Loss: 0.5228\n","Epoch [5/10], Step [13400/32891], Loss: 0.5134\n","Epoch [5/10], Step [13500/32891], Loss: 0.5997\n","Epoch [5/10], Step [13600/32891], Loss: 0.5007\n","Epoch [5/10], Step [13700/32891], Loss: 0.5729\n","Epoch [5/10], Step [13800/32891], Loss: 0.5799\n","Epoch [5/10], Step [13900/32891], Loss: 0.5478\n","Epoch [5/10], Step [14000/32891], Loss: 0.6157\n","Epoch [5/10], Step [14100/32891], Loss: 0.5632\n","Epoch [5/10], Step [14200/32891], Loss: 0.4719\n","Epoch [5/10], Step [14300/32891], Loss: 0.6044\n","Epoch [5/10], Step [14400/32891], Loss: 0.4886\n","Epoch [5/10], Step [14500/32891], Loss: 0.5058\n","Epoch [5/10], Step [14600/32891], Loss: 0.5023\n","Epoch [5/10], Step [14700/32891], Loss: 0.4676\n","Epoch [5/10], Step [14800/32891], Loss: 0.5614\n","Epoch [5/10], Step [14900/32891], Loss: 0.5105\n","Epoch [5/10], Step [15000/32891], Loss: 0.5796\n","Epoch [5/10], Step [15100/32891], Loss: 0.5572\n","Epoch [5/10], Step [15200/32891], Loss: 0.5520\n","Epoch [5/10], Step [15300/32891], Loss: 0.4737\n","Epoch [5/10], Step [15400/32891], Loss: 0.4948\n","Epoch [5/10], Step [15500/32891], Loss: 0.5145\n","Epoch [5/10], Step [15600/32891], Loss: 0.5223\n","Epoch [5/10], Step [15700/32891], Loss: 0.5390\n","Epoch [5/10], Step [15800/32891], Loss: 0.4965\n","Epoch [5/10], Step [15900/32891], Loss: 0.5922\n","Epoch [5/10], Step [16000/32891], Loss: 0.5656\n","Epoch [5/10], Step [16100/32891], Loss: 0.5665\n","Epoch [5/10], Step [16200/32891], Loss: 0.5410\n","Epoch [5/10], Step [16300/32891], Loss: 0.4884\n","Epoch [5/10], Step [16400/32891], Loss: 0.5159\n","Epoch [5/10], Step [16500/32891], Loss: 0.5024\n","Epoch [5/10], Step [16600/32891], Loss: 0.5092\n","Epoch [5/10], Step [16700/32891], Loss: 0.5257\n","Epoch [5/10], Step [16800/32891], Loss: 0.5149\n","Epoch [5/10], Step [16900/32891], Loss: 0.5640\n","Epoch [5/10], Step [17000/32891], Loss: 0.5140\n","Epoch [5/10], Step [17100/32891], Loss: 0.6240\n","Epoch [5/10], Step [17200/32891], Loss: 0.4665\n","Epoch [5/10], Step [17300/32891], Loss: 0.5287\n","Epoch [5/10], Step [17400/32891], Loss: 0.4981\n","Epoch [5/10], Step [17500/32891], Loss: 0.4344\n","Epoch [5/10], Step [17600/32891], Loss: 0.5695\n","Epoch [5/10], Step [17700/32891], Loss: 0.4675\n","Epoch [5/10], Step [17800/32891], Loss: 0.4950\n","Epoch [5/10], Step [17900/32891], Loss: 0.4873\n","Epoch [5/10], Step [18000/32891], Loss: 0.6298\n","Epoch [5/10], Step [18100/32891], Loss: 0.5644\n","Epoch [5/10], Step [18200/32891], Loss: 0.5001\n","Epoch [5/10], Step [18300/32891], Loss: 0.5680\n","Epoch [5/10], Step [18400/32891], Loss: 0.4788\n","Epoch [5/10], Step [18500/32891], Loss: 0.4961\n","Epoch [5/10], Step [18600/32891], Loss: 0.4713\n","Epoch [5/10], Step [18700/32891], Loss: 0.5263\n","Epoch [5/10], Step [18800/32891], Loss: 0.4382\n","Epoch [5/10], Step [18900/32891], Loss: 0.5081\n","Epoch [5/10], Step [19000/32891], Loss: 0.4950\n","Epoch [5/10], Step [19100/32891], Loss: 0.6060\n","Epoch [5/10], Step [19200/32891], Loss: 0.5132\n","Epoch [5/10], Step [19300/32891], Loss: 0.5068\n","Epoch [5/10], Step [19400/32891], Loss: 0.4480\n","Epoch [5/10], Step [19500/32891], Loss: 0.5479\n","Epoch [5/10], Step [19600/32891], Loss: 0.5273\n","Epoch [5/10], Step [19700/32891], Loss: 0.5240\n","Epoch [5/10], Step [19800/32891], Loss: 0.5432\n","Epoch [5/10], Step [19900/32891], Loss: 0.4555\n","Epoch [5/10], Step [20000/32891], Loss: 0.4876\n","Epoch [5/10], Step [20100/32891], Loss: 0.4994\n","Epoch [5/10], Step [20200/32891], Loss: 0.4648\n","Epoch [5/10], Step [20300/32891], Loss: 0.5302\n","Epoch [5/10], Step [20400/32891], Loss: 0.5022\n","Epoch [5/10], Step [20500/32891], Loss: 0.5877\n","Epoch [5/10], Step [20600/32891], Loss: 0.5097\n","Epoch [5/10], Step [20700/32891], Loss: 0.5036\n","Epoch [5/10], Step [20800/32891], Loss: 0.5272\n","Epoch [5/10], Step [20900/32891], Loss: 0.5588\n","Epoch [5/10], Step [21000/32891], Loss: 0.4112\n","Epoch [5/10], Step [21100/32891], Loss: 0.4860\n","Epoch [5/10], Step [21200/32891], Loss: 0.6031\n","Epoch [5/10], Step [21300/32891], Loss: 0.4477\n","Epoch [5/10], Step [21400/32891], Loss: 0.4896\n","Epoch [5/10], Step [21500/32891], Loss: 0.4934\n","Epoch [5/10], Step [21600/32891], Loss: 0.4553\n","Epoch [5/10], Step [21700/32891], Loss: 0.4562\n","Epoch [5/10], Step [21800/32891], Loss: 0.5322\n","Epoch [5/10], Step [21900/32891], Loss: 0.5496\n","Epoch [5/10], Step [22000/32891], Loss: 0.4671\n","Epoch [5/10], Step [22100/32891], Loss: 0.4868\n","Epoch [5/10], Step [22200/32891], Loss: 0.5255\n","Epoch [5/10], Step [22300/32891], Loss: 0.5909\n","Epoch [5/10], Step [22400/32891], Loss: 0.5344\n","Epoch [5/10], Step [22500/32891], Loss: 0.4927\n","Epoch [5/10], Step [22600/32891], Loss: 0.5834\n","Epoch [5/10], Step [22700/32891], Loss: 0.4696\n","Epoch [5/10], Step [22800/32891], Loss: 0.5135\n","Epoch [5/10], Step [22900/32891], Loss: 0.6150\n","Epoch [5/10], Step [23000/32891], Loss: 0.5517\n","Epoch [5/10], Step [23100/32891], Loss: 0.4354\n","Epoch [5/10], Step [23200/32891], Loss: 0.4666\n","Epoch [5/10], Step [23300/32891], Loss: 0.5281\n","Epoch [5/10], Step [23400/32891], Loss: 0.4684\n","Epoch [5/10], Step [23500/32891], Loss: 0.5526\n","Epoch [5/10], Step [23600/32891], Loss: 0.4481\n","Epoch [5/10], Step [23700/32891], Loss: 0.4808\n","Epoch [5/10], Step [23800/32891], Loss: 0.5642\n","Epoch [5/10], Step [23900/32891], Loss: 0.4999\n","Epoch [5/10], Step [24000/32891], Loss: 0.5205\n","Epoch [5/10], Step [24100/32891], Loss: 0.5467\n","Epoch [5/10], Step [24200/32891], Loss: 0.5114\n","Epoch [5/10], Step [24300/32891], Loss: 0.4695\n","Epoch [5/10], Step [24400/32891], Loss: 0.5236\n","Epoch [5/10], Step [24500/32891], Loss: 0.5170\n","Epoch [5/10], Step [24600/32891], Loss: 0.5113\n","Epoch [5/10], Step [24700/32891], Loss: 0.4850\n","Epoch [5/10], Step [24800/32891], Loss: 0.4801\n","Epoch [5/10], Step [24900/32891], Loss: 0.4621\n","Epoch [5/10], Step [25000/32891], Loss: 0.5938\n","Epoch [5/10], Step [25100/32891], Loss: 0.5140\n","Epoch [5/10], Step [25200/32891], Loss: 0.4498\n","Epoch [5/10], Step [25300/32891], Loss: 0.5177\n","Epoch [5/10], Step [25400/32891], Loss: 0.4382\n","Epoch [5/10], Step [25500/32891], Loss: 0.5337\n","Epoch [5/10], Step [25600/32891], Loss: 0.5545\n","Epoch [5/10], Step [25700/32891], Loss: 0.5948\n","Epoch [5/10], Step [25800/32891], Loss: 0.5191\n","Epoch [5/10], Step [25900/32891], Loss: 0.5383\n","Epoch [5/10], Step [26000/32891], Loss: 0.5133\n","Epoch [5/10], Step [26100/32891], Loss: 0.4708\n","Epoch [5/10], Step [26200/32891], Loss: 0.5137\n","Epoch [5/10], Step [26300/32891], Loss: 0.4900\n","Epoch [5/10], Step [26400/32891], Loss: 0.5063\n","Epoch [5/10], Step [26500/32891], Loss: 0.4862\n","Epoch [5/10], Step [26600/32891], Loss: 0.5650\n","Epoch [5/10], Step [26700/32891], Loss: 0.5403\n","Epoch [5/10], Step [26800/32891], Loss: 0.5202\n","Epoch [5/10], Step [26900/32891], Loss: 0.4953\n","Epoch [5/10], Step [27000/32891], Loss: 0.4642\n","Epoch [5/10], Step [27100/32891], Loss: 0.5470\n","Epoch [5/10], Step [27200/32891], Loss: 0.4896\n","Epoch [5/10], Step [27300/32891], Loss: 0.5007\n","Epoch [5/10], Step [27400/32891], Loss: 0.5562\n","Epoch [5/10], Step [27500/32891], Loss: 0.4383\n","Epoch [5/10], Step [27600/32891], Loss: 0.4955\n","Epoch [5/10], Step [27700/32891], Loss: 0.5093\n","Epoch [5/10], Step [27800/32891], Loss: 0.5687\n","Epoch [5/10], Step [27900/32891], Loss: 0.4769\n","Epoch [5/10], Step [28000/32891], Loss: 0.5360\n","Epoch [5/10], Step [28100/32891], Loss: 0.4459\n","Epoch [5/10], Step [28200/32891], Loss: 0.5117\n","Epoch [5/10], Step [28300/32891], Loss: 0.5767\n","Epoch [5/10], Step [28400/32891], Loss: 0.4981\n","Epoch [5/10], Step [28500/32891], Loss: 0.5300\n","Epoch [5/10], Step [28600/32891], Loss: 0.5377\n","Epoch [5/10], Step [28700/32891], Loss: 0.5237\n","Epoch [5/10], Step [28800/32891], Loss: 0.5035\n","Epoch [5/10], Step [28900/32891], Loss: 0.4558\n","Epoch [5/10], Step [29000/32891], Loss: 0.4942\n","Epoch [5/10], Step [29100/32891], Loss: 0.5100\n","Epoch [5/10], Step [29200/32891], Loss: 0.5724\n","Epoch [5/10], Step [29300/32891], Loss: 0.4876\n","Epoch [5/10], Step [29400/32891], Loss: 0.5295\n","Epoch [5/10], Step [29500/32891], Loss: 0.4983\n","Epoch [5/10], Step [29600/32891], Loss: 0.5522\n","Epoch [5/10], Step [29700/32891], Loss: 0.5541\n","Epoch [5/10], Step [29800/32891], Loss: 0.5381\n","Epoch [5/10], Step [29900/32891], Loss: 0.4803\n","Epoch [5/10], Step [30000/32891], Loss: 0.5255\n","Epoch [5/10], Step [30100/32891], Loss: 0.4963\n","Epoch [5/10], Step [30200/32891], Loss: 0.4645\n","Epoch [5/10], Step [30300/32891], Loss: 0.4668\n","Epoch [5/10], Step [30400/32891], Loss: 0.4984\n","Epoch [5/10], Step [30500/32891], Loss: 0.5238\n","Epoch [5/10], Step [30600/32891], Loss: 0.5803\n","Epoch [5/10], Step [30700/32891], Loss: 0.5400\n","Epoch [5/10], Step [30800/32891], Loss: 0.5076\n","Epoch [5/10], Step [30900/32891], Loss: 0.4873\n","Epoch [5/10], Step [31000/32891], Loss: 0.4710\n","Epoch [5/10], Step [31100/32891], Loss: 0.4908\n","Epoch [5/10], Step [31200/32891], Loss: 0.4607\n","Epoch [5/10], Step [31300/32891], Loss: 0.5452\n","Epoch [5/10], Step [31400/32891], Loss: 0.5886\n","Epoch [5/10], Step [31500/32891], Loss: 0.5777\n","Epoch [5/10], Step [31600/32891], Loss: 0.5410\n","Epoch [5/10], Step [31700/32891], Loss: 0.5659\n","Epoch [5/10], Step [31800/32891], Loss: 0.4776\n","Epoch [5/10], Step [31900/32891], Loss: 0.5205\n","Epoch [5/10], Step [32000/32891], Loss: 0.5393\n","Epoch [5/10], Step [32100/32891], Loss: 0.5713\n","Epoch [5/10], Step [32200/32891], Loss: 0.5344\n","Epoch [5/10], Step [32300/32891], Loss: 0.5386\n","Epoch [5/10], Step [32400/32891], Loss: 0.4998\n","Epoch [5/10], Step [32500/32891], Loss: 0.5062\n","Epoch [5/10], Step [32600/32891], Loss: 0.5002\n","Epoch [5/10], Step [32700/32891], Loss: 0.4956\n","Epoch [5/10], Step [32800/32891], Loss: 0.6177\n","Epoch [6/10], Step [100/32891], Loss: 0.4639\n","Epoch [6/10], Step [200/32891], Loss: 0.5277\n","Epoch [6/10], Step [300/32891], Loss: 0.5186\n","Epoch [6/10], Step [400/32891], Loss: 0.5920\n","Epoch [6/10], Step [500/32891], Loss: 0.4621\n","Epoch [6/10], Step [600/32891], Loss: 0.3956\n","Epoch [6/10], Step [700/32891], Loss: 0.4813\n","Epoch [6/10], Step [800/32891], Loss: 0.4737\n","Epoch [6/10], Step [900/32891], Loss: 0.5446\n","Epoch [6/10], Step [1000/32891], Loss: 0.5424\n","Epoch [6/10], Step [1100/32891], Loss: 0.5661\n","Epoch [6/10], Step [1200/32891], Loss: 0.5801\n","Epoch [6/10], Step [1300/32891], Loss: 0.4519\n","Epoch [6/10], Step [1400/32891], Loss: 0.4935\n","Epoch [6/10], Step [1500/32891], Loss: 0.4600\n","Epoch [6/10], Step [1600/32891], Loss: 0.5265\n","Epoch [6/10], Step [1700/32891], Loss: 0.4562\n","Epoch [6/10], Step [1800/32891], Loss: 0.5601\n","Epoch [6/10], Step [1900/32891], Loss: 0.6210\n","Epoch [6/10], Step [2000/32891], Loss: 0.4366\n","Epoch [6/10], Step [2100/32891], Loss: 0.4668\n","Epoch [6/10], Step [2200/32891], Loss: 0.5576\n","Epoch [6/10], Step [2300/32891], Loss: 0.5006\n","Epoch [6/10], Step [2400/32891], Loss: 0.5236\n","Epoch [6/10], Step [2500/32891], Loss: 0.5716\n","Epoch [6/10], Step [2600/32891], Loss: 0.5133\n","Epoch [6/10], Step [2700/32891], Loss: 0.5155\n","Epoch [6/10], Step [2800/32891], Loss: 0.5357\n","Epoch [6/10], Step [2900/32891], Loss: 0.6199\n","Epoch [6/10], Step [3000/32891], Loss: 0.4512\n","Epoch [6/10], Step [3100/32891], Loss: 0.5214\n","Epoch [6/10], Step [3200/32891], Loss: 0.5037\n","Epoch [6/10], Step [3300/32891], Loss: 0.5609\n","Epoch [6/10], Step [3400/32891], Loss: 0.4809\n","Epoch [6/10], Step [3500/32891], Loss: 0.5402\n","Epoch [6/10], Step [3600/32891], Loss: 0.4820\n","Epoch [6/10], Step [3700/32891], Loss: 0.4697\n","Epoch [6/10], Step [3800/32891], Loss: 0.5108\n","Epoch [6/10], Step [3900/32891], Loss: 0.5348\n","Epoch [6/10], Step [4000/32891], Loss: 0.5565\n","Epoch [6/10], Step [4100/32891], Loss: 0.4806\n","Epoch [6/10], Step [4200/32891], Loss: 0.5430\n","Epoch [6/10], Step [4300/32891], Loss: 0.4928\n","Epoch [6/10], Step [4400/32891], Loss: 0.5223\n","Epoch [6/10], Step [4500/32891], Loss: 0.5321\n","Epoch [6/10], Step [4600/32891], Loss: 0.4464\n","Epoch [6/10], Step [4700/32891], Loss: 0.5230\n","Epoch [6/10], Step [4800/32891], Loss: 0.4987\n","Epoch [6/10], Step [4900/32891], Loss: 0.4377\n","Epoch [6/10], Step [5000/32891], Loss: 0.5991\n","Epoch [6/10], Step [5100/32891], Loss: 0.5436\n","Epoch [6/10], Step [5200/32891], Loss: 0.5427\n","Epoch [6/10], Step [5300/32891], Loss: 0.4965\n","Epoch [6/10], Step [5400/32891], Loss: 0.5562\n","Epoch [6/10], Step [5500/32891], Loss: 0.4324\n","Epoch [6/10], Step [5600/32891], Loss: 0.4622\n","Epoch [6/10], Step [5700/32891], Loss: 0.5277\n","Epoch [6/10], Step [5800/32891], Loss: 0.5309\n","Epoch [6/10], Step [5900/32891], Loss: 0.5876\n","Epoch [6/10], Step [6000/32891], Loss: 0.4927\n","Epoch [6/10], Step [6100/32891], Loss: 0.4992\n","Epoch [6/10], Step [6200/32891], Loss: 0.4989\n","Epoch [6/10], Step [6300/32891], Loss: 0.5354\n","Epoch [6/10], Step [6400/32891], Loss: 0.4721\n","Epoch [6/10], Step [6500/32891], Loss: 0.5066\n","Epoch [6/10], Step [6600/32891], Loss: 0.5018\n","Epoch [6/10], Step [6700/32891], Loss: 0.5155\n","Epoch [6/10], Step [6800/32891], Loss: 0.5334\n","Epoch [6/10], Step [6900/32891], Loss: 0.5263\n","Epoch [6/10], Step [7000/32891], Loss: 0.4629\n","Epoch [6/10], Step [7100/32891], Loss: 0.5099\n","Epoch [6/10], Step [7200/32891], Loss: 0.5194\n","Epoch [6/10], Step [7300/32891], Loss: 0.5127\n","Epoch [6/10], Step [7400/32891], Loss: 0.5608\n","Epoch [6/10], Step [7500/32891], Loss: 0.4174\n","Epoch [6/10], Step [7600/32891], Loss: 0.4027\n","Epoch [6/10], Step [7700/32891], Loss: 0.5164\n","Epoch [6/10], Step [7800/32891], Loss: 0.4806\n","Epoch [6/10], Step [7900/32891], Loss: 0.4338\n","Epoch [6/10], Step [8000/32891], Loss: 0.5228\n","Epoch [6/10], Step [8100/32891], Loss: 0.4986\n","Epoch [6/10], Step [8200/32891], Loss: 0.5060\n","Epoch [6/10], Step [8300/32891], Loss: 0.4871\n","Epoch [6/10], Step [8400/32891], Loss: 0.5123\n","Epoch [6/10], Step [8500/32891], Loss: 0.4903\n","Epoch [6/10], Step [8600/32891], Loss: 0.4926\n","Epoch [6/10], Step [8700/32891], Loss: 0.5580\n","Epoch [6/10], Step [8800/32891], Loss: 0.4911\n","Epoch [6/10], Step [8900/32891], Loss: 0.4863\n","Epoch [6/10], Step [9000/32891], Loss: 0.4886\n","Epoch [6/10], Step [9100/32891], Loss: 0.4636\n","Epoch [6/10], Step [9200/32891], Loss: 0.5288\n","Epoch [6/10], Step [9300/32891], Loss: 0.4398\n","Epoch [6/10], Step [9400/32891], Loss: 0.5185\n","Epoch [6/10], Step [9500/32891], Loss: 0.4812\n","Epoch [6/10], Step [9600/32891], Loss: 0.5211\n","Epoch [6/10], Step [9700/32891], Loss: 0.5034\n","Epoch [6/10], Step [9800/32891], Loss: 0.5338\n","Epoch [6/10], Step [9900/32891], Loss: 0.6179\n","Epoch [6/10], Step [10000/32891], Loss: 0.5116\n","Epoch [6/10], Step [10100/32891], Loss: 0.4324\n","Epoch [6/10], Step [10200/32891], Loss: 0.5010\n","Epoch [6/10], Step [10300/32891], Loss: 0.6044\n","Epoch [6/10], Step [10400/32891], Loss: 0.5114\n","Epoch [6/10], Step [10500/32891], Loss: 0.5634\n","Epoch [6/10], Step [10600/32891], Loss: 0.5115\n","Epoch [6/10], Step [10700/32891], Loss: 0.4748\n","Epoch [6/10], Step [10800/32891], Loss: 0.5433\n","Epoch [6/10], Step [10900/32891], Loss: 0.5227\n","Epoch [6/10], Step [11000/32891], Loss: 0.4734\n","Epoch [6/10], Step [11100/32891], Loss: 0.4719\n","Epoch [6/10], Step [11200/32891], Loss: 0.5491\n","Epoch [6/10], Step [11300/32891], Loss: 0.4788\n","Epoch [6/10], Step [11400/32891], Loss: 0.4456\n","Epoch [6/10], Step [11500/32891], Loss: 0.4245\n","Epoch [6/10], Step [11600/32891], Loss: 0.4693\n","Epoch [6/10], Step [11700/32891], Loss: 0.4963\n","Epoch [6/10], Step [11800/32891], Loss: 0.5609\n","Epoch [6/10], Step [11900/32891], Loss: 0.4987\n","Epoch [6/10], Step [12000/32891], Loss: 0.5413\n","Epoch [6/10], Step [12100/32891], Loss: 0.4735\n","Epoch [6/10], Step [12200/32891], Loss: 0.5814\n","Epoch [6/10], Step [12300/32891], Loss: 0.5475\n","Epoch [6/10], Step [12400/32891], Loss: 0.6055\n","Epoch [6/10], Step [12500/32891], Loss: 0.5492\n","Epoch [6/10], Step [12600/32891], Loss: 0.5145\n","Epoch [6/10], Step [12700/32891], Loss: 0.4817\n","Epoch [6/10], Step [12800/32891], Loss: 0.5984\n","Epoch [6/10], Step [12900/32891], Loss: 0.5275\n","Epoch [6/10], Step [13000/32891], Loss: 0.5429\n","Epoch [6/10], Step [13100/32891], Loss: 0.4755\n","Epoch [6/10], Step [13200/32891], Loss: 0.5501\n","Epoch [6/10], Step [13300/32891], Loss: 0.4960\n","Epoch [6/10], Step [13400/32891], Loss: 0.5590\n","Epoch [6/10], Step [13500/32891], Loss: 0.4701\n","Epoch [6/10], Step [13600/32891], Loss: 0.5589\n","Epoch [6/10], Step [13700/32891], Loss: 0.5093\n","Epoch [6/10], Step [13800/32891], Loss: 0.4447\n","Epoch [6/10], Step [13900/32891], Loss: 0.4110\n","Epoch [6/10], Step [14000/32891], Loss: 0.5614\n","Epoch [6/10], Step [14100/32891], Loss: 0.5357\n","Epoch [6/10], Step [14200/32891], Loss: 0.5277\n","Epoch [6/10], Step [14300/32891], Loss: 0.4364\n","Epoch [6/10], Step [14400/32891], Loss: 0.5038\n","Epoch [6/10], Step [14500/32891], Loss: 0.5162\n","Epoch [6/10], Step [14600/32891], Loss: 0.4929\n","Epoch [6/10], Step [14700/32891], Loss: 0.4745\n","Epoch [6/10], Step [14800/32891], Loss: 0.6216\n","Epoch [6/10], Step [14900/32891], Loss: 0.5605\n","Epoch [6/10], Step [15000/32891], Loss: 0.5399\n","Epoch [6/10], Step [15100/32891], Loss: 0.5233\n","Epoch [6/10], Step [15200/32891], Loss: 0.4857\n","Epoch [6/10], Step [15300/32891], Loss: 0.5298\n","Epoch [6/10], Step [15400/32891], Loss: 0.4579\n","Epoch [6/10], Step [15500/32891], Loss: 0.3970\n","Epoch [6/10], Step [15600/32891], Loss: 0.4654\n","Epoch [6/10], Step [15700/32891], Loss: 0.4840\n","Epoch [6/10], Step [15800/32891], Loss: 0.5342\n","Epoch [6/10], Step [15900/32891], Loss: 0.5218\n","Epoch [6/10], Step [16000/32891], Loss: 0.5390\n","Epoch [6/10], Step [16100/32891], Loss: 0.5228\n","Epoch [6/10], Step [16200/32891], Loss: 0.4653\n","Epoch [6/10], Step [16300/32891], Loss: 0.5257\n","Epoch [6/10], Step [16400/32891], Loss: 0.5153\n","Epoch [6/10], Step [16500/32891], Loss: 0.4544\n","Epoch [6/10], Step [16600/32891], Loss: 0.4452\n","Epoch [6/10], Step [16700/32891], Loss: 0.4883\n","Epoch [6/10], Step [16800/32891], Loss: 0.5882\n","Epoch [6/10], Step [16900/32891], Loss: 0.4254\n","Epoch [6/10], Step [17000/32891], Loss: 0.6024\n","Epoch [6/10], Step [17100/32891], Loss: 0.4591\n","Epoch [6/10], Step [17200/32891], Loss: 0.4859\n","Epoch [6/10], Step [17300/32891], Loss: 0.4894\n","Epoch [6/10], Step [17400/32891], Loss: 0.5183\n","Epoch [6/10], Step [17500/32891], Loss: 0.4959\n","Epoch [6/10], Step [17600/32891], Loss: 0.5225\n","Epoch [6/10], Step [17700/32891], Loss: 0.5151\n","Epoch [6/10], Step [17800/32891], Loss: 0.5162\n","Epoch [6/10], Step [17900/32891], Loss: 0.5004\n","Epoch [6/10], Step [18000/32891], Loss: 0.4672\n","Epoch [6/10], Step [18100/32891], Loss: 0.4886\n","Epoch [6/10], Step [18200/32891], Loss: 0.5374\n","Epoch [6/10], Step [18300/32891], Loss: 0.5412\n","Epoch [6/10], Step [18400/32891], Loss: 0.5042\n","Epoch [6/10], Step [18500/32891], Loss: 0.5408\n","Epoch [6/10], Step [18600/32891], Loss: 0.5040\n","Epoch [6/10], Step [18700/32891], Loss: 0.4955\n","Epoch [6/10], Step [18800/32891], Loss: 0.4915\n","Epoch [6/10], Step [18900/32891], Loss: 0.6033\n","Epoch [6/10], Step [19000/32891], Loss: 0.4681\n","Epoch [6/10], Step [19100/32891], Loss: 0.5427\n","Epoch [6/10], Step [19200/32891], Loss: 0.5466\n","Epoch [6/10], Step [19300/32891], Loss: 0.5393\n","Epoch [6/10], Step [19400/32891], Loss: 0.5242\n","Epoch [6/10], Step [19500/32891], Loss: 0.5435\n","Epoch [6/10], Step [19600/32891], Loss: 0.5499\n","Epoch [6/10], Step [19700/32891], Loss: 0.4577\n","Epoch [6/10], Step [19800/32891], Loss: 0.4582\n","Epoch [6/10], Step [19900/32891], Loss: 0.5015\n","Epoch [6/10], Step [20000/32891], Loss: 0.5142\n","Epoch [6/10], Step [20100/32891], Loss: 0.5138\n","Epoch [6/10], Step [20200/32891], Loss: 0.6155\n","Epoch [6/10], Step [20300/32891], Loss: 0.5206\n","Epoch [6/10], Step [20400/32891], Loss: 0.4925\n","Epoch [6/10], Step [20500/32891], Loss: 0.4324\n","Epoch [6/10], Step [20600/32891], Loss: 0.4878\n","Epoch [6/10], Step [20700/32891], Loss: 0.4990\n","Epoch [6/10], Step [20800/32891], Loss: 0.4318\n","Epoch [6/10], Step [20900/32891], Loss: 0.5636\n","Epoch [6/10], Step [21000/32891], Loss: 0.4915\n","Epoch [6/10], Step [21100/32891], Loss: 0.6239\n","Epoch [6/10], Step [21200/32891], Loss: 0.5375\n","Epoch [6/10], Step [21300/32891], Loss: 0.4733\n","Epoch [6/10], Step [21400/32891], Loss: 0.5013\n","Epoch [6/10], Step [21500/32891], Loss: 0.3811\n","Epoch [6/10], Step [21600/32891], Loss: 0.4845\n","Epoch [6/10], Step [21700/32891], Loss: 0.5539\n","Epoch [6/10], Step [21800/32891], Loss: 0.5482\n","Epoch [6/10], Step [21900/32891], Loss: 0.5296\n","Epoch [6/10], Step [22000/32891], Loss: 0.4633\n","Epoch [6/10], Step [22100/32891], Loss: 0.4465\n","Epoch [6/10], Step [22200/32891], Loss: 0.5549\n","Epoch [6/10], Step [22300/32891], Loss: 0.4581\n","Epoch [6/10], Step [22400/32891], Loss: 0.6235\n","Epoch [6/10], Step [22500/32891], Loss: 0.4262\n","Epoch [6/10], Step [22600/32891], Loss: 0.5294\n","Epoch [6/10], Step [22700/32891], Loss: 0.5180\n","Epoch [6/10], Step [22800/32891], Loss: 0.4956\n","Epoch [6/10], Step [22900/32891], Loss: 0.5056\n","Epoch [6/10], Step [23000/32891], Loss: 0.5202\n","Epoch [6/10], Step [23100/32891], Loss: 0.5676\n","Epoch [6/10], Step [23200/32891], Loss: 0.4883\n","Epoch [6/10], Step [23300/32891], Loss: 0.5818\n","Epoch [6/10], Step [23400/32891], Loss: 0.5193\n","Epoch [6/10], Step [23500/32891], Loss: 0.4815\n","Epoch [6/10], Step [23600/32891], Loss: 0.6101\n","Epoch [6/10], Step [23700/32891], Loss: 0.4922\n","Epoch [6/10], Step [23800/32891], Loss: 0.5195\n","Epoch [6/10], Step [23900/32891], Loss: 0.5257\n","Epoch [6/10], Step [24000/32891], Loss: 0.5090\n","Epoch [6/10], Step [24100/32891], Loss: 0.5556\n","Epoch [6/10], Step [24200/32891], Loss: 0.4772\n","Epoch [6/10], Step [24300/32891], Loss: 0.5905\n","Epoch [6/10], Step [24400/32891], Loss: 0.5167\n","Epoch [6/10], Step [24500/32891], Loss: 0.5147\n","Epoch [6/10], Step [24600/32891], Loss: 0.4189\n","Epoch [6/10], Step [24700/32891], Loss: 0.5392\n","Epoch [6/10], Step [24800/32891], Loss: 0.5171\n","Epoch [6/10], Step [24900/32891], Loss: 0.4815\n","Epoch [6/10], Step [25000/32891], Loss: 0.4822\n","Epoch [6/10], Step [25100/32891], Loss: 0.4792\n","Epoch [6/10], Step [25200/32891], Loss: 0.5170\n","Epoch [6/10], Step [25300/32891], Loss: 0.5232\n","Epoch [6/10], Step [25400/32891], Loss: 0.5268\n","Epoch [6/10], Step [25500/32891], Loss: 0.4086\n","Epoch [6/10], Step [25600/32891], Loss: 0.5459\n","Epoch [6/10], Step [25700/32891], Loss: 0.4905\n","Epoch [6/10], Step [25800/32891], Loss: 0.5116\n","Epoch [6/10], Step [25900/32891], Loss: 0.4330\n","Epoch [6/10], Step [26000/32891], Loss: 0.4773\n","Epoch [6/10], Step [26100/32891], Loss: 0.5842\n","Epoch [6/10], Step [26200/32891], Loss: 0.4816\n","Epoch [6/10], Step [26300/32891], Loss: 0.5349\n","Epoch [6/10], Step [26400/32891], Loss: 0.5577\n","Epoch [6/10], Step [26500/32891], Loss: 0.5004\n","Epoch [6/10], Step [26600/32891], Loss: 0.4539\n","Epoch [6/10], Step [26700/32891], Loss: 0.5223\n","Epoch [6/10], Step [26800/32891], Loss: 0.5224\n","Epoch [6/10], Step [26900/32891], Loss: 0.5371\n","Epoch [6/10], Step [27000/32891], Loss: 0.5180\n","Epoch [6/10], Step [27100/32891], Loss: 0.5106\n","Epoch [6/10], Step [27200/32891], Loss: 0.5421\n","Epoch [6/10], Step [27300/32891], Loss: 0.5605\n","Epoch [6/10], Step [27400/32891], Loss: 0.5237\n","Epoch [6/10], Step [27500/32891], Loss: 0.4658\n","Epoch [6/10], Step [27600/32891], Loss: 0.4786\n","Epoch [6/10], Step [27700/32891], Loss: 0.6081\n","Epoch [6/10], Step [27800/32891], Loss: 0.5477\n","Epoch [6/10], Step [27900/32891], Loss: 0.5637\n","Epoch [6/10], Step [28000/32891], Loss: 0.5264\n","Epoch [6/10], Step [28100/32891], Loss: 0.5692\n","Epoch [6/10], Step [28200/32891], Loss: 0.4656\n","Epoch [6/10], Step [28300/32891], Loss: 0.5303\n","Epoch [6/10], Step [28400/32891], Loss: 0.5288\n","Epoch [6/10], Step [28500/32891], Loss: 0.4594\n","Epoch [6/10], Step [28600/32891], Loss: 0.5224\n","Epoch [6/10], Step [28700/32891], Loss: 0.5018\n","Epoch [6/10], Step [28800/32891], Loss: 0.4792\n","Epoch [6/10], Step [28900/32891], Loss: 0.4406\n","Epoch [6/10], Step [29000/32891], Loss: 0.5800\n","Epoch [6/10], Step [29100/32891], Loss: 0.5255\n","Epoch [6/10], Step [29200/32891], Loss: 0.4770\n","Epoch [6/10], Step [29300/32891], Loss: 0.5300\n","Epoch [6/10], Step [29400/32891], Loss: 0.5622\n","Epoch [6/10], Step [29500/32891], Loss: 0.4539\n","Epoch [6/10], Step [29600/32891], Loss: 0.4848\n","Epoch [6/10], Step [29700/32891], Loss: 0.5488\n","Epoch [6/10], Step [29800/32891], Loss: 0.5664\n","Epoch [6/10], Step [29900/32891], Loss: 0.5372\n","Epoch [6/10], Step [30000/32891], Loss: 0.4604\n","Epoch [6/10], Step [30100/32891], Loss: 0.5218\n","Epoch [6/10], Step [30200/32891], Loss: 0.5553\n","Epoch [6/10], Step [30300/32891], Loss: 0.5510\n","Epoch [6/10], Step [30400/32891], Loss: 0.5044\n","Epoch [6/10], Step [30500/32891], Loss: 0.5132\n","Epoch [6/10], Step [30600/32891], Loss: 0.4624\n","Epoch [6/10], Step [30700/32891], Loss: 0.4775\n","Epoch [6/10], Step [30800/32891], Loss: 0.5756\n","Epoch [6/10], Step [30900/32891], Loss: 0.5450\n","Epoch [6/10], Step [31000/32891], Loss: 0.5253\n","Epoch [6/10], Step [31100/32891], Loss: 0.5745\n","Epoch [6/10], Step [31200/32891], Loss: 0.5965\n","Epoch [6/10], Step [31300/32891], Loss: 0.4656\n","Epoch [6/10], Step [31400/32891], Loss: 0.6215\n","Epoch [6/10], Step [31500/32891], Loss: 0.5564\n","Epoch [6/10], Step [31600/32891], Loss: 0.5333\n","Epoch [6/10], Step [31700/32891], Loss: 0.5573\n","Epoch [6/10], Step [31800/32891], Loss: 0.5522\n","Epoch [6/10], Step [31900/32891], Loss: 0.4806\n","Epoch [6/10], Step [32000/32891], Loss: 0.4613\n","Epoch [6/10], Step [32100/32891], Loss: 0.5187\n","Epoch [6/10], Step [32200/32891], Loss: 0.4326\n","Epoch [6/10], Step [32300/32891], Loss: 0.5264\n","Epoch [6/10], Step [32400/32891], Loss: 0.6057\n","Epoch [6/10], Step [32500/32891], Loss: 0.4995\n","Epoch [6/10], Step [32600/32891], Loss: 0.4932\n","Epoch [6/10], Step [32700/32891], Loss: 0.5126\n","Epoch [6/10], Step [32800/32891], Loss: 0.5540\n","Epoch [7/10], Step [100/32891], Loss: 0.5582\n","Epoch [7/10], Step [200/32891], Loss: 0.5060\n","Epoch [7/10], Step [300/32891], Loss: 0.4774\n","Epoch [7/10], Step [400/32891], Loss: 0.4241\n","Epoch [7/10], Step [500/32891], Loss: 0.5264\n","Epoch [7/10], Step [600/32891], Loss: 0.5138\n","Epoch [7/10], Step [700/32891], Loss: 0.4867\n","Epoch [7/10], Step [800/32891], Loss: 0.5691\n","Epoch [7/10], Step [900/32891], Loss: 0.4569\n","Epoch [7/10], Step [1000/32891], Loss: 0.4688\n","Epoch [7/10], Step [1100/32891], Loss: 0.5098\n","Epoch [7/10], Step [1200/32891], Loss: 0.5083\n","Epoch [7/10], Step [1300/32891], Loss: 0.5456\n","Epoch [7/10], Step [1400/32891], Loss: 0.5139\n","Epoch [7/10], Step [1500/32891], Loss: 0.5693\n","Epoch [7/10], Step [1600/32891], Loss: 0.5037\n","Epoch [7/10], Step [1700/32891], Loss: 0.4808\n","Epoch [7/10], Step [1800/32891], Loss: 0.5793\n","Epoch [7/10], Step [1900/32891], Loss: 0.5709\n","Epoch [7/10], Step [2000/32891], Loss: 0.4845\n","Epoch [7/10], Step [2100/32891], Loss: 0.4566\n","Epoch [7/10], Step [2200/32891], Loss: 0.5152\n","Epoch [7/10], Step [2300/32891], Loss: 0.5022\n","Epoch [7/10], Step [2400/32891], Loss: 0.5222\n","Epoch [7/10], Step [2500/32891], Loss: 0.4382\n","Epoch [7/10], Step [2600/32891], Loss: 0.4177\n","Epoch [7/10], Step [2700/32891], Loss: 0.5604\n","Epoch [7/10], Step [2800/32891], Loss: 0.6127\n","Epoch [7/10], Step [2900/32891], Loss: 0.6200\n","Epoch [7/10], Step [3000/32891], Loss: 0.5450\n","Epoch [7/10], Step [3100/32891], Loss: 0.4657\n","Epoch [7/10], Step [3200/32891], Loss: 0.5454\n","Epoch [7/10], Step [3300/32891], Loss: 0.4320\n","Epoch [7/10], Step [3400/32891], Loss: 0.4925\n","Epoch [7/10], Step [3500/32891], Loss: 0.5395\n","Epoch [7/10], Step [3600/32891], Loss: 0.4727\n","Epoch [7/10], Step [3700/32891], Loss: 0.5971\n","Epoch [7/10], Step [3800/32891], Loss: 0.4395\n","Epoch [7/10], Step [3900/32891], Loss: 0.4973\n","Epoch [7/10], Step [4000/32891], Loss: 0.5205\n","Epoch [7/10], Step [4100/32891], Loss: 0.4563\n","Epoch [7/10], Step [4200/32891], Loss: 0.5368\n","Epoch [7/10], Step [4300/32891], Loss: 0.5613\n","Epoch [7/10], Step [4400/32891], Loss: 0.5423\n","Epoch [7/10], Step [4500/32891], Loss: 0.5171\n","Epoch [7/10], Step [4600/32891], Loss: 0.5161\n","Epoch [7/10], Step [4700/32891], Loss: 0.4486\n","Epoch [7/10], Step [4800/32891], Loss: 0.4714\n","Epoch [7/10], Step [4900/32891], Loss: 0.5269\n","Epoch [7/10], Step [5000/32891], Loss: 0.4363\n","Epoch [7/10], Step [5100/32891], Loss: 0.4983\n","Epoch [7/10], Step [5200/32891], Loss: 0.4336\n","Epoch [7/10], Step [5300/32891], Loss: 0.4745\n","Epoch [7/10], Step [5400/32891], Loss: 0.5312\n","Epoch [7/10], Step [5500/32891], Loss: 0.4571\n","Epoch [7/10], Step [5600/32891], Loss: 0.5075\n","Epoch [7/10], Step [5700/32891], Loss: 0.6093\n","Epoch [7/10], Step [5800/32891], Loss: 0.4808\n","Epoch [7/10], Step [5900/32891], Loss: 0.5014\n","Epoch [7/10], Step [6000/32891], Loss: 0.5514\n","Epoch [7/10], Step [6100/32891], Loss: 0.4248\n","Epoch [7/10], Step [6200/32891], Loss: 0.5494\n","Epoch [7/10], Step [6300/32891], Loss: 0.5593\n","Epoch [7/10], Step [6400/32891], Loss: 0.4471\n","Epoch [7/10], Step [6500/32891], Loss: 0.5946\n","Epoch [7/10], Step [6600/32891], Loss: 0.4587\n","Epoch [7/10], Step [6700/32891], Loss: 0.5054\n","Epoch [7/10], Step [6800/32891], Loss: 0.3819\n","Epoch [7/10], Step [6900/32891], Loss: 0.5198\n","Epoch [7/10], Step [7000/32891], Loss: 0.4770\n","Epoch [7/10], Step [7100/32891], Loss: 0.4981\n","Epoch [7/10], Step [7200/32891], Loss: 0.5633\n","Epoch [7/10], Step [7300/32891], Loss: 0.5485\n","Epoch [7/10], Step [7400/32891], Loss: 0.5225\n","Epoch [7/10], Step [7500/32891], Loss: 0.5241\n","Epoch [7/10], Step [7600/32891], Loss: 0.4796\n","Epoch [7/10], Step [7700/32891], Loss: 0.5464\n","Epoch [7/10], Step [7800/32891], Loss: 0.5168\n","Epoch [7/10], Step [7900/32891], Loss: 0.4766\n","Epoch [7/10], Step [8000/32891], Loss: 0.5197\n","Epoch [7/10], Step [8100/32891], Loss: 0.4698\n","Epoch [7/10], Step [8200/32891], Loss: 0.5679\n","Epoch [7/10], Step [8300/32891], Loss: 0.5641\n","Epoch [7/10], Step [8400/32891], Loss: 0.5384\n","Epoch [7/10], Step [8500/32891], Loss: 0.4767\n","Epoch [7/10], Step [8600/32891], Loss: 0.5351\n","Epoch [7/10], Step [8700/32891], Loss: 0.5380\n","Epoch [7/10], Step [8800/32891], Loss: 0.5250\n","Epoch [7/10], Step [8900/32891], Loss: 0.5058\n","Epoch [7/10], Step [9000/32891], Loss: 0.4985\n","Epoch [7/10], Step [9100/32891], Loss: 0.5257\n","Epoch [7/10], Step [9200/32891], Loss: 0.5331\n","Epoch [7/10], Step [9300/32891], Loss: 0.5560\n","Epoch [7/10], Step [9400/32891], Loss: 0.5173\n","Epoch [7/10], Step [9500/32891], Loss: 0.5208\n","Epoch [7/10], Step [9600/32891], Loss: 0.4586\n","Epoch [7/10], Step [9700/32891], Loss: 0.5988\n","Epoch [7/10], Step [9800/32891], Loss: 0.5074\n","Epoch [7/10], Step [9900/32891], Loss: 0.4711\n","Epoch [7/10], Step [10000/32891], Loss: 0.5379\n","Epoch [7/10], Step [10100/32891], Loss: 0.5233\n","Epoch [7/10], Step [10200/32891], Loss: 0.4685\n","Epoch [7/10], Step [10300/32891], Loss: 0.5012\n","Epoch [7/10], Step [10400/32891], Loss: 0.4331\n","Epoch [7/10], Step [10500/32891], Loss: 0.4878\n","Epoch [7/10], Step [10600/32891], Loss: 0.5704\n","Epoch [7/10], Step [10700/32891], Loss: 0.4887\n","Epoch [7/10], Step [10800/32891], Loss: 0.5021\n","Epoch [7/10], Step [10900/32891], Loss: 0.5126\n","Epoch [7/10], Step [11000/32891], Loss: 0.5280\n","Epoch [7/10], Step [11100/32891], Loss: 0.4966\n","Epoch [7/10], Step [11200/32891], Loss: 0.4991\n","Epoch [7/10], Step [11300/32891], Loss: 0.4888\n","Epoch [7/10], Step [11400/32891], Loss: 0.4767\n","Epoch [7/10], Step [11500/32891], Loss: 0.4943\n","Epoch [7/10], Step [11600/32891], Loss: 0.5061\n","Epoch [7/10], Step [11700/32891], Loss: 0.4292\n","Epoch [7/10], Step [11800/32891], Loss: 0.4866\n","Epoch [7/10], Step [11900/32891], Loss: 0.4759\n","Epoch [7/10], Step [12000/32891], Loss: 0.5456\n","Epoch [7/10], Step [12100/32891], Loss: 0.5731\n","Epoch [7/10], Step [12200/32891], Loss: 0.5077\n","Epoch [7/10], Step [12300/32891], Loss: 0.4538\n","Epoch [7/10], Step [12400/32891], Loss: 0.5020\n","Epoch [7/10], Step [12500/32891], Loss: 0.4795\n","Epoch [7/10], Step [12600/32891], Loss: 0.5387\n","Epoch [7/10], Step [12700/32891], Loss: 0.4852\n","Epoch [7/10], Step [12800/32891], Loss: 0.5312\n","Epoch [7/10], Step [12900/32891], Loss: 0.5051\n","Epoch [7/10], Step [13000/32891], Loss: 0.4510\n","Epoch [7/10], Step [13100/32891], Loss: 0.5856\n","Epoch [7/10], Step [13200/32891], Loss: 0.4696\n","Epoch [7/10], Step [13300/32891], Loss: 0.5021\n","Epoch [7/10], Step [13400/32891], Loss: 0.5499\n","Epoch [7/10], Step [13500/32891], Loss: 0.4745\n","Epoch [7/10], Step [13600/32891], Loss: 0.5075\n","Epoch [7/10], Step [13700/32891], Loss: 0.5118\n","Epoch [7/10], Step [13800/32891], Loss: 0.5849\n","Epoch [7/10], Step [13900/32891], Loss: 0.4446\n","Epoch [7/10], Step [14000/32891], Loss: 0.5436\n","Epoch [7/10], Step [14100/32891], Loss: 0.5028\n","Epoch [7/10], Step [14200/32891], Loss: 0.4564\n","Epoch [7/10], Step [14300/32891], Loss: 0.5324\n","Epoch [7/10], Step [14400/32891], Loss: 0.5393\n","Epoch [7/10], Step [14500/32891], Loss: 0.4776\n","Epoch [7/10], Step [14600/32891], Loss: 0.4371\n","Epoch [7/10], Step [14700/32891], Loss: 0.5249\n","Epoch [7/10], Step [14800/32891], Loss: 0.4667\n","Epoch [7/10], Step [14900/32891], Loss: 0.4482\n","Epoch [7/10], Step [15000/32891], Loss: 0.3959\n","Epoch [7/10], Step [15100/32891], Loss: 0.4917\n","Epoch [7/10], Step [15200/32891], Loss: 0.5216\n","Epoch [7/10], Step [15300/32891], Loss: 0.4540\n","Epoch [7/10], Step [15400/32891], Loss: 0.5402\n","Epoch [7/10], Step [15500/32891], Loss: 0.4702\n","Epoch [7/10], Step [15600/32891], Loss: 0.5041\n","Epoch [7/10], Step [15700/32891], Loss: 0.4226\n","Epoch [7/10], Step [15800/32891], Loss: 0.4851\n","Epoch [7/10], Step [15900/32891], Loss: 0.5150\n","Epoch [7/10], Step [16000/32891], Loss: 0.5242\n","Epoch [7/10], Step [16100/32891], Loss: 0.4928\n","Epoch [7/10], Step [16200/32891], Loss: 0.4801\n","Epoch [7/10], Step [16300/32891], Loss: 0.5073\n","Epoch [7/10], Step [16400/32891], Loss: 0.4629\n","Epoch [7/10], Step [16500/32891], Loss: 0.5288\n","Epoch [7/10], Step [16600/32891], Loss: 0.5023\n","Epoch [7/10], Step [16700/32891], Loss: 0.4392\n","Epoch [7/10], Step [16800/32891], Loss: 0.5126\n","Epoch [7/10], Step [16900/32891], Loss: 0.4591\n","Epoch [7/10], Step [17000/32891], Loss: 0.5411\n","Epoch [7/10], Step [17100/32891], Loss: 0.5842\n","Epoch [7/10], Step [17200/32891], Loss: 0.4470\n","Epoch [7/10], Step [17300/32891], Loss: 0.4535\n","Epoch [7/10], Step [17400/32891], Loss: 0.5240\n","Epoch [7/10], Step [17500/32891], Loss: 0.5446\n","Epoch [7/10], Step [17600/32891], Loss: 0.4897\n","Epoch [7/10], Step [17700/32891], Loss: 0.6343\n","Epoch [7/10], Step [17800/32891], Loss: 0.5560\n","Epoch [7/10], Step [17900/32891], Loss: 0.4818\n","Epoch [7/10], Step [18000/32891], Loss: 0.4625\n","Epoch [7/10], Step [18100/32891], Loss: 0.5102\n","Epoch [7/10], Step [18200/32891], Loss: 0.4620\n","Epoch [7/10], Step [18300/32891], Loss: 0.5202\n","Epoch [7/10], Step [18400/32891], Loss: 0.5696\n","Epoch [7/10], Step [18500/32891], Loss: 0.5433\n","Epoch [7/10], Step [18600/32891], Loss: 0.4504\n","Epoch [7/10], Step [18700/32891], Loss: 0.4084\n","Epoch [7/10], Step [18800/32891], Loss: 0.5563\n","Epoch [7/10], Step [18900/32891], Loss: 0.5141\n","Epoch [7/10], Step [19000/32891], Loss: 0.4813\n","Epoch [7/10], Step [19100/32891], Loss: 0.5625\n","Epoch [7/10], Step [19200/32891], Loss: 0.4092\n","Epoch [7/10], Step [19300/32891], Loss: 0.5146\n","Epoch [7/10], Step [19400/32891], Loss: 0.5561\n","Epoch [7/10], Step [19500/32891], Loss: 0.5024\n","Epoch [7/10], Step [19600/32891], Loss: 0.4931\n","Epoch [7/10], Step [19700/32891], Loss: 0.5458\n","Epoch [7/10], Step [19800/32891], Loss: 0.6282\n","Epoch [7/10], Step [19900/32891], Loss: 0.4539\n","Epoch [7/10], Step [20000/32891], Loss: 0.5766\n","Epoch [7/10], Step [20100/32891], Loss: 0.5081\n","Epoch [7/10], Step [20200/32891], Loss: 0.5190\n","Epoch [7/10], Step [20300/32891], Loss: 0.4368\n","Epoch [7/10], Step [20400/32891], Loss: 0.4774\n","Epoch [7/10], Step [20500/32891], Loss: 0.4559\n","Epoch [7/10], Step [20600/32891], Loss: 0.4625\n","Epoch [7/10], Step [20700/32891], Loss: 0.5471\n","Epoch [7/10], Step [20800/32891], Loss: 0.4661\n","Epoch [7/10], Step [20900/32891], Loss: 0.4766\n","Epoch [7/10], Step [21000/32891], Loss: 0.4817\n","Epoch [7/10], Step [21100/32891], Loss: 0.5077\n","Epoch [7/10], Step [21200/32891], Loss: 0.5439\n","Epoch [7/10], Step [21300/32891], Loss: 0.4935\n","Epoch [7/10], Step [21400/32891], Loss: 0.5249\n","Epoch [7/10], Step [21500/32891], Loss: 0.4990\n","Epoch [7/10], Step [21600/32891], Loss: 0.5565\n","Epoch [7/10], Step [21700/32891], Loss: 0.5127\n","Epoch [7/10], Step [21800/32891], Loss: 0.5278\n","Epoch [7/10], Step [21900/32891], Loss: 0.5329\n","Epoch [7/10], Step [22000/32891], Loss: 0.5092\n","Epoch [7/10], Step [22100/32891], Loss: 0.4597\n","Epoch [7/10], Step [22200/32891], Loss: 0.5301\n","Epoch [7/10], Step [22300/32891], Loss: 0.5824\n","Epoch [7/10], Step [22400/32891], Loss: 0.4538\n","Epoch [7/10], Step [22500/32891], Loss: 0.6093\n","Epoch [7/10], Step [22600/32891], Loss: 0.5382\n","Epoch [7/10], Step [22700/32891], Loss: 0.5122\n","Epoch [7/10], Step [22800/32891], Loss: 0.5701\n","Epoch [7/10], Step [22900/32891], Loss: 0.4200\n","Epoch [7/10], Step [23000/32891], Loss: 0.5312\n","Epoch [7/10], Step [23100/32891], Loss: 0.4986\n","Epoch [7/10], Step [23200/32891], Loss: 0.5459\n","Epoch [7/10], Step [23300/32891], Loss: 0.5178\n","Epoch [7/10], Step [23400/32891], Loss: 0.5734\n","Epoch [7/10], Step [23500/32891], Loss: 0.5618\n","Epoch [7/10], Step [23600/32891], Loss: 0.5040\n","Epoch [7/10], Step [23700/32891], Loss: 0.5094\n","Epoch [7/10], Step [23800/32891], Loss: 0.4711\n","Epoch [7/10], Step [23900/32891], Loss: 0.5155\n","Epoch [7/10], Step [24000/32891], Loss: 0.5100\n","Epoch [7/10], Step [24100/32891], Loss: 0.5193\n","Epoch [7/10], Step [24200/32891], Loss: 0.6047\n","Epoch [7/10], Step [24300/32891], Loss: 0.5399\n","Epoch [7/10], Step [24400/32891], Loss: 0.5287\n","Epoch [7/10], Step [24500/32891], Loss: 0.5207\n","Epoch [7/10], Step [24600/32891], Loss: 0.5365\n","Epoch [7/10], Step [24700/32891], Loss: 0.5986\n","Epoch [7/10], Step [24800/32891], Loss: 0.5783\n","Epoch [7/10], Step [24900/32891], Loss: 0.4778\n","Epoch [7/10], Step [25000/32891], Loss: 0.4597\n","Epoch [7/10], Step [25100/32891], Loss: 0.4813\n","Epoch [7/10], Step [25200/32891], Loss: 0.4926\n","Epoch [7/10], Step [25300/32891], Loss: 0.5179\n","Epoch [7/10], Step [25400/32891], Loss: 0.5162\n","Epoch [7/10], Step [25500/32891], Loss: 0.4995\n","Epoch [7/10], Step [25600/32891], Loss: 0.4908\n","Epoch [7/10], Step [25700/32891], Loss: 0.4537\n","Epoch [7/10], Step [25800/32891], Loss: 0.4810\n","Epoch [7/10], Step [25900/32891], Loss: 0.6150\n","Epoch [7/10], Step [26000/32891], Loss: 0.4725\n","Epoch [7/10], Step [26100/32891], Loss: 0.4439\n","Epoch [7/10], Step [26200/32891], Loss: 0.4719\n","Epoch [7/10], Step [26300/32891], Loss: 0.5638\n","Epoch [7/10], Step [26400/32891], Loss: 0.4558\n","Epoch [7/10], Step [26500/32891], Loss: 0.5016\n","Epoch [7/10], Step [26600/32891], Loss: 0.4152\n","Epoch [7/10], Step [26700/32891], Loss: 0.5610\n","Epoch [7/10], Step [26800/32891], Loss: 0.5331\n","Epoch [7/10], Step [26900/32891], Loss: 0.4583\n","Epoch [7/10], Step [27000/32891], Loss: 0.5699\n","Epoch [7/10], Step [27100/32891], Loss: 0.4773\n","Epoch [7/10], Step [27200/32891], Loss: 0.5555\n","Epoch [7/10], Step [27300/32891], Loss: 0.4983\n","Epoch [7/10], Step [27400/32891], Loss: 0.5200\n","Epoch [7/10], Step [27500/32891], Loss: 0.5006\n","Epoch [7/10], Step [27600/32891], Loss: 0.4909\n","Epoch [7/10], Step [27700/32891], Loss: 0.5042\n","Epoch [7/10], Step [27800/32891], Loss: 0.5216\n","Epoch [7/10], Step [27900/32891], Loss: 0.5886\n","Epoch [7/10], Step [28000/32891], Loss: 0.4085\n","Epoch [7/10], Step [28100/32891], Loss: 0.5540\n","Epoch [7/10], Step [28200/32891], Loss: 0.5036\n","Epoch [7/10], Step [28300/32891], Loss: 0.4522\n","Epoch [7/10], Step [28400/32891], Loss: 0.5375\n","Epoch [7/10], Step [28500/32891], Loss: 0.5184\n","Epoch [7/10], Step [28600/32891], Loss: 0.4324\n","Epoch [7/10], Step [28700/32891], Loss: 0.4739\n","Epoch [7/10], Step [28800/32891], Loss: 0.4774\n","Epoch [7/10], Step [28900/32891], Loss: 0.4312\n","Epoch [7/10], Step [29000/32891], Loss: 0.4768\n","Epoch [7/10], Step [29100/32891], Loss: 0.4847\n","Epoch [7/10], Step [29200/32891], Loss: 0.5234\n","Epoch [7/10], Step [29300/32891], Loss: 0.5359\n","Epoch [7/10], Step [29400/32891], Loss: 0.5562\n","Epoch [7/10], Step [29500/32891], Loss: 0.4907\n","Epoch [7/10], Step [29600/32891], Loss: 0.5029\n","Epoch [7/10], Step [29700/32891], Loss: 0.4964\n","Epoch [7/10], Step [29800/32891], Loss: 0.5669\n","Epoch [7/10], Step [29900/32891], Loss: 0.4989\n","Epoch [7/10], Step [30000/32891], Loss: 0.4818\n","Epoch [7/10], Step [30100/32891], Loss: 0.5512\n","Epoch [7/10], Step [30200/32891], Loss: 0.5371\n","Epoch [7/10], Step [30300/32891], Loss: 0.5306\n","Epoch [7/10], Step [30400/32891], Loss: 0.4931\n","Epoch [7/10], Step [30500/32891], Loss: 0.5021\n","Epoch [7/10], Step [30600/32891], Loss: 0.6080\n","Epoch [7/10], Step [30700/32891], Loss: 0.5081\n","Epoch [7/10], Step [30800/32891], Loss: 0.5862\n","Epoch [7/10], Step [30900/32891], Loss: 0.5749\n","Epoch [7/10], Step [31000/32891], Loss: 0.4768\n","Epoch [7/10], Step [31100/32891], Loss: 0.5261\n","Epoch [7/10], Step [31200/32891], Loss: 0.4882\n","Epoch [7/10], Step [31300/32891], Loss: 0.4456\n","Epoch [7/10], Step [31400/32891], Loss: 0.4708\n","Epoch [7/10], Step [31500/32891], Loss: 0.4898\n","Epoch [7/10], Step [31600/32891], Loss: 0.5369\n","Epoch [7/10], Step [31700/32891], Loss: 0.4321\n","Epoch [7/10], Step [31800/32891], Loss: 0.4828\n","Epoch [7/10], Step [31900/32891], Loss: 0.4729\n","Epoch [7/10], Step [32000/32891], Loss: 0.4563\n","Epoch [7/10], Step [32100/32891], Loss: 0.5200\n","Epoch [7/10], Step [32200/32891], Loss: 0.5098\n","Epoch [7/10], Step [32300/32891], Loss: 0.5415\n","Epoch [7/10], Step [32400/32891], Loss: 0.4934\n","Epoch [7/10], Step [32500/32891], Loss: 0.5442\n","Epoch [7/10], Step [32600/32891], Loss: 0.4319\n","Epoch [7/10], Step [32700/32891], Loss: 0.4774\n","Epoch [7/10], Step [32800/32891], Loss: 0.5406\n","Epoch [8/10], Step [100/32891], Loss: 0.6218\n","Epoch [8/10], Step [200/32891], Loss: 0.6251\n","Epoch [8/10], Step [300/32891], Loss: 0.5119\n","Epoch [8/10], Step [400/32891], Loss: 0.4342\n","Epoch [8/10], Step [500/32891], Loss: 0.4522\n","Epoch [8/10], Step [600/32891], Loss: 0.4714\n","Epoch [8/10], Step [700/32891], Loss: 0.5821\n","Epoch [8/10], Step [800/32891], Loss: 0.5903\n","Epoch [8/10], Step [900/32891], Loss: 0.5093\n","Epoch [8/10], Step [1000/32891], Loss: 0.4537\n","Epoch [8/10], Step [1100/32891], Loss: 0.5223\n","Epoch [8/10], Step [1200/32891], Loss: 0.5645\n","Epoch [8/10], Step [1300/32891], Loss: 0.4994\n","Epoch [8/10], Step [1400/32891], Loss: 0.4121\n","Epoch [8/10], Step [1500/32891], Loss: 0.4799\n","Epoch [8/10], Step [1600/32891], Loss: 0.5072\n","Epoch [8/10], Step [1700/32891], Loss: 0.5240\n","Epoch [8/10], Step [1800/32891], Loss: 0.5811\n","Epoch [8/10], Step [1900/32891], Loss: 0.4457\n","Epoch [8/10], Step [2000/32891], Loss: 0.5498\n","Epoch [8/10], Step [2100/32891], Loss: 0.5994\n","Epoch [8/10], Step [2200/32891], Loss: 0.4711\n","Epoch [8/10], Step [2300/32891], Loss: 0.5738\n","Epoch [8/10], Step [2400/32891], Loss: 0.4770\n","Epoch [8/10], Step [2500/32891], Loss: 0.5276\n","Epoch [8/10], Step [2600/32891], Loss: 0.4742\n","Epoch [8/10], Step [2700/32891], Loss: 0.4767\n","Epoch [8/10], Step [2800/32891], Loss: 0.5408\n","Epoch [8/10], Step [2900/32891], Loss: 0.5186\n","Epoch [8/10], Step [3000/32891], Loss: 0.5156\n","Epoch [8/10], Step [3100/32891], Loss: 0.5018\n","Epoch [8/10], Step [3200/32891], Loss: 0.5317\n","Epoch [8/10], Step [3300/32891], Loss: 0.4415\n","Epoch [8/10], Step [3400/32891], Loss: 0.5283\n","Epoch [8/10], Step [3500/32891], Loss: 0.5839\n","Epoch [8/10], Step [3600/32891], Loss: 0.4232\n","Epoch [8/10], Step [3700/32891], Loss: 0.5862\n","Epoch [8/10], Step [3800/32891], Loss: 0.4699\n","Epoch [8/10], Step [3900/32891], Loss: 0.3864\n","Epoch [8/10], Step [4000/32891], Loss: 0.4946\n","Epoch [8/10], Step [4100/32891], Loss: 0.4966\n","Epoch [8/10], Step [4200/32891], Loss: 0.5048\n","Epoch [8/10], Step [4300/32891], Loss: 0.5316\n","Epoch [8/10], Step [4400/32891], Loss: 0.5176\n","Epoch [8/10], Step [4500/32891], Loss: 0.4886\n","Epoch [8/10], Step [4600/32891], Loss: 0.4892\n","Epoch [8/10], Step [4700/32891], Loss: 0.4539\n","Epoch [8/10], Step [4800/32891], Loss: 0.5542\n","Epoch [8/10], Step [4900/32891], Loss: 0.4963\n","Epoch [8/10], Step [5000/32891], Loss: 0.4465\n","Epoch [8/10], Step [5100/32891], Loss: 0.4823\n","Epoch [8/10], Step [5200/32891], Loss: 0.5072\n","Epoch [8/10], Step [5300/32891], Loss: 0.5009\n","Epoch [8/10], Step [5400/32891], Loss: 0.4587\n","Epoch [8/10], Step [5500/32891], Loss: 0.5015\n","Epoch [8/10], Step [5600/32891], Loss: 0.5066\n","Epoch [8/10], Step [5700/32891], Loss: 0.4544\n","Epoch [8/10], Step [5800/32891], Loss: 0.5342\n","Epoch [8/10], Step [5900/32891], Loss: 0.5407\n","Epoch [8/10], Step [6000/32891], Loss: 0.5156\n","Epoch [8/10], Step [6100/32891], Loss: 0.6532\n","Epoch [8/10], Step [6200/32891], Loss: 0.4541\n","Epoch [8/10], Step [6300/32891], Loss: 0.4868\n","Epoch [8/10], Step [6400/32891], Loss: 0.4835\n","Epoch [8/10], Step [6500/32891], Loss: 0.4553\n","Epoch [8/10], Step [6600/32891], Loss: 0.5526\n","Epoch [8/10], Step [6700/32891], Loss: 0.4673\n","Epoch [8/10], Step [6800/32891], Loss: 0.5122\n","Epoch [8/10], Step [6900/32891], Loss: 0.4358\n","Epoch [8/10], Step [7000/32891], Loss: 0.4685\n","Epoch [8/10], Step [7100/32891], Loss: 0.4263\n","Epoch [8/10], Step [7200/32891], Loss: 0.5490\n","Epoch [8/10], Step [7300/32891], Loss: 0.5239\n","Epoch [8/10], Step [7400/32891], Loss: 0.4584\n","Epoch [8/10], Step [7500/32891], Loss: 0.5002\n","Epoch [8/10], Step [7600/32891], Loss: 0.5152\n","Epoch [8/10], Step [7700/32891], Loss: 0.4923\n","Epoch [8/10], Step [7800/32891], Loss: 0.4766\n","Epoch [8/10], Step [7900/32891], Loss: 0.5356\n","Epoch [8/10], Step [8000/32891], Loss: 0.4504\n","Epoch [8/10], Step [8100/32891], Loss: 0.4942\n","Epoch [8/10], Step [8200/32891], Loss: 0.5321\n","Epoch [8/10], Step [8300/32891], Loss: 0.5110\n","Epoch [8/10], Step [8400/32891], Loss: 0.4782\n","Epoch [8/10], Step [8500/32891], Loss: 0.5727\n","Epoch [8/10], Step [8600/32891], Loss: 0.5317\n","Epoch [8/10], Step [8700/32891], Loss: 0.4758\n","Epoch [8/10], Step [8800/32891], Loss: 0.3958\n","Epoch [8/10], Step [8900/32891], Loss: 0.4902\n","Epoch [8/10], Step [9000/32891], Loss: 0.4981\n","Epoch [8/10], Step [9100/32891], Loss: 0.5763\n","Epoch [8/10], Step [9200/32891], Loss: 0.5287\n","Epoch [8/10], Step [9300/32891], Loss: 0.5431\n","Epoch [8/10], Step [9400/32891], Loss: 0.4987\n","Epoch [8/10], Step [9500/32891], Loss: 0.5621\n","Epoch [8/10], Step [9600/32891], Loss: 0.4591\n","Epoch [8/10], Step [9700/32891], Loss: 0.5292\n","Epoch [8/10], Step [9800/32891], Loss: 0.5249\n","Epoch [8/10], Step [9900/32891], Loss: 0.4380\n","Epoch [8/10], Step [10000/32891], Loss: 0.5015\n","Epoch [8/10], Step [10100/32891], Loss: 0.5527\n","Epoch [8/10], Step [10200/32891], Loss: 0.5472\n","Epoch [8/10], Step [10300/32891], Loss: 0.5199\n","Epoch [8/10], Step [10400/32891], Loss: 0.5858\n","Epoch [8/10], Step [10500/32891], Loss: 0.5764\n","Epoch [8/10], Step [10600/32891], Loss: 0.5418\n","Epoch [8/10], Step [10700/32891], Loss: 0.4603\n","Epoch [8/10], Step [10800/32891], Loss: 0.5129\n","Epoch [8/10], Step [10900/32891], Loss: 0.5180\n","Epoch [8/10], Step [11000/32891], Loss: 0.5119\n","Epoch [8/10], Step [11100/32891], Loss: 0.5608\n","Epoch [8/10], Step [11200/32891], Loss: 0.4520\n","Epoch [8/10], Step [11300/32891], Loss: 0.5805\n","Epoch [8/10], Step [11400/32891], Loss: 0.5032\n","Epoch [8/10], Step [11500/32891], Loss: 0.4700\n","Epoch [8/10], Step [11600/32891], Loss: 0.5370\n","Epoch [8/10], Step [11700/32891], Loss: 0.5613\n","Epoch [8/10], Step [11800/32891], Loss: 0.5250\n","Epoch [8/10], Step [11900/32891], Loss: 0.5258\n","Epoch [8/10], Step [12000/32891], Loss: 0.5145\n","Epoch [8/10], Step [12100/32891], Loss: 0.5635\n","Epoch [8/10], Step [12200/32891], Loss: 0.5462\n","Epoch [8/10], Step [12300/32891], Loss: 0.4261\n","Epoch [8/10], Step [12400/32891], Loss: 0.5296\n","Epoch [8/10], Step [12500/32891], Loss: 0.4924\n","Epoch [8/10], Step [12600/32891], Loss: 0.5276\n","Epoch [8/10], Step [12700/32891], Loss: 0.5319\n","Epoch [8/10], Step [12800/32891], Loss: 0.4464\n","Epoch [8/10], Step [12900/32891], Loss: 0.5211\n","Epoch [8/10], Step [13000/32891], Loss: 0.4832\n","Epoch [8/10], Step [13100/32891], Loss: 0.5269\n","Epoch [8/10], Step [13200/32891], Loss: 0.5859\n","Epoch [8/10], Step [13300/32891], Loss: 0.5603\n","Epoch [8/10], Step [13400/32891], Loss: 0.6153\n","Epoch [8/10], Step [13500/32891], Loss: 0.5723\n","Epoch [8/10], Step [13600/32891], Loss: 0.4017\n","Epoch [8/10], Step [13700/32891], Loss: 0.4687\n","Epoch [8/10], Step [13800/32891], Loss: 0.4476\n","Epoch [8/10], Step [13900/32891], Loss: 0.6128\n","Epoch [8/10], Step [14000/32891], Loss: 0.5205\n","Epoch [8/10], Step [14100/32891], Loss: 0.5068\n","Epoch [8/10], Step [14200/32891], Loss: 0.4693\n","Epoch [8/10], Step [14300/32891], Loss: 0.4981\n","Epoch [8/10], Step [14400/32891], Loss: 0.4787\n","Epoch [8/10], Step [14500/32891], Loss: 0.5077\n","Epoch [8/10], Step [14600/32891], Loss: 0.5471\n","Epoch [8/10], Step [14700/32891], Loss: 0.5764\n","Epoch [8/10], Step [14800/32891], Loss: 0.4770\n","Epoch [8/10], Step [14900/32891], Loss: 0.5115\n","Epoch [8/10], Step [15000/32891], Loss: 0.5132\n","Epoch [8/10], Step [15100/32891], Loss: 0.5682\n","Epoch [8/10], Step [15200/32891], Loss: 0.5452\n","Epoch [8/10], Step [15300/32891], Loss: 0.4656\n","Epoch [8/10], Step [15400/32891], Loss: 0.5282\n","Epoch [8/10], Step [15500/32891], Loss: 0.5295\n","Epoch [8/10], Step [15600/32891], Loss: 0.5286\n","Epoch [8/10], Step [15700/32891], Loss: 0.5408\n","Epoch [8/10], Step [15800/32891], Loss: 0.5689\n","Epoch [8/10], Step [15900/32891], Loss: 0.4767\n","Epoch [8/10], Step [16000/32891], Loss: 0.5301\n","Epoch [8/10], Step [16100/32891], Loss: 0.5182\n","Epoch [8/10], Step [16200/32891], Loss: 0.4712\n","Epoch [8/10], Step [16300/32891], Loss: 0.4797\n","Epoch [8/10], Step [16400/32891], Loss: 0.5434\n","Epoch [8/10], Step [16500/32891], Loss: 0.4926\n","Epoch [8/10], Step [16600/32891], Loss: 0.5290\n","Epoch [8/10], Step [16700/32891], Loss: 0.5906\n","Epoch [8/10], Step [16800/32891], Loss: 0.5181\n","Epoch [8/10], Step [16900/32891], Loss: 0.5993\n","Epoch [8/10], Step [17000/32891], Loss: 0.4261\n","Epoch [8/10], Step [17100/32891], Loss: 0.4734\n","Epoch [8/10], Step [17200/32891], Loss: 0.5369\n","Epoch [8/10], Step [17300/32891], Loss: 0.5966\n","Epoch [8/10], Step [17400/32891], Loss: 0.5313\n","Epoch [8/10], Step [17500/32891], Loss: 0.5567\n","Epoch [8/10], Step [17600/32891], Loss: 0.4515\n","Epoch [8/10], Step [17700/32891], Loss: 0.5346\n","Epoch [8/10], Step [17800/32891], Loss: 0.4984\n","Epoch [8/10], Step [17900/32891], Loss: 0.5688\n","Epoch [8/10], Step [18000/32891], Loss: 0.4868\n","Epoch [8/10], Step [18100/32891], Loss: 0.4714\n","Epoch [8/10], Step [18200/32891], Loss: 0.4936\n","Epoch [8/10], Step [18300/32891], Loss: 0.5068\n","Epoch [8/10], Step [18400/32891], Loss: 0.5256\n","Epoch [8/10], Step [18500/32891], Loss: 0.5207\n","Epoch [8/10], Step [18600/32891], Loss: 0.4640\n","Epoch [8/10], Step [18700/32891], Loss: 0.4455\n","Epoch [8/10], Step [18800/32891], Loss: 0.5987\n","Epoch [8/10], Step [18900/32891], Loss: 0.4734\n","Epoch [8/10], Step [19000/32891], Loss: 0.4756\n","Epoch [8/10], Step [19100/32891], Loss: 0.5188\n","Epoch [8/10], Step [19200/32891], Loss: 0.4859\n","Epoch [8/10], Step [19300/32891], Loss: 0.4944\n","Epoch [8/10], Step [19400/32891], Loss: 0.5239\n","Epoch [8/10], Step [19500/32891], Loss: 0.5060\n","Epoch [8/10], Step [19600/32891], Loss: 0.5202\n","Epoch [8/10], Step [19700/32891], Loss: 0.5651\n","Epoch [8/10], Step [19800/32891], Loss: 0.4970\n","Epoch [8/10], Step [19900/32891], Loss: 0.5347\n","Epoch [8/10], Step [20000/32891], Loss: 0.5372\n","Epoch [8/10], Step [20100/32891], Loss: 0.4860\n","Epoch [8/10], Step [20200/32891], Loss: 0.5725\n","Epoch [8/10], Step [20300/32891], Loss: 0.5184\n","Epoch [8/10], Step [20400/32891], Loss: 0.5656\n","Epoch [8/10], Step [20500/32891], Loss: 0.5699\n","Epoch [8/10], Step [20600/32891], Loss: 0.4938\n","Epoch [8/10], Step [20700/32891], Loss: 0.5877\n","Epoch [8/10], Step [20800/32891], Loss: 0.5771\n","Epoch [8/10], Step [20900/32891], Loss: 0.5172\n","Epoch [8/10], Step [21000/32891], Loss: 0.4453\n","Epoch [8/10], Step [21100/32891], Loss: 0.5149\n","Epoch [8/10], Step [21200/32891], Loss: 0.5000\n","Epoch [8/10], Step [21300/32891], Loss: 0.5816\n","Epoch [8/10], Step [21400/32891], Loss: 0.4700\n","Epoch [8/10], Step [21500/32891], Loss: 0.4626\n","Epoch [8/10], Step [21600/32891], Loss: 0.5355\n","Epoch [8/10], Step [21700/32891], Loss: 0.4695\n","Epoch [8/10], Step [21800/32891], Loss: 0.6553\n","Epoch [8/10], Step [21900/32891], Loss: 0.4504\n","Epoch [8/10], Step [22000/32891], Loss: 0.5475\n","Epoch [8/10], Step [22100/32891], Loss: 0.5288\n","Epoch [8/10], Step [22200/32891], Loss: 0.4450\n","Epoch [8/10], Step [22300/32891], Loss: 0.5800\n","Epoch [8/10], Step [22400/32891], Loss: 0.5457\n","Epoch [8/10], Step [22500/32891], Loss: 0.5590\n","Epoch [8/10], Step [22600/32891], Loss: 0.5037\n","Epoch [8/10], Step [22700/32891], Loss: 0.4805\n","Epoch [8/10], Step [22800/32891], Loss: 0.5451\n","Epoch [8/10], Step [22900/32891], Loss: 0.4945\n","Epoch [8/10], Step [23000/32891], Loss: 0.5762\n","Epoch [8/10], Step [23100/32891], Loss: 0.5149\n","Epoch [8/10], Step [23200/32891], Loss: 0.5255\n","Epoch [8/10], Step [23300/32891], Loss: 0.5346\n","Epoch [8/10], Step [23400/32891], Loss: 0.4943\n","Epoch [8/10], Step [23500/32891], Loss: 0.5691\n","Epoch [8/10], Step [23600/32891], Loss: 0.4795\n","Epoch [8/10], Step [23700/32891], Loss: 0.5162\n","Epoch [8/10], Step [23800/32891], Loss: 0.5230\n","Epoch [8/10], Step [23900/32891], Loss: 0.5629\n","Epoch [8/10], Step [24000/32891], Loss: 0.4358\n","Epoch [8/10], Step [24100/32891], Loss: 0.5344\n","Epoch [8/10], Step [24200/32891], Loss: 0.4628\n","Epoch [8/10], Step [24300/32891], Loss: 0.5192\n","Epoch [8/10], Step [24400/32891], Loss: 0.5697\n","Epoch [8/10], Step [24500/32891], Loss: 0.6532\n","Epoch [8/10], Step [24600/32891], Loss: 0.4576\n","Epoch [8/10], Step [24700/32891], Loss: 0.5208\n","Epoch [8/10], Step [24800/32891], Loss: 0.5086\n","Epoch [8/10], Step [24900/32891], Loss: 0.4706\n","Epoch [8/10], Step [25000/32891], Loss: 0.4764\n","Epoch [8/10], Step [25100/32891], Loss: 0.4544\n","Epoch [8/10], Step [25200/32891], Loss: 0.5725\n","Epoch [8/10], Step [25300/32891], Loss: 0.5887\n","Epoch [8/10], Step [25400/32891], Loss: 0.4694\n","Epoch [8/10], Step [25500/32891], Loss: 0.5676\n","Epoch [8/10], Step [25600/32891], Loss: 0.5291\n","Epoch [8/10], Step [25700/32891], Loss: 0.5874\n","Epoch [8/10], Step [25800/32891], Loss: 0.4899\n","Epoch [8/10], Step [25900/32891], Loss: 0.5014\n","Epoch [8/10], Step [26000/32891], Loss: 0.4858\n","Epoch [8/10], Step [26100/32891], Loss: 0.4423\n","Epoch [8/10], Step [26200/32891], Loss: 0.4481\n","Epoch [8/10], Step [26300/32891], Loss: 0.4824\n","Epoch [8/10], Step [26400/32891], Loss: 0.5689\n","Epoch [8/10], Step [26500/32891], Loss: 0.4729\n","Epoch [8/10], Step [26600/32891], Loss: 0.4791\n","Epoch [8/10], Step [26700/32891], Loss: 0.4381\n","Epoch [8/10], Step [26800/32891], Loss: 0.5497\n","Epoch [8/10], Step [26900/32891], Loss: 0.5559\n","Epoch [8/10], Step [27000/32891], Loss: 0.3999\n","Epoch [8/10], Step [27100/32891], Loss: 0.5650\n","Epoch [8/10], Step [27200/32891], Loss: 0.4468\n","Epoch [8/10], Step [27300/32891], Loss: 0.5200\n","Epoch [8/10], Step [27400/32891], Loss: 0.5191\n","Epoch [8/10], Step [27500/32891], Loss: 0.4688\n","Epoch [8/10], Step [27600/32891], Loss: 0.4719\n","Epoch [8/10], Step [27700/32891], Loss: 0.5481\n","Epoch [8/10], Step [27800/32891], Loss: 0.5145\n","Epoch [8/10], Step [27900/32891], Loss: 0.5073\n","Epoch [8/10], Step [28000/32891], Loss: 0.4790\n","Epoch [8/10], Step [28100/32891], Loss: 0.4773\n","Epoch [8/10], Step [28200/32891], Loss: 0.4681\n","Epoch [8/10], Step [28300/32891], Loss: 0.5531\n","Epoch [8/10], Step [28400/32891], Loss: 0.5599\n","Epoch [8/10], Step [28500/32891], Loss: 0.4724\n","Epoch [8/10], Step [28600/32891], Loss: 0.4846\n","Epoch [8/10], Step [28700/32891], Loss: 0.4970\n","Epoch [8/10], Step [28800/32891], Loss: 0.5091\n","Epoch [8/10], Step [28900/32891], Loss: 0.5191\n","Epoch [8/10], Step [29000/32891], Loss: 0.5273\n","Epoch [8/10], Step [29100/32891], Loss: 0.5736\n","Epoch [8/10], Step [29200/32891], Loss: 0.4915\n","Epoch [8/10], Step [29300/32891], Loss: 0.5359\n","Epoch [8/10], Step [29400/32891], Loss: 0.4773\n","Epoch [8/10], Step [29500/32891], Loss: 0.4771\n","Epoch [8/10], Step [29600/32891], Loss: 0.4981\n","Epoch [8/10], Step [29700/32891], Loss: 0.5090\n","Epoch [8/10], Step [29800/32891], Loss: 0.5142\n","Epoch [8/10], Step [29900/32891], Loss: 0.5136\n","Epoch [8/10], Step [30000/32891], Loss: 0.4625\n","Epoch [8/10], Step [30100/32891], Loss: 0.5064\n","Epoch [8/10], Step [30200/32891], Loss: 0.4890\n","Epoch [8/10], Step [30300/32891], Loss: 0.5395\n","Epoch [8/10], Step [30400/32891], Loss: 0.5260\n","Epoch [8/10], Step [30500/32891], Loss: 0.5260\n","Epoch [8/10], Step [30600/32891], Loss: 0.4901\n","Epoch [8/10], Step [30700/32891], Loss: 0.4979\n","Epoch [8/10], Step [30800/32891], Loss: 0.5156\n","Epoch [8/10], Step [30900/32891], Loss: 0.5238\n","Epoch [8/10], Step [31000/32891], Loss: 0.5111\n","Epoch [8/10], Step [31100/32891], Loss: 0.5769\n","Epoch [8/10], Step [31200/32891], Loss: 0.4370\n","Epoch [8/10], Step [31300/32891], Loss: 0.5852\n","Epoch [8/10], Step [31400/32891], Loss: 0.5477\n","Epoch [8/10], Step [31500/32891], Loss: 0.5395\n","Epoch [8/10], Step [31600/32891], Loss: 0.5833\n","Epoch [8/10], Step [31700/32891], Loss: 0.5353\n","Epoch [8/10], Step [31800/32891], Loss: 0.4861\n","Epoch [8/10], Step [31900/32891], Loss: 0.4874\n","Epoch [8/10], Step [32000/32891], Loss: 0.5388\n","Epoch [8/10], Step [32100/32891], Loss: 0.4973\n","Epoch [8/10], Step [32200/32891], Loss: 0.5563\n","Epoch [8/10], Step [32300/32891], Loss: 0.5245\n","Epoch [8/10], Step [32400/32891], Loss: 0.4655\n","Epoch [8/10], Step [32500/32891], Loss: 0.4941\n","Epoch [8/10], Step [32600/32891], Loss: 0.4974\n","Epoch [8/10], Step [32700/32891], Loss: 0.5216\n","Epoch [8/10], Step [32800/32891], Loss: 0.4787\n","Epoch [9/10], Step [100/32891], Loss: 0.5384\n","Epoch [9/10], Step [200/32891], Loss: 0.5476\n","Epoch [9/10], Step [300/32891], Loss: 0.4972\n","Epoch [9/10], Step [400/32891], Loss: 0.5910\n","Epoch [9/10], Step [500/32891], Loss: 0.4972\n","Epoch [9/10], Step [600/32891], Loss: 0.4511\n","Epoch [9/10], Step [700/32891], Loss: 0.4674\n","Epoch [9/10], Step [800/32891], Loss: 0.5080\n","Epoch [9/10], Step [900/32891], Loss: 0.5315\n","Epoch [9/10], Step [1000/32891], Loss: 0.4877\n","Epoch [9/10], Step [1100/32891], Loss: 0.5168\n","Epoch [9/10], Step [1200/32891], Loss: 0.4886\n","Epoch [9/10], Step [1300/32891], Loss: 0.5139\n","Epoch [9/10], Step [1400/32891], Loss: 0.4880\n","Epoch [9/10], Step [1500/32891], Loss: 0.5666\n","Epoch [9/10], Step [1600/32891], Loss: 0.5088\n","Epoch [9/10], Step [1700/32891], Loss: 0.4440\n","Epoch [9/10], Step [1800/32891], Loss: 0.4932\n","Epoch [9/10], Step [1900/32891], Loss: 0.5663\n","Epoch [9/10], Step [2000/32891], Loss: 0.5178\n","Epoch [9/10], Step [2100/32891], Loss: 0.5120\n","Epoch [9/10], Step [2200/32891], Loss: 0.4635\n","Epoch [9/10], Step [2300/32891], Loss: 0.4683\n","Epoch [9/10], Step [2400/32891], Loss: 0.5558\n","Epoch [9/10], Step [2500/32891], Loss: 0.5374\n","Epoch [9/10], Step [2600/32891], Loss: 0.3966\n","Epoch [9/10], Step [2700/32891], Loss: 0.5746\n","Epoch [9/10], Step [2800/32891], Loss: 0.5154\n","Epoch [9/10], Step [2900/32891], Loss: 0.4569\n","Epoch [9/10], Step [3000/32891], Loss: 0.4701\n","Epoch [9/10], Step [3100/32891], Loss: 0.5247\n","Epoch [9/10], Step [3200/32891], Loss: 0.5024\n","Epoch [9/10], Step [3300/32891], Loss: 0.4999\n","Epoch [9/10], Step [3400/32891], Loss: 0.5285\n","Epoch [9/10], Step [3500/32891], Loss: 0.5047\n","Epoch [9/10], Step [3600/32891], Loss: 0.5334\n","Epoch [9/10], Step [3700/32891], Loss: 0.4799\n","Epoch [9/10], Step [3800/32891], Loss: 0.5028\n","Epoch [9/10], Step [3900/32891], Loss: 0.4033\n","Epoch [9/10], Step [4000/32891], Loss: 0.3806\n","Epoch [9/10], Step [4100/32891], Loss: 0.5307\n","Epoch [9/10], Step [4200/32891], Loss: 0.5024\n","Epoch [9/10], Step [4300/32891], Loss: 0.5202\n","Epoch [9/10], Step [4400/32891], Loss: 0.4843\n","Epoch [9/10], Step [4500/32891], Loss: 0.5035\n","Epoch [9/10], Step [4600/32891], Loss: 0.4910\n","Epoch [9/10], Step [4700/32891], Loss: 0.6043\n","Epoch [9/10], Step [4800/32891], Loss: 0.6351\n","Epoch [9/10], Step [4900/32891], Loss: 0.5495\n","Epoch [9/10], Step [5000/32891], Loss: 0.4826\n","Epoch [9/10], Step [5100/32891], Loss: 0.5217\n","Epoch [9/10], Step [5200/32891], Loss: 0.5184\n","Epoch [9/10], Step [5300/32891], Loss: 0.5010\n","Epoch [9/10], Step [5400/32891], Loss: 0.4964\n","Epoch [9/10], Step [5500/32891], Loss: 0.4962\n","Epoch [9/10], Step [5600/32891], Loss: 0.4713\n","Epoch [9/10], Step [5700/32891], Loss: 0.5067\n","Epoch [9/10], Step [5800/32891], Loss: 0.4989\n","Epoch [9/10], Step [5900/32891], Loss: 0.5123\n","Epoch [9/10], Step [6000/32891], Loss: 0.5173\n","Epoch [9/10], Step [6100/32891], Loss: 0.4602\n","Epoch [9/10], Step [6200/32891], Loss: 0.4544\n","Epoch [9/10], Step [6300/32891], Loss: 0.4092\n","Epoch [9/10], Step [6400/32891], Loss: 0.5834\n","Epoch [9/10], Step [6500/32891], Loss: 0.5807\n","Epoch [9/10], Step [6600/32891], Loss: 0.5596\n","Epoch [9/10], Step [6700/32891], Loss: 0.4466\n","Epoch [9/10], Step [6800/32891], Loss: 0.4903\n","Epoch [9/10], Step [6900/32891], Loss: 0.5544\n","Epoch [9/10], Step [7000/32891], Loss: 0.4748\n","Epoch [9/10], Step [7100/32891], Loss: 0.4361\n","Epoch [9/10], Step [7200/32891], Loss: 0.5045\n","Epoch [9/10], Step [7300/32891], Loss: 0.4534\n","Epoch [9/10], Step [7400/32891], Loss: 0.5314\n","Epoch [9/10], Step [7500/32891], Loss: 0.5487\n","Epoch [9/10], Step [7600/32891], Loss: 0.5466\n","Epoch [9/10], Step [7700/32891], Loss: 0.5166\n","Epoch [9/10], Step [7800/32891], Loss: 0.4547\n","Epoch [9/10], Step [7900/32891], Loss: 0.5246\n","Epoch [9/10], Step [8000/32891], Loss: 0.5187\n","Epoch [9/10], Step [8100/32891], Loss: 0.5194\n","Epoch [9/10], Step [8200/32891], Loss: 0.4935\n","Epoch [9/10], Step [8300/32891], Loss: 0.5113\n","Epoch [9/10], Step [8400/32891], Loss: 0.4002\n","Epoch [9/10], Step [8500/32891], Loss: 0.5463\n","Epoch [9/10], Step [8600/32891], Loss: 0.5601\n","Epoch [9/10], Step [8700/32891], Loss: 0.5597\n","Epoch [9/10], Step [8800/32891], Loss: 0.4377\n","Epoch [9/10], Step [8900/32891], Loss: 0.5381\n","Epoch [9/10], Step [9000/32891], Loss: 0.4826\n","Epoch [9/10], Step [9100/32891], Loss: 0.5934\n","Epoch [9/10], Step [9200/32891], Loss: 0.4966\n","Epoch [9/10], Step [9300/32891], Loss: 0.5279\n","Epoch [9/10], Step [9400/32891], Loss: 0.5141\n","Epoch [9/10], Step [9500/32891], Loss: 0.5743\n","Epoch [9/10], Step [9600/32891], Loss: 0.5132\n","Epoch [9/10], Step [9700/32891], Loss: 0.4878\n","Epoch [9/10], Step [9800/32891], Loss: 0.5885\n","Epoch [9/10], Step [9900/32891], Loss: 0.4965\n","Epoch [9/10], Step [10000/32891], Loss: 0.5075\n","Epoch [9/10], Step [10100/32891], Loss: 0.4267\n","Epoch [9/10], Step [10200/32891], Loss: 0.4928\n","Epoch [9/10], Step [10300/32891], Loss: 0.4408\n","Epoch [9/10], Step [10400/32891], Loss: 0.4998\n","Epoch [9/10], Step [10500/32891], Loss: 0.4532\n","Epoch [9/10], Step [10600/32891], Loss: 0.4837\n","Epoch [9/10], Step [10700/32891], Loss: 0.5715\n","Epoch [9/10], Step [10800/32891], Loss: 0.5459\n","Epoch [9/10], Step [10900/32891], Loss: 0.4742\n","Epoch [9/10], Step [11000/32891], Loss: 0.5347\n","Epoch [9/10], Step [11100/32891], Loss: 0.5496\n","Epoch [9/10], Step [11200/32891], Loss: 0.4401\n","Epoch [9/10], Step [11300/32891], Loss: 0.5454\n","Epoch [9/10], Step [11400/32891], Loss: 0.5670\n","Epoch [9/10], Step [11500/32891], Loss: 0.4720\n","Epoch [9/10], Step [11600/32891], Loss: 0.5214\n","Epoch [9/10], Step [11700/32891], Loss: 0.5517\n","Epoch [9/10], Step [11800/32891], Loss: 0.4394\n","Epoch [9/10], Step [11900/32891], Loss: 0.5393\n","Epoch [9/10], Step [12000/32891], Loss: 0.4810\n","Epoch [9/10], Step [12100/32891], Loss: 0.5486\n","Epoch [9/10], Step [12200/32891], Loss: 0.5030\n","Epoch [9/10], Step [12300/32891], Loss: 0.6426\n","Epoch [9/10], Step [12400/32891], Loss: 0.4955\n","Epoch [9/10], Step [12500/32891], Loss: 0.5210\n","Epoch [9/10], Step [12600/32891], Loss: 0.5023\n","Epoch [9/10], Step [12700/32891], Loss: 0.4616\n","Epoch [9/10], Step [12800/32891], Loss: 0.4705\n","Epoch [9/10], Step [12900/32891], Loss: 0.4689\n","Epoch [9/10], Step [13000/32891], Loss: 0.5548\n","Epoch [9/10], Step [13100/32891], Loss: 0.4668\n","Epoch [9/10], Step [13200/32891], Loss: 0.5362\n","Epoch [9/10], Step [13300/32891], Loss: 0.4689\n","Epoch [9/10], Step [13400/32891], Loss: 0.4536\n","Epoch [9/10], Step [13500/32891], Loss: 0.4491\n","Epoch [9/10], Step [13600/32891], Loss: 0.4569\n","Epoch [9/10], Step [13700/32891], Loss: 0.5008\n","Epoch [9/10], Step [13800/32891], Loss: 0.5291\n","Epoch [9/10], Step [13900/32891], Loss: 0.5182\n","Epoch [9/10], Step [14000/32891], Loss: 0.5588\n","Epoch [9/10], Step [14100/32891], Loss: 0.5031\n","Epoch [9/10], Step [14200/32891], Loss: 0.5290\n","Epoch [9/10], Step [14300/32891], Loss: 0.4877\n","Epoch [9/10], Step [14400/32891], Loss: 0.4851\n","Epoch [9/10], Step [14500/32891], Loss: 0.5079\n","Epoch [9/10], Step [14600/32891], Loss: 0.5194\n","Epoch [9/10], Step [14700/32891], Loss: 0.5770\n","Epoch [9/10], Step [14800/32891], Loss: 0.4921\n","Epoch [9/10], Step [14900/32891], Loss: 0.4653\n","Epoch [9/10], Step [15000/32891], Loss: 0.4912\n","Epoch [9/10], Step [15100/32891], Loss: 0.5930\n","Epoch [9/10], Step [15200/32891], Loss: 0.5835\n","Epoch [9/10], Step [15300/32891], Loss: 0.5291\n","Epoch [9/10], Step [15400/32891], Loss: 0.4970\n","Epoch [9/10], Step [15500/32891], Loss: 0.5681\n","Epoch [9/10], Step [15600/32891], Loss: 0.4888\n","Epoch [9/10], Step [15700/32891], Loss: 0.4327\n","Epoch [9/10], Step [15800/32891], Loss: 0.5242\n","Epoch [9/10], Step [15900/32891], Loss: 0.4952\n","Epoch [9/10], Step [16000/32891], Loss: 0.4452\n","Epoch [9/10], Step [16100/32891], Loss: 0.5907\n","Epoch [9/10], Step [16200/32891], Loss: 0.5578\n","Epoch [9/10], Step [16300/32891], Loss: 0.4731\n","Epoch [9/10], Step [16400/32891], Loss: 0.5551\n","Epoch [9/10], Step [16500/32891], Loss: 0.4474\n","Epoch [9/10], Step [16600/32891], Loss: 0.5480\n","Epoch [9/10], Step [16700/32891], Loss: 0.5126\n","Epoch [9/10], Step [16800/32891], Loss: 0.5075\n","Epoch [9/10], Step [16900/32891], Loss: 0.4229\n","Epoch [9/10], Step [17000/32891], Loss: 0.5636\n","Epoch [9/10], Step [17100/32891], Loss: 0.5329\n","Epoch [9/10], Step [17200/32891], Loss: 0.5822\n","Epoch [9/10], Step [17300/32891], Loss: 0.4676\n","Epoch [9/10], Step [17400/32891], Loss: 0.5460\n","Epoch [9/10], Step [17500/32891], Loss: 0.5144\n","Epoch [9/10], Step [17600/32891], Loss: 0.4383\n","Epoch [9/10], Step [17700/32891], Loss: 0.5384\n","Epoch [9/10], Step [17800/32891], Loss: 0.5666\n","Epoch [9/10], Step [17900/32891], Loss: 0.5083\n","Epoch [9/10], Step [18000/32891], Loss: 0.4818\n","Epoch [9/10], Step [18100/32891], Loss: 0.4789\n","Epoch [9/10], Step [18200/32891], Loss: 0.4789\n","Epoch [9/10], Step [18300/32891], Loss: 0.4780\n","Epoch [9/10], Step [18400/32891], Loss: 0.5502\n","Epoch [9/10], Step [18500/32891], Loss: 0.5185\n","Epoch [9/10], Step [18600/32891], Loss: 0.4942\n","Epoch [9/10], Step [18700/32891], Loss: 0.5244\n","Epoch [9/10], Step [18800/32891], Loss: 0.5083\n","Epoch [9/10], Step [18900/32891], Loss: 0.4638\n","Epoch [9/10], Step [19000/32891], Loss: 0.5211\n","Epoch [9/10], Step [19100/32891], Loss: 0.4452\n","Epoch [9/10], Step [19200/32891], Loss: 0.4315\n","Epoch [9/10], Step [19300/32891], Loss: 0.4931\n","Epoch [9/10], Step [19400/32891], Loss: 0.5186\n","Epoch [9/10], Step [19500/32891], Loss: 0.4879\n","Epoch [9/10], Step [19600/32891], Loss: 0.4794\n","Epoch [9/10], Step [19700/32891], Loss: 0.4906\n","Epoch [9/10], Step [19800/32891], Loss: 0.4570\n","Epoch [9/10], Step [19900/32891], Loss: 0.5293\n","Epoch [9/10], Step [20000/32891], Loss: 0.4612\n","Epoch [9/10], Step [20100/32891], Loss: 0.5830\n","Epoch [9/10], Step [20200/32891], Loss: 0.4912\n","Epoch [9/10], Step [20300/32891], Loss: 0.4687\n","Epoch [9/10], Step [20400/32891], Loss: 0.4551\n","Epoch [9/10], Step [20500/32891], Loss: 0.5633\n","Epoch [9/10], Step [20600/32891], Loss: 0.5662\n","Epoch [9/10], Step [20700/32891], Loss: 0.5112\n","Epoch [9/10], Step [20800/32891], Loss: 0.4937\n","Epoch [9/10], Step [20900/32891], Loss: 0.4545\n","Epoch [9/10], Step [21000/32891], Loss: 0.4942\n","Epoch [9/10], Step [21100/32891], Loss: 0.4052\n","Epoch [9/10], Step [21200/32891], Loss: 0.4697\n","Epoch [9/10], Step [21300/32891], Loss: 0.5117\n","Epoch [9/10], Step [21400/32891], Loss: 0.5073\n","Epoch [9/10], Step [21500/32891], Loss: 0.4117\n","Epoch [9/10], Step [21600/32891], Loss: 0.4271\n","Epoch [9/10], Step [21700/32891], Loss: 0.5089\n","Epoch [9/10], Step [21800/32891], Loss: 0.4932\n","Epoch [9/10], Step [21900/32891], Loss: 0.4453\n","Epoch [9/10], Step [22000/32891], Loss: 0.4405\n","Epoch [9/10], Step [22100/32891], Loss: 0.5152\n","Epoch [9/10], Step [22200/32891], Loss: 0.4632\n","Epoch [9/10], Step [22300/32891], Loss: 0.4780\n","Epoch [9/10], Step [22400/32891], Loss: 0.4907\n","Epoch [9/10], Step [22500/32891], Loss: 0.5109\n","Epoch [9/10], Step [22600/32891], Loss: 0.4678\n","Epoch [9/10], Step [22700/32891], Loss: 0.5144\n","Epoch [9/10], Step [22800/32891], Loss: 0.4651\n","Epoch [9/10], Step [22900/32891], Loss: 0.5433\n","Epoch [9/10], Step [23000/32891], Loss: 0.5871\n","Epoch [9/10], Step [23100/32891], Loss: 0.5484\n","Epoch [9/10], Step [23200/32891], Loss: 0.4714\n","Epoch [9/10], Step [23300/32891], Loss: 0.4812\n","Epoch [9/10], Step [23400/32891], Loss: 0.4702\n","Epoch [9/10], Step [23500/32891], Loss: 0.4835\n","Epoch [9/10], Step [23600/32891], Loss: 0.5252\n","Epoch [9/10], Step [23700/32891], Loss: 0.4829\n","Epoch [9/10], Step [23800/32891], Loss: 0.4924\n","Epoch [9/10], Step [23900/32891], Loss: 0.4807\n","Epoch [9/10], Step [24000/32891], Loss: 0.5274\n","Epoch [9/10], Step [24100/32891], Loss: 0.4813\n","Epoch [9/10], Step [24200/32891], Loss: 0.5385\n","Epoch [9/10], Step [24300/32891], Loss: 0.5051\n","Epoch [9/10], Step [24400/32891], Loss: 0.4907\n","Epoch [9/10], Step [24500/32891], Loss: 0.5194\n","Epoch [9/10], Step [24600/32891], Loss: 0.4567\n","Epoch [9/10], Step [24700/32891], Loss: 0.4565\n","Epoch [9/10], Step [24800/32891], Loss: 0.5017\n","Epoch [9/10], Step [24900/32891], Loss: 0.4692\n","Epoch [9/10], Step [25000/32891], Loss: 0.5386\n","Epoch [9/10], Step [25100/32891], Loss: 0.5470\n","Epoch [9/10], Step [25200/32891], Loss: 0.4919\n","Epoch [9/10], Step [25300/32891], Loss: 0.5167\n","Epoch [9/10], Step [25400/32891], Loss: 0.5266\n","Epoch [9/10], Step [25500/32891], Loss: 0.5648\n","Epoch [9/10], Step [25600/32891], Loss: 0.5198\n","Epoch [9/10], Step [25700/32891], Loss: 0.5137\n","Epoch [9/10], Step [25800/32891], Loss: 0.5361\n","Epoch [9/10], Step [25900/32891], Loss: 0.5980\n","Epoch [9/10], Step [26000/32891], Loss: 0.6393\n","Epoch [9/10], Step [26100/32891], Loss: 0.4879\n","Epoch [9/10], Step [26200/32891], Loss: 0.4947\n","Epoch [9/10], Step [26300/32891], Loss: 0.5815\n","Epoch [9/10], Step [26400/32891], Loss: 0.4873\n","Epoch [9/10], Step [26500/32891], Loss: 0.4568\n","Epoch [9/10], Step [26600/32891], Loss: 0.5016\n","Epoch [9/10], Step [26700/32891], Loss: 0.4579\n","Epoch [9/10], Step [26800/32891], Loss: 0.5062\n","Epoch [9/10], Step [26900/32891], Loss: 0.5333\n","Epoch [9/10], Step [27000/32891], Loss: 0.5264\n","Epoch [9/10], Step [27100/32891], Loss: 0.5026\n","Epoch [9/10], Step [27200/32891], Loss: 0.5325\n","Epoch [9/10], Step [27300/32891], Loss: 0.4619\n","Epoch [9/10], Step [27400/32891], Loss: 0.4861\n","Epoch [9/10], Step [27500/32891], Loss: 0.6183\n","Epoch [9/10], Step [27600/32891], Loss: 0.4881\n","Epoch [9/10], Step [27700/32891], Loss: 0.5147\n","Epoch [9/10], Step [27800/32891], Loss: 0.4895\n","Epoch [9/10], Step [27900/32891], Loss: 0.5320\n","Epoch [9/10], Step [28000/32891], Loss: 0.4989\n","Epoch [9/10], Step [28100/32891], Loss: 0.5578\n","Epoch [9/10], Step [28200/32891], Loss: 0.5554\n","Epoch [9/10], Step [28300/32891], Loss: 0.5445\n","Epoch [9/10], Step [28400/32891], Loss: 0.5021\n","Epoch [9/10], Step [28500/32891], Loss: 0.5134\n","Epoch [9/10], Step [28600/32891], Loss: 0.4978\n","Epoch [9/10], Step [28700/32891], Loss: 0.5435\n","Epoch [9/10], Step [28800/32891], Loss: 0.5585\n","Epoch [9/10], Step [28900/32891], Loss: 0.4983\n","Epoch [9/10], Step [29000/32891], Loss: 0.4773\n","Epoch [9/10], Step [29100/32891], Loss: 0.4655\n","Epoch [9/10], Step [29200/32891], Loss: 0.4429\n","Epoch [9/10], Step [29300/32891], Loss: 0.5247\n","Epoch [9/10], Step [29400/32891], Loss: 0.4754\n","Epoch [9/10], Step [29500/32891], Loss: 0.5425\n","Epoch [9/10], Step [29600/32891], Loss: 0.5038\n","Epoch [9/10], Step [29700/32891], Loss: 0.5068\n","Epoch [9/10], Step [29800/32891], Loss: 0.4741\n","Epoch [9/10], Step [29900/32891], Loss: 0.4660\n","Epoch [9/10], Step [30000/32891], Loss: 0.4817\n","Epoch [9/10], Step [30100/32891], Loss: 0.4925\n","Epoch [9/10], Step [30200/32891], Loss: 0.4666\n","Epoch [9/10], Step [30300/32891], Loss: 0.5113\n","Epoch [9/10], Step [30400/32891], Loss: 0.4998\n","Epoch [9/10], Step [30500/32891], Loss: 0.6302\n","Epoch [9/10], Step [30600/32891], Loss: 0.5521\n","Epoch [9/10], Step [30700/32891], Loss: 0.5969\n","Epoch [9/10], Step [30800/32891], Loss: 0.5050\n","Epoch [9/10], Step [30900/32891], Loss: 0.5199\n","Epoch [9/10], Step [31000/32891], Loss: 0.5119\n","Epoch [9/10], Step [31100/32891], Loss: 0.5035\n","Epoch [9/10], Step [31200/32891], Loss: 0.5627\n","Epoch [9/10], Step [31300/32891], Loss: 0.4507\n","Epoch [9/10], Step [31400/32891], Loss: 0.4465\n","Epoch [9/10], Step [31500/32891], Loss: 0.4907\n","Epoch [9/10], Step [31600/32891], Loss: 0.4756\n","Epoch [9/10], Step [31700/32891], Loss: 0.4757\n","Epoch [9/10], Step [31800/32891], Loss: 0.5817\n","Epoch [9/10], Step [31900/32891], Loss: 0.4410\n","Epoch [9/10], Step [32000/32891], Loss: 0.4125\n","Epoch [9/10], Step [32100/32891], Loss: 0.5732\n","Epoch [9/10], Step [32200/32891], Loss: 0.5525\n","Epoch [9/10], Step [32300/32891], Loss: 0.5321\n","Epoch [9/10], Step [32400/32891], Loss: 0.4590\n","Epoch [9/10], Step [32500/32891], Loss: 0.4675\n","Epoch [9/10], Step [32600/32891], Loss: 0.4581\n","Epoch [9/10], Step [32700/32891], Loss: 0.5325\n","Epoch [9/10], Step [32800/32891], Loss: 0.5550\n","Epoch [10/10], Step [100/32891], Loss: 0.4600\n","Epoch [10/10], Step [200/32891], Loss: 0.4841\n","Epoch [10/10], Step [300/32891], Loss: 0.5721\n","Epoch [10/10], Step [400/32891], Loss: 0.4882\n","Epoch [10/10], Step [500/32891], Loss: 0.5178\n","Epoch [10/10], Step [600/32891], Loss: 0.4984\n","Epoch [10/10], Step [700/32891], Loss: 0.5455\n","Epoch [10/10], Step [800/32891], Loss: 0.5388\n","Epoch [10/10], Step [900/32891], Loss: 0.4957\n","Epoch [10/10], Step [1000/32891], Loss: 0.4912\n","Epoch [10/10], Step [1100/32891], Loss: 0.4945\n","Epoch [10/10], Step [1200/32891], Loss: 0.5003\n","Epoch [10/10], Step [1300/32891], Loss: 0.4683\n","Epoch [10/10], Step [1400/32891], Loss: 0.5227\n","Epoch [10/10], Step [1500/32891], Loss: 0.5546\n","Epoch [10/10], Step [1600/32891], Loss: 0.5857\n","Epoch [10/10], Step [1700/32891], Loss: 0.5223\n","Epoch [10/10], Step [1800/32891], Loss: 0.5145\n","Epoch [10/10], Step [1900/32891], Loss: 0.4892\n","Epoch [10/10], Step [2000/32891], Loss: 0.4737\n","Epoch [10/10], Step [2100/32891], Loss: 0.4440\n","Epoch [10/10], Step [2200/32891], Loss: 0.4789\n","Epoch [10/10], Step [2300/32891], Loss: 0.5759\n","Epoch [10/10], Step [2400/32891], Loss: 0.4924\n","Epoch [10/10], Step [2500/32891], Loss: 0.4570\n","Epoch [10/10], Step [2600/32891], Loss: 0.4138\n","Epoch [10/10], Step [2700/32891], Loss: 0.4170\n","Epoch [10/10], Step [2800/32891], Loss: 0.4863\n","Epoch [10/10], Step [2900/32891], Loss: 0.4983\n","Epoch [10/10], Step [3000/32891], Loss: 0.5172\n","Epoch [10/10], Step [3100/32891], Loss: 0.4773\n","Epoch [10/10], Step [3200/32891], Loss: 0.4780\n","Epoch [10/10], Step [3300/32891], Loss: 0.4734\n","Epoch [10/10], Step [3400/32891], Loss: 0.4635\n","Epoch [10/10], Step [3500/32891], Loss: 0.4341\n","Epoch [10/10], Step [3600/32891], Loss: 0.4449\n","Epoch [10/10], Step [3700/32891], Loss: 0.4825\n","Epoch [10/10], Step [3800/32891], Loss: 0.4671\n","Epoch [10/10], Step [3900/32891], Loss: 0.5848\n","Epoch [10/10], Step [4000/32891], Loss: 0.5253\n","Epoch [10/10], Step [4100/32891], Loss: 0.4705\n","Epoch [10/10], Step [4200/32891], Loss: 0.4945\n","Epoch [10/10], Step [4300/32891], Loss: 0.5197\n","Epoch [10/10], Step [4400/32891], Loss: 0.4912\n","Epoch [10/10], Step [4500/32891], Loss: 0.5277\n","Epoch [10/10], Step [4600/32891], Loss: 0.5610\n","Epoch [10/10], Step [4700/32891], Loss: 0.5815\n","Epoch [10/10], Step [4800/32891], Loss: 0.4870\n","Epoch [10/10], Step [4900/32891], Loss: 0.4745\n","Epoch [10/10], Step [5000/32891], Loss: 0.5099\n","Epoch [10/10], Step [5100/32891], Loss: 0.5418\n","Epoch [10/10], Step [5200/32891], Loss: 0.4886\n","Epoch [10/10], Step [5300/32891], Loss: 0.4953\n","Epoch [10/10], Step [5400/32891], Loss: 0.4673\n","Epoch [10/10], Step [5500/32891], Loss: 0.5713\n","Epoch [10/10], Step [5600/32891], Loss: 0.5288\n","Epoch [10/10], Step [5700/32891], Loss: 0.4212\n","Epoch [10/10], Step [5800/32891], Loss: 0.6397\n","Epoch [10/10], Step [5900/32891], Loss: 0.4860\n","Epoch [10/10], Step [6000/32891], Loss: 0.6182\n","Epoch [10/10], Step [6100/32891], Loss: 0.5900\n","Epoch [10/10], Step [6200/32891], Loss: 0.4756\n","Epoch [10/10], Step [6300/32891], Loss: 0.4805\n","Epoch [10/10], Step [6400/32891], Loss: 0.4952\n","Epoch [10/10], Step [6500/32891], Loss: 0.5164\n","Epoch [10/10], Step [6600/32891], Loss: 0.4934\n","Epoch [10/10], Step [6700/32891], Loss: 0.5322\n","Epoch [10/10], Step [6800/32891], Loss: 0.5168\n","Epoch [10/10], Step [6900/32891], Loss: 0.4548\n","Epoch [10/10], Step [7000/32891], Loss: 0.5167\n","Epoch [10/10], Step [7100/32891], Loss: 0.5121\n","Epoch [10/10], Step [7200/32891], Loss: 0.5704\n","Epoch [10/10], Step [7300/32891], Loss: 0.4920\n","Epoch [10/10], Step [7400/32891], Loss: 0.5992\n","Epoch [10/10], Step [7500/32891], Loss: 0.3852\n","Epoch [10/10], Step [7600/32891], Loss: 0.4778\n","Epoch [10/10], Step [7700/32891], Loss: 0.5593\n","Epoch [10/10], Step [7800/32891], Loss: 0.5524\n","Epoch [10/10], Step [7900/32891], Loss: 0.4481\n","Epoch [10/10], Step [8000/32891], Loss: 0.5866\n","Epoch [10/10], Step [8100/32891], Loss: 0.5550\n","Epoch [10/10], Step [8200/32891], Loss: 0.5936\n","Epoch [10/10], Step [8300/32891], Loss: 0.4875\n","Epoch [10/10], Step [8400/32891], Loss: 0.5247\n","Epoch [10/10], Step [8500/32891], Loss: 0.5293\n","Epoch [10/10], Step [8600/32891], Loss: 0.5079\n","Epoch [10/10], Step [8700/32891], Loss: 0.5226\n","Epoch [10/10], Step [8800/32891], Loss: 0.5155\n","Epoch [10/10], Step [8900/32891], Loss: 0.5161\n","Epoch [10/10], Step [9000/32891], Loss: 0.5027\n","Epoch [10/10], Step [9100/32891], Loss: 0.5425\n","Epoch [10/10], Step [9200/32891], Loss: 0.4780\n","Epoch [10/10], Step [9300/32891], Loss: 0.4766\n","Epoch [10/10], Step [9400/32891], Loss: 0.4153\n","Epoch [10/10], Step [9500/32891], Loss: 0.4878\n","Epoch [10/10], Step [9600/32891], Loss: 0.4385\n","Epoch [10/10], Step [9700/32891], Loss: 0.4276\n","Epoch [10/10], Step [9800/32891], Loss: 0.5255\n","Epoch [10/10], Step [9900/32891], Loss: 0.4824\n","Epoch [10/10], Step [10000/32891], Loss: 0.5550\n","Epoch [10/10], Step [10100/32891], Loss: 0.5138\n","Epoch [10/10], Step [10200/32891], Loss: 0.5679\n","Epoch [10/10], Step [10300/32891], Loss: 0.5106\n","Epoch [10/10], Step [10400/32891], Loss: 0.5208\n","Epoch [10/10], Step [10500/32891], Loss: 0.4891\n","Epoch [10/10], Step [10600/32891], Loss: 0.4854\n","Epoch [10/10], Step [10700/32891], Loss: 0.5952\n","Epoch [10/10], Step [10800/32891], Loss: 0.5208\n","Epoch [10/10], Step [10900/32891], Loss: 0.4877\n","Epoch [10/10], Step [11000/32891], Loss: 0.4659\n","Epoch [10/10], Step [11100/32891], Loss: 0.5112\n","Epoch [10/10], Step [11200/32891], Loss: 0.5360\n","Epoch [10/10], Step [11300/32891], Loss: 0.6071\n","Epoch [10/10], Step [11400/32891], Loss: 0.5411\n","Epoch [10/10], Step [11500/32891], Loss: 0.4960\n","Epoch [10/10], Step [11600/32891], Loss: 0.4442\n","Epoch [10/10], Step [11700/32891], Loss: 0.4943\n","Epoch [10/10], Step [11800/32891], Loss: 0.5397\n","Epoch [10/10], Step [11900/32891], Loss: 0.5118\n","Epoch [10/10], Step [12000/32891], Loss: 0.4858\n","Epoch [10/10], Step [12100/32891], Loss: 0.4970\n","Epoch [10/10], Step [12200/32891], Loss: 0.5133\n","Epoch [10/10], Step [12300/32891], Loss: 0.4954\n","Epoch [10/10], Step [12400/32891], Loss: 0.5441\n","Epoch [10/10], Step [12500/32891], Loss: 0.5284\n","Epoch [10/10], Step [12600/32891], Loss: 0.5060\n","Epoch [10/10], Step [12700/32891], Loss: 0.5676\n","Epoch [10/10], Step [12800/32891], Loss: 0.5365\n","Epoch [10/10], Step [12900/32891], Loss: 0.5129\n","Epoch [10/10], Step [13000/32891], Loss: 0.4500\n","Epoch [10/10], Step [13100/32891], Loss: 0.4531\n","Epoch [10/10], Step [13200/32891], Loss: 0.5101\n","Epoch [10/10], Step [13300/32891], Loss: 0.5147\n","Epoch [10/10], Step [13400/32891], Loss: 0.4740\n","Epoch [10/10], Step [13500/32891], Loss: 0.5166\n","Epoch [10/10], Step [13600/32891], Loss: 0.5302\n","Epoch [10/10], Step [13700/32891], Loss: 0.4320\n","Epoch [10/10], Step [13800/32891], Loss: 0.5115\n","Epoch [10/10], Step [13900/32891], Loss: 0.5303\n","Epoch [10/10], Step [14000/32891], Loss: 0.5082\n","Epoch [10/10], Step [14100/32891], Loss: 0.4634\n","Epoch [10/10], Step [14200/32891], Loss: 0.5047\n","Epoch [10/10], Step [14300/32891], Loss: 0.5242\n","Epoch [10/10], Step [14400/32891], Loss: 0.5501\n","Epoch [10/10], Step [14500/32891], Loss: 0.4173\n","Epoch [10/10], Step [14600/32891], Loss: 0.4623\n","Epoch [10/10], Step [14700/32891], Loss: 0.5574\n","Epoch [10/10], Step [14800/32891], Loss: 0.5584\n","Epoch [10/10], Step [14900/32891], Loss: 0.4591\n","Epoch [10/10], Step [15000/32891], Loss: 0.5069\n","Epoch [10/10], Step [15100/32891], Loss: 0.4408\n","Epoch [10/10], Step [15200/32891], Loss: 0.5094\n","Epoch [10/10], Step [15300/32891], Loss: 0.5603\n","Epoch [10/10], Step [15400/32891], Loss: 0.5227\n","Epoch [10/10], Step [15500/32891], Loss: 0.4831\n","Epoch [10/10], Step [15600/32891], Loss: 0.4691\n","Epoch [10/10], Step [15700/32891], Loss: 0.4883\n","Epoch [10/10], Step [15800/32891], Loss: 0.4129\n","Epoch [10/10], Step [15900/32891], Loss: 0.4768\n","Epoch [10/10], Step [16000/32891], Loss: 0.5187\n","Epoch [10/10], Step [16100/32891], Loss: 0.5408\n","Epoch [10/10], Step [16200/32891], Loss: 0.4996\n","Epoch [10/10], Step [16300/32891], Loss: 0.4769\n","Epoch [10/10], Step [16400/32891], Loss: 0.5462\n","Epoch [10/10], Step [16500/32891], Loss: 0.4686\n","Epoch [10/10], Step [16600/32891], Loss: 0.4380\n","Epoch [10/10], Step [16700/32891], Loss: 0.5643\n","Epoch [10/10], Step [16800/32891], Loss: 0.4593\n","Epoch [10/10], Step [16900/32891], Loss: 0.6023\n","Epoch [10/10], Step [17000/32891], Loss: 0.4903\n","Epoch [10/10], Step [17100/32891], Loss: 0.4731\n","Epoch [10/10], Step [17200/32891], Loss: 0.4955\n","Epoch [10/10], Step [17300/32891], Loss: 0.4937\n","Epoch [10/10], Step [17400/32891], Loss: 0.5362\n","Epoch [10/10], Step [17500/32891], Loss: 0.5238\n","Epoch [10/10], Step [17600/32891], Loss: 0.4713\n","Epoch [10/10], Step [17700/32891], Loss: 0.4810\n","Epoch [10/10], Step [17800/32891], Loss: 0.4438\n","Epoch [10/10], Step [17900/32891], Loss: 0.4767\n","Epoch [10/10], Step [18000/32891], Loss: 0.4689\n","Epoch [10/10], Step [18100/32891], Loss: 0.4312\n","Epoch [10/10], Step [18200/32891], Loss: 0.4928\n","Epoch [10/10], Step [18300/32891], Loss: 0.5378\n","Epoch [10/10], Step [18400/32891], Loss: 0.5116\n","Epoch [10/10], Step [18500/32891], Loss: 0.5719\n","Epoch [10/10], Step [18600/32891], Loss: 0.5046\n","Epoch [10/10], Step [18700/32891], Loss: 0.5792\n","Epoch [10/10], Step [18800/32891], Loss: 0.5332\n","Epoch [10/10], Step [18900/32891], Loss: 0.5026\n","Epoch [10/10], Step [19000/32891], Loss: 0.5296\n","Epoch [10/10], Step [19100/32891], Loss: 0.4543\n","Epoch [10/10], Step [19200/32891], Loss: 0.5333\n","Epoch [10/10], Step [19300/32891], Loss: 0.4819\n","Epoch [10/10], Step [19400/32891], Loss: 0.4482\n","Epoch [10/10], Step [19500/32891], Loss: 0.4877\n","Epoch [10/10], Step [19600/32891], Loss: 0.4160\n","Epoch [10/10], Step [19700/32891], Loss: 0.4898\n","Epoch [10/10], Step [19800/32891], Loss: 0.4926\n","Epoch [10/10], Step [19900/32891], Loss: 0.5519\n","Epoch [10/10], Step [20000/32891], Loss: 0.5647\n","Epoch [10/10], Step [20100/32891], Loss: 0.5120\n","Epoch [10/10], Step [20200/32891], Loss: 0.4853\n","Epoch [10/10], Step [20300/32891], Loss: 0.5454\n","Epoch [10/10], Step [20400/32891], Loss: 0.4862\n","Epoch [10/10], Step [20500/32891], Loss: 0.4633\n","Epoch [10/10], Step [20600/32891], Loss: 0.5238\n","Epoch [10/10], Step [20700/32891], Loss: 0.5342\n","Epoch [10/10], Step [20800/32891], Loss: 0.5966\n","Epoch [10/10], Step [20900/32891], Loss: 0.5494\n","Epoch [10/10], Step [21000/32891], Loss: 0.4892\n","Epoch [10/10], Step [21100/32891], Loss: 0.5123\n","Epoch [10/10], Step [21200/32891], Loss: 0.5642\n","Epoch [10/10], Step [21300/32891], Loss: 0.4309\n","Epoch [10/10], Step [21400/32891], Loss: 0.5803\n","Epoch [10/10], Step [21500/32891], Loss: 0.4916\n","Epoch [10/10], Step [21600/32891], Loss: 0.5162\n","Epoch [10/10], Step [21700/32891], Loss: 0.5538\n","Epoch [10/10], Step [21800/32891], Loss: 0.5906\n","Epoch [10/10], Step [21900/32891], Loss: 0.5744\n","Epoch [10/10], Step [22000/32891], Loss: 0.5272\n","Epoch [10/10], Step [22100/32891], Loss: 0.5006\n","Epoch [10/10], Step [22200/32891], Loss: 0.5424\n","Epoch [10/10], Step [22300/32891], Loss: 0.4949\n","Epoch [10/10], Step [22400/32891], Loss: 0.4963\n","Epoch [10/10], Step [22500/32891], Loss: 0.4650\n","Epoch [10/10], Step [22600/32891], Loss: 0.4883\n","Epoch [10/10], Step [22700/32891], Loss: 0.4595\n","Epoch [10/10], Step [22800/32891], Loss: 0.5714\n","Epoch [10/10], Step [22900/32891], Loss: 0.5036\n","Epoch [10/10], Step [23000/32891], Loss: 0.5418\n","Epoch [10/10], Step [23100/32891], Loss: 0.4656\n","Epoch [10/10], Step [23200/32891], Loss: 0.5480\n","Epoch [10/10], Step [23300/32891], Loss: 0.6176\n","Epoch [10/10], Step [23400/32891], Loss: 0.5887\n","Epoch [10/10], Step [23500/32891], Loss: 0.5052\n","Epoch [10/10], Step [23600/32891], Loss: 0.5942\n","Epoch [10/10], Step [23700/32891], Loss: 0.4365\n","Epoch [10/10], Step [23800/32891], Loss: 0.4745\n","Epoch [10/10], Step [23900/32891], Loss: 0.4987\n","Epoch [10/10], Step [24000/32891], Loss: 0.5438\n","Epoch [10/10], Step [24100/32891], Loss: 0.4607\n","Epoch [10/10], Step [24200/32891], Loss: 0.5933\n","Epoch [10/10], Step [24300/32891], Loss: 0.5662\n","Epoch [10/10], Step [24400/32891], Loss: 0.5268\n","Epoch [10/10], Step [24500/32891], Loss: 0.4939\n","Epoch [10/10], Step [24600/32891], Loss: 0.5493\n","Epoch [10/10], Step [24700/32891], Loss: 0.4888\n","Epoch [10/10], Step [24800/32891], Loss: 0.5092\n","Epoch [10/10], Step [24900/32891], Loss: 0.5716\n","Epoch [10/10], Step [25000/32891], Loss: 0.5275\n","Epoch [10/10], Step [25100/32891], Loss: 0.5648\n","Epoch [10/10], Step [25200/32891], Loss: 0.4625\n","Epoch [10/10], Step [25300/32891], Loss: 0.4849\n","Epoch [10/10], Step [25400/32891], Loss: 0.5431\n","Epoch [10/10], Step [25500/32891], Loss: 0.6173\n","Epoch [10/10], Step [25600/32891], Loss: 0.5921\n","Epoch [10/10], Step [25700/32891], Loss: 0.4225\n","Epoch [10/10], Step [25800/32891], Loss: 0.4703\n","Epoch [10/10], Step [25900/32891], Loss: 0.5367\n","Epoch [10/10], Step [26000/32891], Loss: 0.5204\n","Epoch [10/10], Step [26100/32891], Loss: 0.5072\n","Epoch [10/10], Step [26200/32891], Loss: 0.5051\n","Epoch [10/10], Step [26300/32891], Loss: 0.5995\n","Epoch [10/10], Step [26400/32891], Loss: 0.4692\n","Epoch [10/10], Step [26500/32891], Loss: 0.5443\n","Epoch [10/10], Step [26600/32891], Loss: 0.4367\n","Epoch [10/10], Step [26700/32891], Loss: 0.4927\n","Epoch [10/10], Step [26800/32891], Loss: 0.4695\n","Epoch [10/10], Step [26900/32891], Loss: 0.5070\n","Epoch [10/10], Step [27000/32891], Loss: 0.4918\n","Epoch [10/10], Step [27100/32891], Loss: 0.4996\n","Epoch [10/10], Step [27200/32891], Loss: 0.5970\n","Epoch [10/10], Step [27300/32891], Loss: 0.5336\n","Epoch [10/10], Step [27400/32891], Loss: 0.6358\n","Epoch [10/10], Step [27500/32891], Loss: 0.5094\n","Epoch [10/10], Step [27600/32891], Loss: 0.5103\n","Epoch [10/10], Step [27700/32891], Loss: 0.5921\n","Epoch [10/10], Step [27800/32891], Loss: 0.5000\n","Epoch [10/10], Step [27900/32891], Loss: 0.4852\n","Epoch [10/10], Step [28000/32891], Loss: 0.4291\n","Epoch [10/10], Step [28100/32891], Loss: 0.5370\n","Epoch [10/10], Step [28200/32891], Loss: 0.4868\n","Epoch [10/10], Step [28300/32891], Loss: 0.4534\n","Epoch [10/10], Step [28400/32891], Loss: 0.6023\n","Epoch [10/10], Step [28500/32891], Loss: 0.4630\n","Epoch [10/10], Step [28600/32891], Loss: 0.4844\n","Epoch [10/10], Step [28700/32891], Loss: 0.5122\n","Epoch [10/10], Step [28800/32891], Loss: 0.4535\n","Epoch [10/10], Step [28900/32891], Loss: 0.5934\n","Epoch [10/10], Step [29000/32891], Loss: 0.5174\n","Epoch [10/10], Step [29100/32891], Loss: 0.5728\n","Epoch [10/10], Step [29200/32891], Loss: 0.5150\n","Epoch [10/10], Step [29300/32891], Loss: 0.4176\n","Epoch [10/10], Step [29400/32891], Loss: 0.5189\n","Epoch [10/10], Step [29500/32891], Loss: 0.5670\n","Epoch [10/10], Step [29600/32891], Loss: 0.5438\n","Epoch [10/10], Step [29700/32891], Loss: 0.4666\n","Epoch [10/10], Step [29800/32891], Loss: 0.5922\n","Epoch [10/10], Step [29900/32891], Loss: 0.5008\n","Epoch [10/10], Step [30000/32891], Loss: 0.4940\n","Epoch [10/10], Step [30100/32891], Loss: 0.4899\n","Epoch [10/10], Step [30200/32891], Loss: 0.5324\n","Epoch [10/10], Step [30300/32891], Loss: 0.4920\n","Epoch [10/10], Step [30400/32891], Loss: 0.6476\n","Epoch [10/10], Step [30500/32891], Loss: 0.5418\n","Epoch [10/10], Step [30600/32891], Loss: 0.5103\n","Epoch [10/10], Step [30700/32891], Loss: 0.5202\n","Epoch [10/10], Step [30800/32891], Loss: 0.5116\n","Epoch [10/10], Step [30900/32891], Loss: 0.4918\n","Epoch [10/10], Step [31000/32891], Loss: 0.5119\n","Epoch [10/10], Step [31100/32891], Loss: 0.4650\n","Epoch [10/10], Step [31200/32891], Loss: 0.6066\n","Epoch [10/10], Step [31300/32891], Loss: 0.5579\n","Epoch [10/10], Step [31400/32891], Loss: 0.4988\n","Epoch [10/10], Step [31500/32891], Loss: 0.4817\n","Epoch [10/10], Step [31600/32891], Loss: 0.4231\n","Epoch [10/10], Step [31700/32891], Loss: 0.5278\n","Epoch [10/10], Step [31800/32891], Loss: 0.5155\n","Epoch [10/10], Step [31900/32891], Loss: 0.5222\n","Epoch [10/10], Step [32000/32891], Loss: 0.4265\n","Epoch [10/10], Step [32100/32891], Loss: 0.5434\n","Epoch [10/10], Step [32200/32891], Loss: 0.5138\n","Epoch [10/10], Step [32300/32891], Loss: 0.4493\n","Epoch [10/10], Step [32400/32891], Loss: 0.5309\n","Epoch [10/10], Step [32500/32891], Loss: 0.5923\n","Epoch [10/10], Step [32600/32891], Loss: 0.5380\n","Epoch [10/10], Step [32700/32891], Loss: 0.5038\n","Epoch [10/10], Step [32800/32891], Loss: 0.5664\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dimNyUxTW4QP","executionInfo":{"status":"ok","timestamp":1620170468384,"user_tz":240,"elapsed":1271,"user":{"displayName":"Ryan Cooper","photoUrl":"","userId":"03930546846624815383"}}},"source":["net.eval()\n","out = net.forward(torch.as_tensor(embed_test).cuda())"],"execution_count":108,"outputs":[]},{"cell_type":"code","metadata":{"id":"A8UDtXUKZcwS","executionInfo":{"status":"ok","timestamp":1620170468387,"user_tz":240,"elapsed":1262,"user":{"displayName":"Ryan Cooper","photoUrl":"","userId":"03930546846624815383"}}},"source":["y_pred = out.cpu().detach().argmax(dim=1)\n","y_true = test_labels"],"execution_count":109,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yts4GbECY7TC","executionInfo":{"status":"ok","timestamp":1620170470371,"user_tz":240,"elapsed":3236,"user":{"displayName":"Ryan Cooper","photoUrl":"","userId":"03930546846624815383"}},"outputId":"3e512e67-7c84-4799-d211-8abda928382b"},"source":["print(\"Accuracy:\",sklearn.metrics.accuracy_score(test_labels, y_pred))\n","print(\"Precision:\",sklearn.metrics.precision_score(test_labels, y_pred))\n","print(\"Recall:\",sklearn.metrics.recall_score(test_labels, y_pred))\n","print(\"f1-score:\",sklearn.metrics.f1_score(test_labels, y_pred))"],"execution_count":110,"outputs":[{"output_type":"stream","text":["Accuracy: 0.7578686489652646\n","Precision: 0.7554056880557612\n","Recall: 0.7622440248702299\n","f1-score: 0.7588094501245006\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4CLAqwZiZRMn","executionInfo":{"status":"ok","timestamp":1620170470373,"user_tz":240,"elapsed":3228,"user":{"displayName":"Ryan Cooper","photoUrl":"","userId":"03930546846624815383"}}},"source":["torch.save(net.state_dict(), '/content/gdrive/My Drive/relevancy_model_v3')"],"execution_count":111,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4Xfs4iIlhVD"},"source":[""],"execution_count":null,"outputs":[]}]}